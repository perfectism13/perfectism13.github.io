<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":false,"nav":null,"activeClass":"gitalk"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":"trut","trigger":"auto","top_n_per_article":5,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="perfectism&#39;s blog">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="perfectism&#39;s blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Chenyang Min">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yoursite.com/page/2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>perfectism's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">perfectism's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/perfectism13" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/24/%E5%B7%A5%E4%BD%9C%E5%B2%97%E4%BD%8D%E9%9C%80%E6%B1%82/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chenyang Min">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="perfectism's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/07/24/%E5%B7%A5%E4%BD%9C%E5%B2%97%E4%BD%8D%E9%9C%80%E6%B1%82/" class="post-title-link" itemprop="url">工作岗位需求</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-24 13:10:01" itemprop="dateCreated datePublished" datetime="2020-07-24T13:10:01+08:00">2020-07-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-06-25 17:39:48" itemprop="dateModified" datetime="2020-06-25T17:39:48+08:00">2020-06-25</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="工作岗位需求"><a href="#工作岗位需求" class="headerlink" title="工作岗位需求"></a>工作岗位需求</h1><h2 id="华为"><a href="#华为" class="headerlink" title="华为"></a>华为</h2><h3 id="算法工程师-软件算法"><a href="#算法工程师-软件算法" class="headerlink" title="算法工程师-软件算法"></a>算法工程师-软件算法</h3><ul>
<li>人工智能AI算法、大数据算法、数据结构算法设计和开发能力</li>
<li>至少掌握Java/Python/C其中一种开发语言，掌握Hadoop开源工具使用更佳；</li>
<li>至少掌握一种数据挖掘工具和深度模型训练工具,如Tensorflow,caffe,matlab；</li>
</ul>
<h3 id="算法工程师-媒体算法"><a href="#算法工程师-媒体算法" class="headerlink" title="算法工程师-媒体算法"></a>算法工程师-媒体算法</h3><ul>
<li>具备图像、音频、视频处理算法、深度学习、人脸识别、监控视频、SLAM、3D重建、场景识别、智能语音、智能交互、多媒体信息搜索、光学设计、视频协议标准（HEVC/H264/VPx/VC1/MPEGx）等领域算法理论、研发经历或评测调优经验</li>
</ul>
<h3 id="技术研究工程师-车联网与自动驾驶"><a href="#技术研究工程师-车联网与自动驾驶" class="headerlink" title="技术研究工程师-车联网与自动驾驶"></a>技术研究工程师-车联网与自动驾驶</h3><ul>
<li>（1）传感器融合算法<br>（2）SLAM/VIO算法<br>（3）智能决策、推理、路径规划和运动控制<br>（4）智能交通系统模拟仿真<br>（5）计算机视觉、模式识别、多媒体内容分析<br>负责本领域算法/模型的设计、实现、测试和评估</li>
<li>（1）具备移动机器人等领域研究经验，参与国内外知名相关竞赛，如未来挑战赛等；<br>（2）具备相关工程或开发经验，如深度学习、仿真系统搭建/开发经验等；<br>（3）传感器融合算法方向要求熟悉视觉、毫米波雷达、激光雷达和GPS/IMU等传感器；</li>
</ul>
<h3 id="AI工程师-CV"><a href="#AI工程师-CV" class="headerlink" title="AI工程师-CV"></a>AI工程师-CV</h3><ul>
<li>从事计算机视觉、模式识别、多媒体内容分析等方向的应用研究和开发工作；如3D重建、图像超分、OCR、多目标跟踪、场景识别等；</li>
</ul>
<h3 id="AI工程师-ML"><a href="#AI工程师-ML" class="headerlink" title="AI工程师-ML"></a>AI工程师-ML</h3><ul>
<li>从事机器学习算法和理论前沿研究。研究领域包括：元学习，AutoML, 深度学习，强化学习，贝叶斯学习等；</li>
</ul>
<h2 id="腾讯"><a href="#腾讯" class="headerlink" title="腾讯"></a>腾讯</h2><h3 id="技术研究ML"><a href="#技术研究ML" class="headerlink" title="技术研究ML"></a>技术研究ML</h3><p>神经网络模型设计，超参数优化，现有模型的分布式加速，并行算法库，模式识别，概率统计，最优化，SPark，XGboost</p>
<h3 id="技术研究CV"><a href="#技术研究CV" class="headerlink" title="技术研究CV"></a>技术研究CV</h3><p>人脸识别，物体检测，分类，语义分割，活体识别，车辆与人员的检测识别与跟踪，图像/视频搜索，视频语义分析，视频特征提取与识别，页面分析与自动合成，OCR</p>
<p>shell、python，matlab</p>
<h3 id="技术研究others"><a href="#技术研究others" class="headerlink" title="技术研究others"></a>技术研究others</h3><p>传统ML（SVM，随机森林，k-MEANS）,深度神经网络（CNN，RNN，LSTM，Seq2Seq）</p>
<h2 id="大疆"><a href="#大疆" class="headerlink" title="大疆"></a>大疆</h2><h3 id="算法-影像类"><a href="#算法-影像类" class="headerlink" title="算法 -影像类"></a>算法 -影像类</h3><p>3A技术：自动对焦(AF)、自动曝光(AE)和自动白平衡(AWB)</p>
<p>画质调优、智能增强</p>
<p>掌握ISP核心算法（去噪、插值、锐化、颜色链路等模块）及3A控制算法设计原理。对计算成像（曝光融合，图像去噪，色调映射）有较深入理解，了解一般的机器学习算法，熟悉相机相关业务（人脸识别、分割、检测、融合、增强等）算法的质量评价准则及具体实现，掌握相机成像及工作原理相关知识，爱好摄影，熟悉后期工作流者优先。</p>
<h3 id="算法-感知类"><a href="#算法-感知类" class="headerlink" title="算法-感知类"></a>算法-感知类</h3><p>SLAM、多传感器融合及深度估计算法</p>
<p>基于双目立体匹配算法的自主机器人环境感知系统开发</p>
<p>基于多传感器融合方案的自主机器人定位及运动物体状态估计系统开发</p>
<p>研发3D检测跟踪算法，开发基于多传感器融合的环境感知算法</p>
<p>熟悉常见传感器特性、多视觉几何算法、三维重建算法、定位匹配技术、滤波理论及常用的图像处理算法，对机器人学等领域有深入认识，并了解各个算法的条件和瓶颈，具有点云数据处理、立体视觉、多传感器融合等科研或开发经验优先。</p>
<p>在高水平国际会议、期刊上发布过相关文章，或在各类竞赛中取得优异成绩，包括但不限于IJRR、CVPR、ICCV、ECCV、NIPS、ICML、ICRA、IROS、ITS、IV、3DV、RSS、IJRR、T-RO、JFR、电子设计大赛、Robocon等；</p>
<h3 id="算法-ML类"><a href="#算法-ML类" class="headerlink" title="算法-ML类"></a>算法-ML类</h3><p>\1. 研发基于图像、点云的语义分割、3D检测跟踪算法；</p>
<p>\2. 研发图像跟踪、人脸识别、人体关键点识别、检测等视觉算法；</p>
<p>\3. 研发视频内容理解、自动剪辑等视觉算法，以及在实际场景中的应用；</p>
<p>\4. 深度学习基础技术的研发，包括但不限于神经网络量化和加速、AutoML、Active Learning等。</p>
<p>熟悉机器学习算法，了解深度学习的学术前沿，具有AUTOML，模型压缩，对抗学习，增强学习，自学习，动作识别，视频理解，物体检测、目标跟踪、场景分割、人脸识别等科研或开发经验优先。</p>
<h3 id="算法-决策规划类"><a href="#算法-决策规划类" class="headerlink" title="算法-决策规划类"></a>算法-决策规划类</h3><p>\1. 研发基于激光雷达、视觉、毫米波雷达等传感器的机器人自动导航应用；</p>
<p>\2. 研发动态复杂环境下规划模块及数据融合框架的算法设计、实现；</p>
<p>\3. 控制和量化导航规划系统风险，强化系统健壮性。</p>
<p>具备导航规划算法、机器人环境感知算法及数据融合算法、凸优化、在线优化、非线性优化、数值优化、移动机器人系统开发等经验。</p>
<h2 id="Alibaba"><a href="#Alibaba" class="headerlink" title="Alibaba"></a>Alibaba</h2><h3 id="达摩院算法-3D-cv"><a href="#达摩院算法-3D-cv" class="headerlink" title="达摩院算法-3D cv"></a>达摩院算法-3D cv</h3><p>三维重建、点云分析、网格处理、参数化建模、纹理合成、SLAM，SFM等计算机图形学和计算机三维视觉相关领域</p>
<h3 id="天猫精灵事业部-视觉算法专家-视觉交互方向"><a href="#天猫精灵事业部-视觉算法专家-视觉交互方向" class="headerlink" title="天猫精灵事业部-视觉算法专家-视觉交互方向"></a>天猫精灵事业部-视觉算法专家-视觉交互方向</h3><p>熟悉图像／视频分析（如物体检测，物体识别，场景理解，手势识别，肢体识别等）的相关算法；</p>
<h3 id="达摩院-自动驾驶视觉感知算法专家-杭州-北京"><a href="#达摩院-自动驾驶视觉感知算法专家-杭州-北京" class="headerlink" title="达摩院-自动驾驶视觉感知算法专家-杭州/北京"></a>达摩院-自动驾驶视觉感知算法专家-杭州/北京</h3><p>具有视频分割检测、模型轻量化网络搜索、单目回3D、多目标跟踪中的一个或多个开发和系统实现经验；</p>
<p>3、精通PyTorch, Caffe框架中的一种，并掌握神经网络相关的优化调参；或精通卡尔曼滤波系列和粒子滤波等技术在单目3D,多目标跟踪中的实际应用；</p>
<h3 id="阿里文娱产品技术平台-计算机视觉算法（增强方向）-摩酷实验室"><a href="#阿里文娱产品技术平台-计算机视觉算法（增强方向）-摩酷实验室" class="headerlink" title="阿里文娱产品技术平台-计算机视觉算法（增强方向）-摩酷实验室"></a>阿里文娱产品技术平台-计算机视觉算法（增强方向）-摩酷实验室</h3><p>a) 去噪声、超分辨率等方向的研发经验；</p>
<p>b) 深度学习模型工程化压缩加速，云/端设备部署相关经验；</p>
<p>c) HDR、影像风格迁移等方向的研发经验；</p>
<h3 id="达摩院-工程专家-视觉智能"><a href="#达摩院-工程专家-视觉智能" class="headerlink" title="达摩院-工程专家-视觉智能"></a>达摩院-工程专家-视觉智能</h3><p>3) 熟悉云上产品流程开发经验和工具栈，或者端上AI应用和优化经验，具备分布式计算、FPGA/CUDA开发、Hadoop/Spark/Flink等流计算开发能力者优先；</p>
<p>4) 具有扎实的工程实现和架构能力，精通C/C++/Java/Python其中一种及以上编程语言；</p>
<p>5) 或：精通各种主流JAVA框架，包括spring、netty、hibernate、mybatis等，对JVM原理有深层次的理解；或具备分布式系统架构能力，熟悉分布式容错、分布式缓存、高并发等主流技术，具备多线程及高性能的设计与编码及性能调优经验；</p>
<h3 id="阿里文娱产品技术平台-计算机视觉算法（人脸方向）-摩酷实验室"><a href="#阿里文娱产品技术平台-计算机视觉算法（人脸方向）-摩酷实验室" class="headerlink" title="阿里文娱产品技术平台-计算机视觉算法（人脸方向）-摩酷实验室"></a>阿里文娱产品技术平台-计算机视觉算法（人脸方向）-摩酷实验室</h3><p>a) 人脸识别、端侧人脸检测、端侧人脸关键点提取等方向的研发经验；</p>
<p>b) 深度学习端侧模型工程化压缩加速部署相关经验；</p>
<p>c) 人脸图像/视频生成端侧模型方向的研发经验；</p>
<h3 id="新零售技术事业群-视觉算法-淘系技术部"><a href="#新零售技术事业群-视觉算法-淘系技术部" class="headerlink" title="新零售技术事业群-视觉算法-淘系技术部"></a>新零售技术事业群-视觉算法-淘系技术部</h3><p>图像数据的分析与处理、生成与编辑、搭配与增强、效果评估、视觉数据检索等技术研发；</p>
<h3 id="钉钉-DingTalk-视觉技术（图像视频）专家-智能硬件技术"><a href="#钉钉-DingTalk-视觉技术（图像视频）专家-智能硬件技术" class="headerlink" title="钉钉(DingTalk)-视觉技术（图像视频）专家-智能硬件技术"></a>钉钉(DingTalk)-视觉技术（图像视频）专家-智能硬件技术</h3><p>\2. 算法工程方向，负责计算机视觉、图像识别、视频分析等方向算法工程化应用，落地到产品上；</p>
<p>\3. 图像质量方向，负责Camera驱动适配和软件功能开发、ISP tuning以及图像处理算法应用等相关工作</p>
<p>\4. 应用开发方向，负责机器视觉和图像视频系统软件架构设计和软件开发；</p>
<h3 id="蚂蚁金服-计算机视觉高级-资深专家"><a href="#蚂蚁金服-计算机视觉高级-资深专家" class="headerlink" title="蚂蚁金服-计算机视觉高级/资深专家"></a>蚂蚁金服-计算机视觉高级/资深专家</h3><p>参与图像/视频技术的研发、升级，以及在蚂蚁金服各个应用场景的落地；</p>
<p>2、运用 CUDA 库以及多机多 GPU 卡参与大规模分布式机器学习能力建设；</p>
<p>对大规模分布式计算范式有深刻认识，熟悉 MapReduce，了解 Parameter Server 框架；</p>
<p>对于有模型压缩、量化、剪枝、加速、端上移植优化等经验者优先</p>
<h3 id="Aliexpress-算法专家-视觉技术"><a href="#Aliexpress-算法专家-视觉技术" class="headerlink" title="Aliexpress-算法专家-视觉技术"></a>Aliexpress-算法专家-视觉技术</h3><p>\1. 图像/视频搜索方向（拍立淘）</p>
<p>图像/视频分析算法，包括但不限于视频检测和跟踪、图像/视频特征、图像/视频caption和视频摘要；</p>
<p>大规模图像/视频搜索系统，包括但不限于矢量搜索引擎、鲁棒的图像/视频表示、多模态搜索和搜索重排序。</p>
<p>\2. 图像/视频识别方向</p>
<p>大规模图像识别（extreme classification），包括但不限于multi-class/multi-label；</p>
<p>万物识别（如花草等），商品识别、细粒度识别以及多模态识别（如图文联合识别）相关。</p>
<p>\3. 图像/视频分割检测方向</p>
<p>设计开发图像/视频检测和分割算法，包括但不限于显著物体检测，实例分割，语义分割；</p>
<p>手机端轻量级模型设计开发，服务器端模型设计开发。</p>
<p>\4. 超大规模分布式训练</p>
<p>参与超大规模分布式深度学习训练平台建设及优化开发；</p>
<p>高性能分布式深度学习训练算法设计及实现，包括但不限于计算优化、通信优化、算子优化等。</p>
<p>2.熟悉常见分布式训练框架，包括但不限于Horovod等；</p>
<p>3.精通并行编程技术及相关并行加速库，能够实现算子级设计和优化；</p>
<p>\4. 扎实的工程能力，精通C/C++/Python，熟悉分布式计算，熟悉分布式计算，有Hadoop/SPAPK经验者优先；</p>
<h3 id="达摩院-多媒体技术专家-创意视觉"><a href="#达摩院-多媒体技术专家-创意视觉" class="headerlink" title="达摩院-多媒体技术专家-创意视觉"></a>达摩院-多媒体技术专家-创意视觉</h3><p>\2. 熟悉opencv或opengl，了解图像渲染和处理的机制和常用算法工具。</p>
<p>\3. 熟悉ffmpeg 源码或者熟练使用ffmpeg 库API 或者其它类似的多媒体架构，深入了解媒体处理的流程。</p>
<h3 id="阿里云智能事业群-视频云-实时计算机视觉算法专家-杭州-上海"><a href="#阿里云智能事业群-视频云-实时计算机视觉算法专家-杭州-上海" class="headerlink" title="阿里云智能事业群-视频云-实时计算机视觉算法专家-杭州/上海"></a>阿里云智能事业群-视频云-实时计算机视觉算法专家-杭州/上海</h3><p>a. 负责视频会议场景下视频图像的AI算法研发优化和技术创新，包括但不限于背景虚化/替换、视频去噪、视频超分、超帧率、细节增强、色彩优化、光线矫正、花屏修复、抖动矫正、违规检测、拥塞预测、宕机预测等；</p>
<p>b. 结合业务场景和前沿技术发展设计轻量、高效、低功耗的算法，并推动算法快速工程化落地。</p>
<p>a.具有人像抠图、视频去噪、超分辨率、超帧率、图像增强等方向研发经验者优先；</p>
<p>b.具备模型轻量化剪枝、量化、压缩等相关经验者优先；</p>
<p>c.熟悉多终端模型推理优化者优先，包括但不限于Intel CPU、Cuda、ARM、Meta、Vulkan、OpenCL等相关工程优化；</p>
<p>3、 精通Tensorflow、Pytorch等框架，熟悉MNN、NCNN等推理框架及其优化方法；</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/24/%E5%8A%A8%E4%BD%9C%EF%BC%88%E8%A1%8C%E4%B8%BA%EF%BC%89%E8%AF%86%E5%88%AB%E4%B8%8E%E5%88%86%E7%B1%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chenyang Min">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="perfectism's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/07/24/%E5%8A%A8%E4%BD%9C%EF%BC%88%E8%A1%8C%E4%B8%BA%EF%BC%89%E8%AF%86%E5%88%AB%E4%B8%8E%E5%88%86%E7%B1%BB/" class="post-title-link" itemprop="url">动作（行为）识别与分类</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-24 13:10:01" itemprop="dateCreated datePublished" datetime="2020-07-24T13:10:01+08:00">2020-07-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-16 21:38:55" itemprop="dateModified" datetime="2020-03-16T21:38:55+08:00">2020-03-16</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="动作（行为）识别与分类"><a href="#动作（行为）识别与分类" class="headerlink" title="动作（行为）识别与分类"></a>动作（行为）识别与分类</h1><p>闵晨阳 2019年12月</p>
<h2 id="视频理解"><a href="#视频理解" class="headerlink" title="视频理解"></a>视频理解</h2><p><img src="https://perfectism13.github.io/2019/12/05/%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB%E4%B8%8E%E5%88%86%E7%B1%BB/VideoUnderstanding.png" alt="img"></p>
<p>长期动作和短期动作的区别</p>
<h2 id="图像分类的传统方法"><a href="#图像分类的传统方法" class="headerlink" title="图像分类的传统方法"></a>图像分类的传统方法</h2><p>传统方法：特征提取与特征分类两个过程进行的。</p>
<p><img src="https://perfectism13.github.io/2019/12/05/%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB%E4%B8%8E%E5%88%86%E7%B1%BB/image-20191211151744336.png" alt="image-20191211151744336"></p>
<h3 id="特征提取概述"><a href="#特征提取概述" class="headerlink" title="特征提取概述"></a>特征提取概述</h3><p><strong>视频本身时间维度上的特征</strong>:</p>
<p><strong>每一帧图像二维空间上的特征</strong>：根据像素<strong>梯度变化</strong>，如一阶、二阶导数与几何特征来进行角点、边缘、区域的检测，<strong>边缘</strong>是图像亮度变化不连续或突变的位置，<strong>角点</strong>是边缘发生不连续或突变的位置，即边缘曲线的曲率极大值的地方。</p>
<ul>
<li><strong>角点检测</strong>：Harris、Kitchen-Rosenfeld角、Shi-Tomasi和FAST角点检测方法</li>
<li><strong>边缘检测</strong>：Sobel、Lapacian、Canny边缘检测方法</li>
<li><strong>局部特征</strong>：如SIFT、SURF、STAR、BRISK、BRIEF、ORB、SimpleBlob方法</li>
<li><strong>针对图像内人体的特征提取办法</strong>：HoG、HoF、MBH等</li>
</ul>
<p>(1). Harris角点检测是通过设置好的窗口在图像上进行滑动来计算局部信号的自相关函数的矩阵特征值与迹，获得极值后从而确定角点位置，具有旋转不变性、尺度不变性和光照不变性特征，算法介绍详见 <a href="https://link.zhihu.com/?target=http%3A//www.cnblogs.com/ronny/p/4009425.html">Harris角点</a>，算法实现详见corner.cpp的cv::cornerHarris()函数。</p>
<p><img src="https://perfectism13.github.io/2019/12/05/%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB%E4%B8%8E%E5%88%86%E7%B1%BB/v2-2b14ef871ea0c07cbbcd6cc26766970f_hd.jpg" alt="img">小窗口在图像中的平移(光滑区、边缘区与角点区)</p>
<p><img src="https://perfectism13.github.io/2019/12/05/%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB%E4%B8%8E%E5%88%86%E7%B1%BB/v2-521fd66f5e5f65592be01f496da4342c_hd.jpg" alt="img"></p>
<p> 自相关二项函数的椭圆曲线扁率及尺寸，由本征值决定</p>
<p>(2). Kitchen-Rosenfeld角点检测是通过计算边缘曲线曲率和梯度幅度的乘积来获得响应极值(人工设置阈值)从而确定角点位置，算法实现详见corner.cpp的cv::preCornerDetect()函数。</p>
<p>(3). Shi-Tomasi角点检测通过设置好的窗口在图像上进行滑动来计算局部信号的自相关函数的矩阵特征值的大小来判断是否是角点，是对Harris角点算法进行了改进，对非极大值进行了抑制，算法介绍详见<a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/tostq/article/details/49178601">Shi_Tomasi角点</a>，在OpenCV中又称GFTT(GoodFeatureToTrack)特征点检测算法，算法实现详见featureselect.cpp的cv::goodFeaturesToTrack()函数。</p>
<p>(4). FAST角点检测通过圆周和圆心的像素点亮度情况，来判断圆心是否为角点，算法介绍详见<a href="https://link.zhihu.com/?target=https%3A//www.cnblogs.com/ronny/p/4078710.html">FAST特征点检测</a>，算法实现详见fast.cpp。</p>
<p><img src="https://perfectism13.github.io/2019/12/05/%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB%E4%B8%8E%E5%88%86%E7%B1%BB/v2-991bebbb04201340457fb524174c2c7f_hd.jpg" alt="img"></p>
<p> FAST角点的圆周检测</p>
<p>边缘检测包括Sobel、Lapacian、Canny边缘检测方法。</p>
<p>(1). Sobel边缘检测，通过高斯平滑滤波和一阶微分求导，对图像灰度函数的近似梯度进行计算，从而判断边缘，算法介绍详见<a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/xiaqunfeng123/article/details/17302003">Sobel 边缘检测算子</a>，算法实现详见Deriv.cpp的cv::Sobel函数。</p>
<p>(2). Lapacian边缘检测，通过高斯平滑滤波和二阶微分求导，对图像灰度函数的近似梯度进行计算，从而判断边缘，算法介绍详见<a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/xiaowei_cqu/article/details/7829481">拉普拉斯算子</a>。</p>
<p>(3). Canny边缘检测是通过对图像进行二维高斯平滑滤波、Sobel算子的梯度检测、求取水平方向与垂直方向梯度的L2/L1范数、非极大值抑制和滞后阈值处理五个过程从而确定边缘位置，算法介绍详见<a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/dcrmg/article/details/52344902">Canny边缘检</a>测，算法详见canny.cpp的cv::Canny()函数。</p>
<p>除了角点和边缘，还可以提取图像的某种局部特征，如SIFT、SURF、STAR、BRISK、BRIEF、ORB、SimpleBlob方法</p>
<p>(1). SIFT即尺度不变特征变换，该算法通过不同尺度空间内的极值检测、特征点定位、梯度方向(梯度的幅值和幅角)确定、描述符生成四个过程，实现了局部特征的提取，该特征具有尺度不变性，且对亮度变化、噪声、视角变化下有一定的稳定性和抗干扰性，算法介绍详见<a href="https://link.zhihu.com/?target=https%3A//www.cnblogs.com/wangguchangqing/p/4853263.html">SIFT特征详解</a>，算法实现详见sift.cpp。</p>
<p><img src="https://perfectism13.github.io/2019/12/05/%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB%E4%B8%8E%E5%88%86%E7%B1%BB/v2-3d4b45b999c08402d288aee3689fa128_hd.jpg" alt="img"></p>
<p> SIFT中的尺度空间金字塔</p>
<p><img src="https://perfectism13.github.io/2019/12/05/%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB%E4%B8%8E%E5%88%86%E7%B1%BB/v2-addfdaf72392dcc70833d5cd47d66460_hd.jpg" alt="img">SIFT中16个Keypoint生成的128维向量</p>
<p>(2). SURF即加速鲁棒性特征，该算法通过Hessian矩阵和LoG方法对特征点进行检测、积分图像的尺度空间建立、特征点定位、梯度方向(梯度的幅值和幅角)确定、描述符生成五个过程，实现了局部特征的提取，该算法与SIFT的过程类似也具有尺度不变性，但计算效率和鲁棒性优于SIFT，算法介绍详见<a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/dcrmg/article/details/52601010">Surf算法特征点检测与匹配</a>，算法实现详见surf.cpp。</p>
<p><img src="https://perfectism13.github.io/2019/12/05/%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB%E4%B8%8E%E5%88%86%E7%B1%BB/v2-b79ab065fb0e9de19de41999af376646_hd.jpg" alt="img">SURF的主方向</p>
<p>(3). STAR算法通过星型滤波器计算图像中每个像素点的响应值，再对响应值进行非极大抑制与直线抑制(提取边缘判断)，从而确定特征点位置，算法详见StarDetector.cpp。</p>
<p>(4). BRISK即二进制鲁棒不变尺度关键点，该算法是通过尺度空间建立、特征点检测、非极大值抑制、特征点信息提取四个过程，比较特征点邻域采样像素之间的灰度值形成二进制字符串，进行汉明距离匹配得到特征描述符，算法介绍详见<a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/hujingshuang/article/details/47045497">BRISK特征提取算法</a>，算法实现详见Brisk.cpp。</p>
<p>(5). BRIEF即二进制鲁棒独立元素特征，该算法通过patch区域建立、像素点灰度值比较，从而确定特征点位置，算法介绍详见<a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/hujingshuang/article/details/46910259">BRIEF特征点描述算法</a>，算法实现详见Brief.cpp。</p>
<p>(6). ORB即面向FAST和旋转BRIEF特征，该算法通过patch区域建立、强度质心搜索，从而确定特征点位置，该特征点有旋转不变性，算法介绍详见<a href="https://link.zhihu.com/?target=https%3A//www.cnblogs.com/wangyaning/p/7854017.html">ORB特征</a>，算法实现详见Orb.cpp。</p>
<p>(7). SimpleBlob算法通过灰度图像二值化转换(连续阈值一转多)，连同区域提取、斑点分类、斑点位置尺寸确定四个过程，检测斑点类的特征点，算法介绍详见<a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/zhaocj/article/details/44886475">SimpleBlobDetector</a>，算法实现详见BlobDetecot.cpp。</p>
<p>(8). MSER即最大稳定极值区域检测，该算法通过改进的分水岭方法，进而判断图像的斑点区域，算法介绍详见<a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/zhaocj/article/details/40742191">MSER</a>，算法实现详见Mser.cpp。</p>
<p>除了通用的上述特征外，还有针对图像内人体的一些特征的提取方法，如HoG、HoF、MBH等方法。</p>
<p>(1). HoG特征用来表达局部目标外观形状的梯度方向分布密度，或称梯度统计信息，通过将图像分成小的连通区域(细胞单元)，并将单元内的各项度点梯度或边缘计算其方向与横轴的夹角，根据圆内划分区域内梯度方向的数量分布构建成直方图，最后组合起来形成特征描述，论文见《Histograms of Oriented Gradients for Human Detection》，算法介绍详见<a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/kuweicai/article/details/78981150">HOG特征检测</a>，算法实现详见HoG.cpp。早期的行人检测算法都是HoG+SVM来实现的。</p>
<p><img src="https://perfectism13.github.io/2019/12/05/%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB%E4%B8%8E%E5%88%86%E7%B1%BB/v2-378f90fb6afb7533685ee0c1e7860523_hd.jpg" alt="img">基本HoG特征</p>
<p><img src="https://perfectism13.github.io/2019/12/05/%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB%E4%B8%8E%E5%88%86%E7%B1%BB/v2-d4b05234a58d4e4cc945c707997a5412_hd.jpg" alt="img">HoG的平均梯度(a)、正负SVM(b、c)、测试图像(d)、矩形HoG描述符(e)、带SVM正负权重的HoG描述符(f、g)</p>
<p>(2). HoF特征类似于HoG特征，只是用光流来代替梯度，即计算光流方向与横轴的夹角，根据圆内划分区域内光流方向的数量分布构建成直方图，最后组合起来形成特征描述。HoF算法介绍详见<a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/u013089961/article/details/44981815">HOF特征</a>，光流算法介绍详见<a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/carson2005/article/details/7581642">光流法简单介绍</a>。</p>
<p>(3). MBH特征也是通过计算光流获得，但它是将x方向和y方向上光流图像看作为两张灰度图像，然后提取灰度图像的梯度直方图，即再图像的x、y方向光流图像上计算HoG特征。</p>
<p><img src="https://perfectism13.github.io/2019/12/05/%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB%E4%B8%8E%E5%88%86%E7%B1%BB/v2-d10b14b25101eaeea60c8785d1fc99bc_hd.jpg" alt="img">相邻两帧(a、b)、光流及边界(c、d)、光流场强度(e、f)、MBH描述符(g、h)</p>
<p>在特征分类上，基本方法是使用kNN或SVM分类器对提取的图片特征进行分类，这两种算法的介绍比较多在此不详细展开。</p>
<p><strong>特征分类</strong>：KNN,SVM</p>
<h3 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h3><p>传统方法一般依据人体行为的构成方式，分为整体表示方式和局部表示方式。</p>
<h4 id="整体表示方式"><a href="#整体表示方式" class="headerlink" title="整体表示方式"></a>整体表示方式</h4><p>将视频帧看作一个整体，通过人体定位-&gt;背景提取追踪-&gt;ROI编码一系列过程，自上而下的提取出全局特征。</p>
<p><strong>优点</strong>：编码信息比较丰富</p>
<p><strong>缺点</strong>：过于依赖准确的定位、精确的背景提取追踪</p>
<p> 对摄像机视点、噪声、遮挡极其敏感</p>
<h5 id="ROI提取表示"><a href="#ROI提取表示" class="headerlink" title="ROI提取表示"></a>ROI提取表示</h5><p>用到的方法有背景剪除法、差分法和光流法，轮廓边缘特征包括运动能量图像(Motion Energy Image, MEI)、运动历史图像(Motion History Image, MHI)、形状上下文(Shape Context, SC)等</p>
<p><strong>优点</strong>：算法相对简单</p>
<p><strong>缺点</strong>：背景剪除可能带来很多噪声，导致人体行为特征很难精确描述，即准确率大大受限于人体行为轮廓提取及帧序列中轮廓的跟踪</p>
<h5 id="时空体积-Space-time-volume-表示"><a href="#时空体积-Space-time-volume-表示" class="headerlink" title="时空体积(Space-time volume)表示"></a>时空体积(Space-time volume)表示</h5><p>将给定序列的帧进行堆叠，但是也需要精确的定位、对齐以及背景剪除。</p>
<h5 id="网络切分-Grid-based-表示"><a href="#网络切分-Grid-based-表示" class="headerlink" title="网络切分(Grid-based)表示"></a>网络切分(Grid-based)表示</h5><p>将待识别的人体区域ROI分割成若干时间空间网格，每个网格代表视频帧的一部分特征，网格的组合才代表ROI的整体特征</p>
<p><strong>优点</strong>：减少ROI中存在的噪声，降低了视角变化带来的细微差异，平滑了自身遮挡产生区分度较差的特征空间</p>
<h4 id="局部表示方式"><a href="#局部表示方式" class="headerlink" title="局部表示方式"></a>局部表示方式</h4><p>将视频段落作为一个整体，通过时空兴趣点检测-&gt;邻域特征点计算-&gt;特征整合与表达一系列过程，自下而上的提取特征</p>
<p><strong>优点</strong>：编码信息比较丰富</p>
<p> 不依赖背景提取、追踪算法</p>
<p><strong>缺点</strong>：依赖兴趣点提取的数量和预处理方法</p>
<p> 摄像机运动产生的误差也会对兴趣点采集造成影响</p>
<h5 id="时空兴趣点检测"><a href="#时空兴趣点检测" class="headerlink" title="时空兴趣点检测"></a>时空兴趣点检测</h5><p>在时空域内提取出兴趣点，该兴趣点是空域时域均变化显著的邻域点，如3D Harris。</p>
<p>有时候多个时空兴趣点的组合也称为局部描述符，描述符已经不再仅仅关注于某些点，而是更上层的关注并描述视频中人体特征的局部，比如3D-HOG(Histogram of Gradien) 《A spatio-temporal descriptor based on 3D-gradients》、3D-SIFT(Scale Invariangt Feature Transform)《A 3-dimensional SIFT descriptor and its application to action recognition》、3D SURF(Speeded-Up Robust Features)《An Efficient Dense and Scale-Invariant Spatio-Temporal Interest Point Detector》。</p>
<h6 id="STIP"><a href="#STIP" class="headerlink" title="STIP"></a>STIP</h6><p>《On space-time interest points》</p>
<ol>
<li>首先对视频进行时间和空间上的尺度变换，即通过不同尺度的高斯滤波函数将视频转为线性尺度空间表示，得到了3D Harris的时空域表达形式</li>
<li>进行时空尺度自适应调整，通过尺度归一化来去除尺度因子对兴趣点的影响，归一化时空尺度的极大值(拉普拉斯极大值:拉普拉斯方程解处的函数值)就是角点函数的极大值，需要类似于EM的算法一面计算能达到极大值的尺度，一面计算在该尺度下重新计算兴趣点的位置，直到位置与尺度收敛</li>
<li>要对这些时空兴趣点将噪声去除，进行分类并用分别向量表示，用马氏距离的k-means进行聚类</li>
</ol>
<p>时空兴趣点本质是通过映射函数把视频这个三维的函数映射到一维空间中，再求此一维空间的局部极大值的点。尺度因子对兴趣点的影响较大，时间尺度因子越大更能检测出动作时间较长的兴趣点，时间尺度因子越小更能检测出动作时间较短的兴趣点，空间尺度越大更能检测出动作幅度较大的兴趣点，作者采用能够表征运动和动作外观信息的局部描述算子，最终组合成34维特征向量。</p>
<h6 id="Cuboid"><a href="#Cuboid" class="headerlink" title="Cuboid"></a>Cuboid</h6><p>《Behavior Recognition via Sparse Spatio-Temporal Features》</p>
<p>STIP的缺点：</p>
<p>使用的是Harris角点，但是对于<strong>动作幅度很小的情形(如面部的表情变化)，或是动作幅度有周期性的情形(如车轮旋转)Harris角点很少</strong>，这一时空角点所产生的特征过于稀疏无法去描述反映特征。</p>
<p>作者提出的Cuboid时空特征点检测器基于时域Gabor滤波器的检测器，能够弥补Harris检测器的不足，检测出很多动作幅度小或是周期性运动的特征。</p>
<p>算法过程：</p>
<ol>
<li>通过特征点检测器检测出兴趣点，再扩展成一个Cuboid(长和宽是检测尺度的6倍)</li>
<li>进行简单变换，特征向量统计处理进行相似度比较</li>
<li>对于Cuboid原型使用k-means进行聚类，对于聚类后的行为描述符可以用卡方距离或SVM来进行分类</li>
</ol>
<p>由于没有尺度变换过程，所以该特征不是尺度不变的，简单变换方法作者尝试了3种，分别是归一化像素值、亮度梯度、加窗光流，特征向量统计处理方法作者尝试了3种，分别是直接使用、全局直方图、局部直方图，最后得出结果是求亮度梯度+局部直方图分类误差最小。</p>
<h6 id="MEI-MHI"><a href="#MEI-MHI" class="headerlink" title="MEI+MHI"></a>MEI+MHI</h6><p>《The recognition of human movement using temporal templates》</p>
<p>作者独特的把行为识别分成了基于人体模型重建的、基于表观模板的和基于运动的三类方法。</p>
<p>人体三维结构重建过于复杂，表观模板有的仅仅是二维的剪影、轮廓或边缘，运动模板主要是光流。</p>
<p>算法过程：</p>
<ol>
<li>先在T时间内通过帧差法检查像素点运动</li>
<li>二值化成MEI，灰度化成MHI</li>
<li>利用马氏距离进行目标匹配</li>
</ol>
<p>帧间差分法是<a href="https://blog.csdn.net/yangleo1987/article/details/79745279" target="_blank" rel="noopener">背景提取算法</a>的一种：将视频流中相邻两帧或相隔几帧图像的两幅图像像素值相减，并对相减后的图像进行阈值化来提取图像中的运动区域</p>
<h6 id="HoG-HoF"><a href="#HoG-HoF" class="headerlink" title="HoG+HoF"></a>HoG+HoF</h6><p>《Learning realistic human actions from movies》</p>
<p>作者结合了Cuboid的思路和HoG、HoF的特征描述，将视频中多尺度Harris角点特征提取后将兴趣点周围的提及划分成若干个Cuboid，并计算每个Cuboid的HoG和HoF特征，最后将归一化后的方向直方图向量串联构成描述符。</p>
<h5 id="局部网格表示"><a href="#局部网格表示" class="headerlink" title="局部网格表示"></a>局部网格表示</h5><p>类似于整体网格表示，只不过是将局部的patch放入了网格单元中</p>
<h3 id="特征融合"><a href="#特征融合" class="headerlink" title="特征融合"></a>特征融合</h3><p>在特征融合方面，人体的轮廓、边缘、运动特征等方面<strong>不具备通用性</strong>，只有将其组合起来，才能构建出更好鲁棒性和有效性的特征。在特征提取之后，为了使特征具有较高的区分能力，去掉冗余信息，提高目标识别的计算效率，需要对所提取的特征进行融合，这一过程也称为<strong>特征编码</strong>，主流的特征编码方式有Bag of Feature和Fisher Vector两种。有些文献中，特征提取后的结果(如纹理、轮廓、角点、边缘、光流)称为<strong>低级特征</strong>，特征融合后的结果称为<strong>中级特征(或中级语义)</strong>，特征分类后的结果称为<strong>高级特征(或高级语义)</strong>。</p>
<h4 id="Bag-of-Feature-词袋-，Bag-of-Visual"><a href="#Bag-of-Feature-词袋-，Bag-of-Visual" class="headerlink" title="Bag of Feature(词袋)，Bag of Visual"></a>Bag of Feature(词袋)，Bag of Visual</h4><p>《Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories》</p>
<p>概念起源于文本分类里的词袋模型（Bag of Words)。特征提取由于都是底层特征，<strong>或多或少会受到光照、遮挡、背景等干扰</strong>，而融合之后的特征能够提炼出局部关键点不变特征，所以需要进行融合表达。</p>
<p>视觉词袋从<strong>时空兴趣点生成的特征描述子进行聚类</strong>获得，每一个聚类的中心就可以看做是一个视觉单词，由于和文本有所差异，故还需要解决<strong>局部特征抽样策略、词典大小、可视化单词的权重计算以及全局词典的构建</strong>等问题。</p>
<p>算法过程：</p>
<ol>
<li><p>提取图像视频特征，其次对特征进行聚类得到一部字典(Visual Vocabulary，或Code Book)</p>
</li>
<li><p>提取图像视频特征，其次对特征进行聚类得到一部字典(Visual Vocabulary，或Code Book)，通过区分度高的特征来寻找聚类中心</p>
</li>
<li><p>最后作为特征分类器的输入对分类器进行训练</p>
<p><img src="https://perfectism13.github.io/2019/12/05/%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB%E4%B8%8E%E5%88%86%E7%B1%BB/v2-1c5477dd52d4e32c9d97058045f0b942_hd.jpg" alt="img"></p>
</li>
</ol>
<h4 id="Fisher-Vector"><a href="#Fisher-Vector" class="headerlink" title="Fisher Vector"></a>Fisher Vector</h4><p>《Fisher Kernels on Visual Vocabularies for Image Categorization》</p>
<p>概率与似然性的区别：</p>
<p>概率，用于在已知一些参数的情况下，预测接下来在观测上所得到的结果；似然性，则是用于在已知某些观测所得到的结果时，对有关事物之性质的参数进行估值。——摘自维基百科</p>
<p>Bag of Feature的缺点：</p>
<p>融合图像底层特征分布时没有考虑这些特征在图像中的相对或绝对位置，且频率直方图的计算量较大，每加入一个类别需要重新进行训练，所以不具备特征的普遍性和紧凑性</p>
<p>Fisher Vector通过似然函数的梯度向量来表达一幅图像，由于图像的概率密度函数是由图像中所有SIFT描述子的概率密度组成的，且每个描述子本质上是由K个高斯模型加权得到的，故整个图像就是由大量高斯模型生成出来的，对每个高斯模型参数求偏导得到的特征向量可以反映该高斯模型在图像中的分布情况。</p>
<p>Fisher Vector通过模型化信号的产生过程，通过EM算法训练SIFT描述子得到每个视觉单词(视觉单词和前文Visual Word不同，并不是词汇描述而是K组高斯模型参数)的权重、均值和协方差矩阵，<strong>图像表示向量维数比Bag of Feature要高，但开销不大</strong>。</p>
<h3 id="特征分类"><a href="#特征分类" class="headerlink" title="特征分类"></a>特征分类</h3><h4 id="直接分类法"><a href="#直接分类法" class="headerlink" title="直接分类法"></a>直接分类法</h4><p>直接分类法需要对提取出来或编码后的行为特征进行降维处理(如PCA)来减少计算复杂度、去除噪声，再用KNN、SVM等传统分类器进行分类，不同特征之间距离的计算可以通过欧式距离、马氏距离等进行度量。</p>
<h4 id="时域状态空间融合模型"><a href="#时域状态空间融合模型" class="headerlink" title="时域状态空间融合模型"></a>时域状态空间融合模型</h4><p>利用动态时间规划(Dynamic Time Warping, DTW)或动态时空规划(Dynamic Space-Time Warping, DSTW)，对不同尺度的时间维度进行对齐，或利用生成模型(如HMM)判别模型(如CRF、MEMM)进行分类判断。</p>
<p>DTW本质上是一个优化问题，用<strong>满足一定条件的时间规整函数来描述输入模板和参考模板的时间对应关系</strong>，进而求解两<strong>模板匹配时累计距离最小</strong>所对应的规整函数。</p>
<h5 id="动态时间规划"><a href="#动态时间规划" class="headerlink" title="动态时间规划"></a>动态时间规划</h5><p>来源于语音识别的方法。和语音信号的随机性类似，视频中的动作行为对于不同的人不同场景下结果是不同的，不可能具有完全相同的时间长度，故<strong>在与已存储模板相匹配时，未知的时间轴要不均匀地扭曲或弯折</strong>，以使其特征与模板特征对正。</p>
<p><img src="https://perfectism13.github.io/2019/12/05/%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB%E4%B8%8E%E5%88%86%E7%B1%BB/v2-ca8dbeb420bbab322d90e7fbe7615be3_hd.jpg" alt="img"></p>
<p>如上图所示，两个相同的动作行为时间序列上表征可能有所差异，需要把时间序列进行延伸和缩短来计算两个时间序列性之间的相关性。方法是用代价矩阵来表示归整路径(Warp Path)，用动态规划的算法来对距离最短路径进行求解.</p>
<p><img src="https://perfectism13.github.io/2019/12/05/%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB%E4%B8%8E%E5%88%86%E7%B1%BB/v2-127ad4b77abd30747036d527a8a4e83d_hd.jpg" alt="img"></p>
<h3 id="以iDT算法为例看传统方法的出理过程"><a href="#以iDT算法为例看传统方法的出理过程" class="headerlink" title="以iDT算法为例看传统方法的出理过程"></a>以iDT算法为例看传统方法的出理过程</h3><p><img src="https://perfectism13.github.io/2019/12/05/%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB%E4%B8%8E%E5%88%86%E7%B1%BB/v2-bdaa9a162be9f337364b6d40b585476c_hd.jpg" alt="img"></p>
<p>《Dense Trajectories and Motion Boundary Descriptors for Action Recognition》和《Action Recognition with Improved Trajectories》</p>
<p>iDT算法再特征提取上采用了上文中的整体表示方法的时空体积方法，特征融合上采用了Fisher Vector方法，特征分类方面采用了<a href="https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Radial_basis_function_kernel">RBF-SVM</a>方法，并采用one-versus-rest策略训练多类分类器</p>
<p>(1). 摄像机预处理</p>
<p>这个过程的目的在于对摄像机的抖动进行消除，因为摄像机的运动会对光流的计算以及轨迹分布有较大影响，要消除这种干扰就要对摄像机的运动有所估计，从而消除背景区域的光流。由于前提设定为相邻两帧图像变化较小，故摄像机运动估计算法本质上是求解前后帧图像计算投影变换矩阵来实现的，而计算投影变换矩阵需要使用<a href="https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Random_sample_consensus">RANSAC算法</a>来估计，该算法需要对两幅图像进行匹配，iDT中选择了SURF特征与光流特征作为匹配特征。有了投影变换矩阵，从而可以获得假定摄像机不运动的校正后图像，从而计算出优化过的光流。</p>
<p>但是如果视频中人体所占比例较大，可能也会被误认为运动的背景，导致投影矩阵估计不准确，iDT使用了一个human detector并对检测到的人体用矩形框标注出来，框中的匹配点不进行计算。</p>
<p><img src="https://perfectism13.github.io/2019/12/05/%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB%E4%B8%8E%E5%88%86%E7%B1%BB/v2-7488d31a771f1e82d46a6fc424cd9304_hd.jpg" alt="img">图14 未经过人体矩形框处理的摄像机校正和经过人体矩形框处理后的摄像机校正</p>
<p>(2). 帧间特征提取</p>
<p>首先构建出多尺度空间，在空间中进行密集特征点采样，帧间特征体现的是一个运动的过程，所以需要对这种特征进行跟踪。每个图像都能的到坐标，并可以通过密集光流场与中值滤波器的乘积计算出该特征点下一帧图像的位置，进而得到了该特征点的一段轨迹。再将轨迹正则化后转为一种特征描述子，包括水平和垂直两个方向。</p>
<p>此外对于不重要的特征点需要设置阈值去除，是通过计算特征点的自相关矩阵的特征值(eigenvalue，不是feature)来和阈值进行比较，并合理去除。</p>
<p>iDT选择尺度数为8，特征点采样间隔为5，连续采集帧数为15，轨迹特征描述子维度为30。</p>
<p>(3). 帧内特征提取</p>
<p>帧内主要提取HoG特征、HoF特征与MBH特征，具体描述可见上一节课。这里的帧内更准确的说是特征点周围N<em>N这个时空体内进行特征提取，空间每个方向分为a份，时间上分为b份，则HoG特征维度为a</em>a<em>b</em>直方图bin数量，HoF特征维度为a<em>a</em>b<em>(直方图bin数量+1)，MBH特征是N</em>b*2。计算后再对三种特征进行L1正则化后再对特征的每个维度开平方。</p>
<p>i一般N为23，a为2，b为3，直方图bin数量为8，故HoG特征、HoF特征与MBH特征维度分别 96、108、192。</p>
<p>(4). 特征编码</p>
<p>iDT中，先进行了一次PCA降维，再进行Fisher Vector编码。PCA的介绍比较多在此不详细展开。Fisher特征即用似然函数的梯度向量来表达。首先各个维度的分布看成独立同分布高斯分布，则图像上的概率分布就是各个特征维度概率分布的乘积，其次对这个乘积(或是取对数后的和)对权重、均值、方差求偏导，再次，用Fisher matrix进行归一化，最后得出融合后的特征数。如果输入特征有d维，用k个高斯分布去拟合，则输出特征有(2<em>d+1)</em>k-1维。通常使用机器学习中的EM来求解GMM的各项参数。论文参见《Image Classification with the Fisher Vector: Theory and Practice》。</p>
<p>iDT中，原始维度d=426(30+96+108+192)，PCA后降为1/2，输入维度d=213，k=256，输出维度为109311.</p>
<p>(5). 特征分类</p>
<p>使用RBF-SVM进行分类。</p>
<p>one-versus-all即训练时依次把某个类别的样本归为一类,其他剩余的样本归为另一类，k个类别的样本就构造出了k个SVM。</p>
<p>该算法代码为<a href="https://link.zhihu.com/?target=http%3A//lear.inrialpes.fr/people/wang/dense_trajectories">http://lear.inrialpes.fr/people/wang/dense_trajectories</a></p>
<p>(6). 结论</p>
<p><img src="https://perfectism13.github.io/2019/12/05/%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB%E4%B8%8E%E5%88%86%E7%B1%BB/v2-1c6a850848f44f2ba3f9d3772b36723b_hd.jpg" alt="img">图15 iDT各特征描述子和不同光流运算方式结合的准确率对比</p>
<p><img src="https://perfectism13.github.io/2019/12/05/%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB%E4%B8%8E%E5%88%86%E7%B1%BB/v2-00111eeecd61b9ffde93ff06e2617916_hd.jpg" alt="img">图16 iDT不同特征融合方式准确率对比</p>
<p>iDT所选的特征描述子以及它们的组合，结合各种不同光流运算方式在四大数据集中的分类准确率表明，将所有特征描述子都用上，并且去除掉背景轨迹的光流结合方式，最终分类准确率最高。在特征融合上Fisher vector+iDT比BoF\FV+DT\iDT的其他组合都要优异。</p>
<h2 id="图像分类的深度学习方法"><a href="#图像分类的深度学习方法" class="headerlink" title="图像分类的深度学习方法"></a>图像分类的深度学习方法</h2><p>深度学习网络本质上就是自动编码器、受限玻尔兹曼机、深度置信网络、卷积神经网络、循环神经网络、对抗生成网络这些网络以及它们的组合、变体或演进网络。</p>
<p>ResNet-152已经以3.5%的错误率超越了人类视觉5.1%的错误率.CNN加以利用仅仅是2维空间的特征提取与分类，在时间方面的特征如何提取并与空间特征进行融合，根据这些不同的问题解决思路可以清晰的分成了三个流派分支，分别是two-stream(双流)方法，C3D方法(三维卷积核法)以及CNN-LSTM方法(卷积循环神经网络)</p>
<p><img src="https://perfectism13.github.io/2019/12/05/%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB%E4%B8%8E%E5%88%86%E7%B1%BB/v2-b7b5591415d249e7d1c219f46a532e82_hd.jpg" alt="img"></p>
<h3 id="深度学习方法具体流程"><a href="#深度学习方法具体流程" class="headerlink" title="深度学习方法具体流程"></a>深度学习方法具体流程</h3><p><img src="https://perfectism13.github.io/2019/12/05/%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB%E4%B8%8E%E5%88%86%E7%B1%BB/v2-ca3dac97b3ae014f88c969ad7bbe1f80_hd.jpg" alt="img"></p>
<h4 id="数据载入和数据预处理"><a href="#数据载入和数据预处理" class="headerlink" title="数据载入和数据预处理"></a>数据载入和数据预处理</h4><p><strong>数据载入</strong>包括将数据集划分为training set、validate set与test set，并将数据打乱次序，设置数据并行方式。</p>
<p>验证集与训练集不必分开，但测试集需要完全分开</p>
<p><strong>并行计算</strong>：单核CPU的SIMD、多核CPU的多线程、多GPU、多主机等各种方式</p>
<p>瓶颈：指令集版本、CPU核数于主频、PCIe带宽以及网络开销</p>
<p>数据并行：将一个mini batch的数据放在不同设备上进行计算，实现梯度计算的并行化</p>
<p>模型并行：将一个神经网络的不同部分放在不同设备上进行计算，从而减少每一轮训练迭代的时间，不过对神经网络不同区域间的依赖程度有所要求</p>
<p><strong>数据预处理</strong>：归一化、中心化、白化、数据增强（扩张）</p>
<p>归一化：不必进行归一化(像素尺度范围一致)</p>
<p>中心化：改变数据的分布中心</p>
<p>白化：使每一层的输出规范到<code>0~1</code>,改变数据的分布范围</p>
<p>数据增强：</p>
<ul>
<li><p>翻转(Flip)</p>
</li>
<li><p>颜色变换(Color Jittering)：可以改变HSV色彩空间的对比度，或RGB经过PCA之后主分量进行随机因子调整，或对每个RGB像素进行盐噪声/高斯噪声扰动</p>
</li>
<li><p>随机剪裁/缩放/平移(Random Crops/Scale/Shfit)</p>
<p><img src="https://perfectism13.github.io/2019/12/05/%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB%E4%B8%8E%E5%88%86%E7%B1%BB/v2-d77ebeb3e1dbacdd4ead48410790209f_hd.jpg" alt="img"></p>
</li>
</ul>
<p><img src="https://perfectism13.github.io/2019/12/05/%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB%E4%B8%8E%E5%88%86%E7%B1%BB/v2-96d1f36ed4dcf167387dde11368f7f5d_hd.jpg" alt="img"></p>
<p><img src="https://perfectism13.github.io/2019/12/05/%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB%E4%B8%8E%E5%88%86%E7%B1%BB/v2-1c1780b115e54914babd614263e870eb_hd.jpg" alt="img"></p>
<h4 id="网络构建"><a href="#网络构建" class="headerlink" title="网络构建"></a>网络构建</h4><p>网络设计、网络参数初始化及防止过拟合设计</p>
<p><strong>网络设计</strong>：考虑因素：</p>
<ul>
<li>需要几层卷积层、池化层、正规化层和全连接层</li>
<li>每一个卷积层的卷积核尺寸、步长、个数是多少</li>
<li>每一个池化层的尺寸、步长是多少，池化层是平均池化还是最大池化，是否允许有重叠</li>
<li>在哪些层之后做正则化，全连接层维度是多少</li>
<li>全连接层维度是多少，数据在每层之间流转的张量各个维度分别是多少，是否需要网中网，是否需要1x1的卷积核进行降维等等</li>
</ul>
<p>对于视频识别来说，主要研究精力在于如何添加时间维度并实现于网络之中，故对于基础卷积神经网络的设计一般会沿用经典图像识别网络设计，如VGG、GoogLeNet和ResNet，网络设计中的参数皆为超参数，不随着训练而发生改变</p>
<p><strong>网络参数初始化及与训练</strong>：可以小随机数初始化，如果要对方差大小进行规范化可以采用<a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/victoriaw/article/details/73000632">Xavier初始化</a>或<a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/VictoriaW/article/details/73166752">Kaming初始化</a>，也可以将之前的模型训练结果(pre-trained models，或称为模型载入)进行初始化</p>
<p><strong>防止过拟合设计</strong>：增强模型的泛化能力，即需要进行正则化(regularization)和随机失活(dropout)</p>
<h4 id="分类函数与loss定义"><a href="#分类函数与loss定义" class="headerlink" title="分类函数与loss定义"></a>分类函数与loss定义</h4><p><strong>分类函数</strong>由回归函数定义，常见的回归函数有一维线性回归、多维线性回归、多项式回归、Logistic回归、Softmax回归。行为识别属于多标签分类，对于多标签来说最常用的就是Softmax回归，原理是处理多分类任务时将可以判定为某类的特征进行相加，然后将特征转化为判定。</p>
<p><strong>Loss</strong>：MSE、合页损失函数(hinge loss)和交叉熵函数(cross entropy loss)</p>
<p>对于Softmax回归最常用的Loss即是交叉熵函数，它是真实的概率分布One-hot编码后取对数再乘以预测的概率分布求和取反。</p>
<h4 id="优化器定义"><a href="#优化器定义" class="headerlink" title="优化器定义"></a>优化器定义</h4><p>SGD(随机梯度下降)、SGD+Momentum(动量)、SGD+Nesterov Momentum(牛顿型动量)、Adagrad(自适应学习率)、Adadelta、RMSProp、Adam。</p>
<p>一般用Adam来作为默认的优化算法。初始的学习率一般为0.01或0.001，在训练过程中学习率的调整可以按照固<strong>定次减缓、指数减缓、分数减缓</strong>来进行。</p>
<h4 id="训练与验证过程"><a href="#训练与验证过程" class="headerlink" title="训练与验证过程"></a>训练与验证过程</h4><p>通过不断迭代，以mini-batch为单位将数据喂给模型，同时计算梯度，更新学习参数，返回本次的accuracy和loss。</p>
<p>在每个epoch每次批处理(mini-batch)训练后在该训练集和验证集上分别作网络前向运算，预测训练集和验证集样本标记(label)，返回本次的accuracy和loss，绘制学习曲线来检验模型泛化能力。</p>
<p>每个epoch训练前将数据集随机打乱来确保不同回合喂给模型的数据是不同的；每隔一段时间存储模型参数，以免crash从头训练</p>
<p>模型微调：可将训练好的模型带入网络进行初始化，选择一个较小的学习率，甚至可以不同层设置不同的学习率微调整个网络模型。</p>
<h4 id="测试阶段"><a href="#测试阶段" class="headerlink" title="测试阶段"></a>测试阶段</h4><p>只是前向计算没有训练收敛过程，故对于同一个样本输入，输出结果也应该一致。最后，可通过正负样本、Top-1/5或混淆矩阵多种方式表示准确率。</p>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p><img src="https://perfectism13.github.io/2019/12/05/%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB%E4%B8%8E%E5%88%86%E7%B1%BB/20190926211248102.png" alt="动作识别与分类"></p>
<p>方法：</p>
<p>人体图像分割</p>
<p>人体骨骼关键点检测</p>
<p>人体姿态估计</p>
<p>纯粹的图像（动作）分类</p>
<p>光流法</p>
<p>动作的识别最终就能转变成<strong>特征提取、分类</strong>两个主要过程</p>
<p>特征提取包含<strong>静态帧的特征，动态帧间的特征</strong>。</p>
<h2 id="动作识别实现"><a href="#动作识别实现" class="headerlink" title="动作识别实现"></a>动作识别实现</h2><p>视频逐帧分析，采用连续的动作识别出人物动作，如走路、跑步、蹲下等。在计算机视觉中人机交互中有很大的应用，主要处理模型大概分为两个大类：卷积神经网络（3D-CNN）、基于循环神经网络与其扩展模型（CNN + LSTM）</p>
<p>要识别出人物的动作通常需要连续的视频数据进行分析处理，需要采集的特征通常有单帧图像数据的特征和多帧图像数据之间时间上的特征，简单来说就是静态帧数据+帧间数据。</p>
<p>a、静态帧数据，表示单帧图像空间信息</p>
<p>b、帧间数据，表示时间信息（光流数据）</p>
<p>常用的数据集有：KTH、Weizmaan、HOHA、Keck Gesture、MSR action、YouTube Action、UT-Interaction等等。</p>
<p>从目标分析的角度上看，动作识别也能看作是分类的问题，每个动作就是一类，如果有二十个动作就是二十类。那么动作的识别最终就能转变成特征提取、分类两个主要过程。特征提取包含静态帧的特征，动态帧间的特征。算法在不断的迭代发展，产生了很多经典的处理模型、算法。一般的识别流程为：</p>
<p><img src="https://perfectism13.github.io/2019/12/05/%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB%E4%B8%8E%E5%88%86%E7%B1%BB/640.webp" alt="img"></p>
<h1 id="传统有监督特征提取方法"><a href="#传统有监督特征提取方法" class="headerlink" title="传统有监督特征提取方法"></a>传统有监督特征提取方法</h1><p>时空关键点，密集轨迹方法</p>
<h2 id="学习过程"><a href="#学习过程" class="headerlink" title="学习过程"></a>学习过程</h2><p>恰巧我也算是没人带在看这方面的事情，如果基于深度学习的话，你不妨先了解神经网络-&gt;卷积-&gt;循环神经网络。 了解一些通用的众人皆知的卷积神经网络（CNN）之后（如lenet5，alexnet，resnet，googlenet等），再去了解动作识别用神经网络如何去做，通常分为（静态、动态）。静态的话CNN基本可以完成，动态的话，你需要去了解双流结构，Two-Stream Convolutional Networks for Action Recognition in Videos.pdf，去了解3D卷积神经网络（搜索3D convolution for action recognition, C3D network）。 接下来，你可以去了解是否需要加入RNN的模块来帮助构造模型更好的去解析时序类的数据，看一些LSTM+action recognition的论文，在接下来，你可以看看目前火热的Attention机制，</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol>
<li><a href="https://zhuanlan.zhihu.com/p/44420871" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/44420871</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/45444790" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/45444790</a></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/24/VS2013+OpenCV4.2.0%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chenyang Min">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="perfectism's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/07/24/VS2013+OpenCV4.2.0%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/" class="post-title-link" itemprop="url">VS2013+OpenCV4.2.0安装与配置</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-24 13:10:01" itemprop="dateCreated datePublished" datetime="2020-07-24T13:10:01+08:00">2020-07-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-06-02 20:36:56" itemprop="dateModified" datetime="2020-06-02T20:36:56+08:00">2020-06-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="VS2013-OpenCV4-2-0安装与配置"><a href="#VS2013-OpenCV4-2-0安装与配置" class="headerlink" title="VS2013+OpenCV4.2.0安装与配置"></a>VS2013+OpenCV4.2.0安装与配置</h1><h2 id="VS2013"><a href="#VS2013" class="headerlink" title="VS2013"></a>VS2013</h2><p>下载链接：ed2k://|file|cn_visual_studio_ultimate_2013_with_update_5_x86_dvd_6816649.iso|5567336448|641555AD6472A98923B29CC5E371461E|/</p>
<p>安装教程：<a href="https://mp.weixin.qq.com/s/2Luj8FxXY6wYY2nhDe4SGw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/2Luj8FxXY6wYY2nhDe4SGw</a></p>
<p>密匙：BWG7X-J98B3-W34RT-33B3R-JVYW9</p>
<h2 id="OpenCV4-2-0"><a href="#OpenCV4-2-0" class="headerlink" title="OpenCV4.2.0"></a>OpenCV4.2.0</h2><p>下载链接：<a href="https://opencv.org/releases/" target="_blank" rel="noopener">https://opencv.org/releases/</a></p>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p><a href="https://blog.csdn.net/qq_32717603/article/details/89234512" target="_blank" rel="noopener">https://blog.csdn.net/qq_32717603/article/details/89234512</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/24/Tricks%20of%20Training%20Deep%20Neural%20Works/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chenyang Min">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="perfectism's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/07/24/Tricks%20of%20Training%20Deep%20Neural%20Works/" class="post-title-link" itemprop="url">Tricks of Training Deep Neural Works</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-24 13:10:01" itemprop="dateCreated datePublished" datetime="2020-07-24T13:10:01+08:00">2020-07-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-31 10:28:09" itemprop="dateModified" datetime="2020-03-31T10:28:09+08:00">2020-03-31</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Tricks-of-Training-Deep-Neural-Works"><a href="#Tricks-of-Training-Deep-Neural-Works" class="headerlink" title="Tricks of Training Deep Neural Works"></a>Tricks of Training Deep Neural Works</h1><h2 id="Overfitting"><a href="#Overfitting" class="headerlink" title="Overfitting"></a>Overfitting</h2><p>训练数据包含<strong>抽样误差</strong>，训练时，复杂的模型将抽样误差也考虑在内，将抽样误差也进行了很好的拟合。最终模型在训练集上效果好；在测试集上效果差。模型泛化能力弱</p>
<p><img src="https://perfectism13.github.io/2020/02/13/Tricks%20of%20Training%20Deep%20Neural%20Works/v2-953f6e7ce85ac1856764572e1c855705_hd.jpg" alt="img"></p>
<p>过拟合的表现：</p>
<ul>
<li>train loss不断下降，test loss趋于不变</li>
<li>训练集和测试集准确率相差过大 15%以上</li>
</ul>
<h3 id="减少模型的复杂程度（容量）"><a href="#减少模型的复杂程度（容量）" class="headerlink" title="减少模型的复杂程度（容量）"></a>减少模型的复杂程度（容量）</h3><p><strong>L2正则化</strong></p>
<p><strong>Dropout</strong>：提高dropout的rate</p>
<p><strong>减少预训练的锁定层数</strong></p>
<h3 id="更多的数据"><a href="#更多的数据" class="headerlink" title="更多的数据"></a>更多的数据</h3><p>让模型感受更多的数据，逼迫模型泛化</p>
<p><strong>数据增强</strong></p>
<p><strong>采集更多的数据</strong></p>
<p><strong>查看数据集的分割是否合适</strong></p>
<h3 id="学习率的调整"><a href="#学习率的调整" class="headerlink" title="学习率的调整"></a>学习率的调整</h3><p>trick是 <strong>warm up（热身），就是先采用小的学习率（0.01）进行训练，</strong>训练了400iterations之后将学习率调整至0.1开始正式训练</p>
<p>在学习遇到瓶颈，即训练和验证损失均趋于不变时，适当调小batch_size,用更细的笔来画画</p>
<h3 id="进行交叉验证"><a href="#进行交叉验证" class="headerlink" title="进行交叉验证"></a>进行交叉验证</h3><p>当数据集比较小的时候，交叉验证可以“充分利用”有限的数据找到合适的模型参数，防止过度拟合</p>
<p>做法：就是把样本集S分成k份，分别使用其中的(k-1)份作为训练集，剩下的1份作为交叉验证集，最后取最后的平均误差，来评估这个模型</p>
<p>最后对k个模型的结果取平均</p>
<h3 id="Early-Stopping"><a href="#Early-Stopping" class="headerlink" title="Early Stopping"></a>Early Stopping</h3><h2 id="Owe-fitting"><a href="#Owe-fitting" class="headerlink" title="Owe fitting"></a>Owe fitting</h2><p>若准确率很低，检查数据和标签的对应关系，或者损失函数是否导致无法梯度下降</p>
<p>1、观察数据中是否有异常样本或异常label导致数据读取异常<br>2、调小初始化权重，以便使softmax输入的feature尽可能变小<br>3、降低学习率，这样就能减小权重参数的波动范围，从而减小权重变大的可能性。这条也是网上出现较多的方法。</p>
<p>4、调大batch_size<br>5、如果有BN（batch normalization）层，finetune时最好不要冻结BN的参数，否则数据分布不一致时很容易使输出值变的很大。</p>
<p>6、神经网络不够深。</p>
<p>7、训练的epoch不够。</p>
<h2 id="训练和验证集loss相差不大，验证集准确率为1或者0"><a href="#训练和验证集loss相差不大，验证集准确率为1或者0" class="headerlink" title="训练和验证集loss相差不大，验证集准确率为1或者0"></a>训练和验证集loss相差不大，验证集准确率为1或者0</h2><h2 id="检查数据集是否存在inf或者NaN"><a href="#检查数据集是否存在inf或者NaN" class="headerlink" title="检查数据集是否存在inf或者NaN"></a>检查数据集是否存在inf或者NaN</h2><h2 id="有时在第一代打乱数据，后续不再打乱，可能会有意想不到的好结果"><a href="#有时在第一代打乱数据，后续不再打乱，可能会有意想不到的好结果" class="headerlink" title="有时在第一代打乱数据，后续不再打乱，可能会有意想不到的好结果"></a><strong>有时在第一代打乱数据，后续不再打乱，可能会有意想不到的好结果</strong></h2><h2 id="References"><a href="#References" class="headerlink" title="References"></a><strong>Referenc</strong>es</h2>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/24/PyTorch%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chenyang Min">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="perfectism's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/07/24/PyTorch%E7%AC%94%E8%AE%B0/" class="post-title-link" itemprop="url">PyTorch笔记</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-24 13:10:01" itemprop="dateCreated datePublished" datetime="2020-07-24T13:10:01+08:00">2020-07-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-16 21:45:02" itemprop="dateModified" datetime="2020-03-16T21:45:02+08:00">2020-03-16</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="PyTorch笔记"><a href="#PyTorch笔记" class="headerlink" title="PyTorch笔记"></a>PyTorch笔记</h1><p>PyTorch 1.3.0</p>
<h2 id="数据类型Tensor"><a href="#数据类型Tensor" class="headerlink" title="数据类型Tensor"></a>数据类型Tensor</h2><h3 id="浮点型、整型"><a href="#浮点型、整型" class="headerlink" title="浮点型、整型"></a>浮点型、整型</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">a &#x3D; torch.FloatTensor(2,3) #按照指定维度随机生成浮点型tensor</span><br><span class="line">b &#x3D; torch.FloatTensor([2,3,4,5]) #按照给定列表生成浮点型tensor</span><br><span class="line">a &#x3D; torch.IntTensor(2,3) #整型同上</span><br><span class="line">b &#x3D; torch.IntTensor([2,3,4,5])</span><br></pre></td></tr></table></figure>
<h3 id="数据生成"><a href="#数据生成" class="headerlink" title="数据生成"></a>数据生成</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a &#x3D; torch.rand(2,3) #生成0到1之间的随机浮点型tensor</span><br><span class="line">a &#x3D; torch.randn(2,3) #生成0到1之间的随机浮点型tensor，满足均值为0，方差为1</span><br><span class="line">a &#x3D; torch.arange(1,20,1) #生成一个等差数组，输入为起始值、结束值、步长</span><br><span class="line">a &#x3D; torch.zeros(2,3) #生成全0 tesnor</span><br><span class="line">x &#x3D; torch.zeros(5, 3, dtype&#x3D;torch.long)</span><br><span class="line">x &#x3D; torch.empty(5, 3) #创建一个5x3的未初始化的Tensor</span><br><span class="line">print(x.size()) #获取tensor的形状，torch.size为一个tuple</span><br><span class="line">print(x.shape)</span><br></pre></td></tr></table></figure>
<h2 id="tensor运算"><a href="#tensor运算" class="headerlink" title="tensor运算"></a>tensor运算</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">b &#x3D; torch.abs(a) #取绝对值</span><br><span class="line">c &#x3D; torch.add(a,b) #两tensor相加</span><br><span class="line">e &#x3D; torch.add(c,10) #tensor与scalar相加</span><br><span class="line">b &#x3D; torch.clamp(a, -0.1, 0.1) #以-0.1为下边界，0.1为上边界将a截断</span><br><span class="line">c &#x3D; torch.div(a,b) #两tensor的元素相除。a&#x2F;b</span><br><span class="line">e &#x3D; torch.div(d,10) #tensor与scalar相除</span><br><span class="line">c &#x3D; torch.mul(a,b) #两tensor的元素求积，同上</span><br><span class="line">e &#x3D; torch.mul(d,10)</span><br><span class="line">b &#x3D; torch.pow(a, 2) #tesnor元素指数运算</span><br><span class="line">c &#x3D; torch.mm(a, b) #两tenssor进行矩阵乘法运算</span><br><span class="line">c &#x3D; torch.mv(a, b) #a tensor与b向量乘积</span><br></pre></td></tr></table></figure>
<h2 id="第一个神经网络"><a href="#第一个神经网络" class="headerlink" title="第一个神经网络"></a>第一个神经网络</h2><p>【输入层100x1000】x【权重w1矩阵1000x100】= 【隐藏层输出100x100】</p>
<p>【隐藏层输出100x100】x 【权重w2矩阵100x10】= 【输出层输出100x10】</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">batch_n &#x3D; 100</span><br><span class="line">hidden_layer &#x3D; 100</span><br><span class="line">input_data &#x3D; 1000</span><br><span class="line">output_data &#x3D; 10</span><br><span class="line"></span><br><span class="line">x &#x3D; torch.randn(batch_n, input_data)</span><br><span class="line">y &#x3D; torch.randn(batch_n, output_data)</span><br><span class="line">w1 &#x3D; torch.randn(input_data, hidden_layer)</span><br><span class="line">w2 &#x3D; torch.randn(hidden_layer, output_data)</span><br><span class="line"></span><br><span class="line">epoch_n &#x3D; 30</span><br><span class="line">learning_rate &#x3D; 1e-6</span><br><span class="line"></span><br><span class="line">for epoch in range(epoch_n):</span><br><span class="line">    h1 &#x3D; x.mm(w1) #100*1000</span><br><span class="line">    h1 &#x3D; h1.clamp(min &#x3D; 0) #加上ReLU激活函数</span><br><span class="line">    y_pred &#x3D; h1.mm(w2) #100*10</span><br><span class="line">    loss &#x3D; (y_pred - y).pow(2).sum()</span><br><span class="line">    print(&quot;Epoch:&#123;&#125;, Loss:&#123;:.4f&#125;&quot;.format(epoch,loss))</span><br><span class="line">    grad_y_pred &#x3D; 2*(y_pred - y)</span><br><span class="line">    grad_w2 &#x3D; h1.t().mm(grad_y_pred) #链式求导</span><br><span class="line">    grad_h &#x3D; grad_y_pred.clone()</span><br><span class="line">    grad_h &#x3D; grad_h.mm(w2.t())</span><br><span class="line">    grad_h.clamp_(min&#x3D;0)</span><br><span class="line">    grad_w1 &#x3D; x.t().mm(grad_h)</span><br><span class="line">    w1 -&#x3D; learning_rate*grad_w1</span><br><span class="line">    w2 -&#x3D; learning_rate*grad_w2</span><br></pre></td></tr></table></figure>
<p>w1=h1,h1w2=ypw1=h1,h1w2=yp</p>
<p>∂L∂w2=∂(yp−y)2∂ypypw2=2(y2−y)[h1]T∂L∂w2=∂(yp−y)2∂ypypw2=2(y2−y)[h1]T</p>
<p>通过前向传播和后向传播实现了对模型的训练和对权重参数的优化</p>
<h2 id="自动梯度"><a href="#自动梯度" class="headerlink" title="自动梯度"></a>自动梯度</h2><h3 id="autograd与自定义传播函数"><a href="#autograd与自定义传播函数" class="headerlink" title="autograd与自定义传播函数"></a>autograd与自定义传播函数</h3><p>计算图：每一个节点表示一个变量，变量可以是任何类型，只是将计算形式化为图形的方法之一</p>
<p>操作：一个或多个变量的简单函数</p>
<p>解决∂L/∂W∂L/∂W的复杂链式求解问题，<strong>最新版已不需要使用<code>torch.autograd</code>包中的<code>Variabale</code>类对输入的tensor数据进行封装</strong>。用X 来代表我们选中的节点，那么<code>X.data</code>代表Tensor 数据类型的变量， <code>X.grad</code>也是一个Variable 对象，不过它表示的是X 的梯度，访问梯度值时需要使用<code>X.grad.data</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">#from torch.autograd import Variable</span><br><span class="line">batch_n &#x3D; 100</span><br><span class="line">hidden_layer &#x3D; 100</span><br><span class="line">input_data &#x3D; 1000</span><br><span class="line">output_data &#x3D; 10</span><br><span class="line"></span><br><span class="line">class Model(torch.nn.Module): #继承torch.nn.Module类</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Model, self).__init__()</span><br><span class="line">    </span><br><span class="line">    def forward(self, input, w1, w2): #实现前向传播的矩阵运算</span><br><span class="line">        x &#x3D; torch.mm(input, w1)</span><br><span class="line">        x &#x3D; torch.clamp(x, min &#x3D; 0)</span><br><span class="line">        x &#x3D;torch.mm(x, w2)</span><br><span class="line">        return x</span><br><span class="line">    </span><br><span class="line">    def backward(self): #实现后向传播的自动梯度计算</span><br><span class="line">        pass</span><br><span class="line">    </span><br><span class="line">model &#x3D; Model()</span><br><span class="line"></span><br><span class="line">#x &#x3D; Variable(torch.randn(batch_n, input_data), requires_grad &#x3D; False)</span><br><span class="line">#y &#x3D; Variable(torch.randn(batch_n, output_data), requires_grad &#x3D; False)</span><br><span class="line">x &#x3D; torch.randn((batch_n, input_data), requires_grad &#x3D; False) #autograd不会保留梯度值</span><br><span class="line">y &#x3D; torch.randn((batch_n, output_data), requires_grad &#x3D; False)</span><br><span class="line"></span><br><span class="line">#w1 &#x3D; Variable(torch.randn(input_data, hidden_layer), requires_grad &#x3D; True)</span><br><span class="line">#w2 &#x3D; Variable(torch.randn(hidden_layer, output_data), requires_grad &#x3D; True)</span><br><span class="line">w1 &#x3D; torch.randn((input_data, hidden_layer), requires_grad &#x3D; True) #autograd保留梯度值</span><br><span class="line">w2 &#x3D; torch.randn((hidden_layer, output_data), requires_grad &#x3D; True)</span><br><span class="line"></span><br><span class="line">epoch_n &#x3D; 20</span><br><span class="line">learning_rate &#x3D; 1e-6</span><br><span class="line"></span><br><span class="line">for epoch in range(epoch_n):</span><br><span class="line">    #y_pred &#x3D; model(x,w1,w2) #完成神经网络的搭建</span><br><span class="line">    y_pred &#x3D; x.mm(w1).clamp(min &#x3D; 0).mm(w2)</span><br><span class="line">    loss &#x3D; (y_pred - y).pow(2).sum()</span><br><span class="line">    print(&quot;Epoch:&#123;&#125;, Loss:&#123;:.4f&#125;&quot;.format(epoch,loss.data))</span><br><span class="line">    </span><br><span class="line">    loss.backward() #根据设定求loss对各计算节点的梯度</span><br><span class="line">    </span><br><span class="line">    w1.data -&#x3D; learning_rate*w1.grad.data</span><br><span class="line">    w2.data -&#x3D; learning_rate*w2.grad.data</span><br><span class="line">    </span><br><span class="line">    w1.grad.data.zero_() #将梯度清零，否则计算的梯度会累加</span><br><span class="line">    w2.grad.data.zero_()</span><br></pre></td></tr></table></figure>
<p><img src="https://perfectism13.github.io/2019/11/23/PyTorch%E7%AC%94%E8%AE%B0/1.png" alt="image-20191124170522501"></p>
<h2 id="模型搭建和参数优化"><a href="#模型搭建和参数优化" class="headerlink" title="模型搭建和参数优化"></a>模型搭建和参数优化</h2><h3 id="torch-nn"><a href="#torch-nn" class="headerlink" title="torch.nn"></a>torch.nn</h3><p>torch.nn 包提供了很多与实现神经网络中的具体功能相关的类,比如神经网络中的卷积层、池化层、全连接层这类层次构造的方法、防止过拟合的参数归一化方法、Dropout 方法，还有激活函数部分的线性激活函数、非线性激活函数相关的方法等</p>
<p>实现自动前向传播、后向传播、生成权重和偏置、损失函数的自动计算。</p>
<h4 id="torch-nn中模型搭建的常用类"><a href="#torch-nn中模型搭建的常用类" class="headerlink" title="torch.nn中模型搭建的常用类"></a>torch.nn中模型搭建的常用类</h4><p>1.<code>torch.nn.Sequential</code></p>
<p>一种序列容器，通过在容器中嵌套各种实现神经网络中具体功能相关的类，来完成对神经网络模型的搭建</p>
<p>模块加入的两种方式：1.按照代码顺序直接嵌套，默认使用从零开始的数字序列作为每个模块的名字。2.以<code>orderdict</code>有序字典的方式传入，模型的每个模块都有我们自定义的名字</p>
<p>2.<code>torch.nn.Linear</code></p>
<p>输入：输入特征数、输出特征数、是否使用偏置，一般输入前两个会自动生成权重参数和偏置.</p>
<p>3.<code>torch.nn.ReLU</code>非线性激活函数类，<code>Sigmoid</code>,<code>Softmax</code>,<code>PReLU</code>,<code>LeakyRLU</code>,<code>Tanh</code>等</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">hidden_layer &#x3D; 100</span><br><span class="line">input_data &#x3D; 1000</span><br><span class="line">output_data &#x3D; 10</span><br><span class="line">#按照代码顺序直接嵌套</span><br><span class="line">models &#x3D; torch.nn.Sequential(</span><br><span class="line">torch.nn.Linear(input_data, hidden_layer),</span><br><span class="line">torch.nn.ReLU(),</span><br><span class="line">torch.nn.Linear(hidden_layer, output_data)</span><br><span class="line">)</span><br><span class="line">#以有序字典的方式传入</span><br><span class="line">from collections import OrderedDict</span><br><span class="line">models &#x3D; torch.nn.Sequential(OrderedDict([</span><br><span class="line">(&quot;Line1&quot;,torch.nn.Linear(input_data, hidden_layer)),</span><br><span class="line">(&quot;Relu1&quot;,torch.nn.ReLU()),</span><br><span class="line">(&quot;Line2&quot;,torch.nn.Linear(hidden_layer, output_data))])</span><br><span class="line">)</span><br><span class="line">print(models)</span><br></pre></td></tr></table></figure>
<h4 id="torch-nn中损失函数计算的常用类"><a href="#torch-nn中损失函数计算的常用类" class="headerlink" title="torch.nn中损失函数计算的常用类"></a>torch.nn中损失函数计算的常用类</h4><p>1.<code>torch.nn.MSELoss</code>均方误差函数，Mean Square Error，预测值与真实值之差的平方的期望值</p>
<p><code>torch.nn.L1Loss</code>平均绝对误差函数，预测值与真实值之差的绝对值的平均值</p>
<p><code>torch.nn.CrossEntropyLoss</code>交叉熵</p>
<p>C=−1n∑x∑j[yjlnaLj+(1−yj)ln(1−aLj)]C=−1n∑x∑j[yjln⁡ajL+(1−yj)ln⁡(1−ajL)]</p>
<p>其中aa是输出，yy是真实的标签</p>
<h4 id="使用torch-nn搭建模型"><a href="#使用torch-nn搭建模型" class="headerlink" title="使用torch.nn搭建模型"></a>使用torch.nn搭建模型</h4><p>通过对<code>models.parameters()</code>的遍历来实现每个参数的更新</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">#from torch.autograd import Variable</span><br><span class="line">batch_n &#x3D; 100</span><br><span class="line">hidden_layer &#x3D; 100</span><br><span class="line">input_data &#x3D; 1000</span><br><span class="line">output_data &#x3D; 10</span><br><span class="line">x &#x3D; torch.randn((batch_n, input_data), requires_grad &#x3D; False)</span><br><span class="line">#x &#x3D; Variable(torch.randn(batch_n, input_data), requires_grad &#x3D; False)</span><br><span class="line">y &#x3D; Variable(torch.randn(batch_n, output_data), requires_grad &#x3D; False)</span><br><span class="line"></span><br><span class="line">models &#x3D; torch.nn.Sequential(</span><br><span class="line">torch.nn.Linear(input_data, hidden_layer),</span><br><span class="line">torch.nn.ReLU(),</span><br><span class="line">torch.nn.Linear(hidden_layer, output_data)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">epoch_n &#x3D; 10000</span><br><span class="line">learning_rate &#x3D; 1e-4</span><br><span class="line">loss_fn &#x3D; torch.nn.MSELoss()</span><br><span class="line"></span><br><span class="line">for epoch in range(epoch_n):</span><br><span class="line">    y_pred &#x3D; models(x)</span><br><span class="line">    loss &#x3D; loss_fn(y_pred, y)</span><br><span class="line">    if epoch%1000 &#x3D;&#x3D; 0:</span><br><span class="line">        print(&quot;Epoch:&#123;&#125;, Loss:&#123;:.4f&#125;&quot;.format(epoch,loss.data))</span><br><span class="line">    models.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    for param in models.parameters():</span><br><span class="line">        param.data -&#x3D; param.grad.data*learning_rate</span><br></pre></td></tr></table></figure>
<h3 id="参数自动优化—torch-optim"><a href="#参数自动优化—torch-optim" class="headerlink" title="参数自动优化—torch.optim"></a>参数自动优化—torch.optim</h3><p>固定的学习速率—参数优化更新没有自动化导致的问题，学习率是难以设置的超参数之一</p>
<p>解决方案：1.动量算法—引入另一超参数</p>
<p> 2.自适应学习率算法：SGD、AdaGrad、RMSProp、Adam等</p>
<p> 3.二阶近似算法</p>
<p> 4.元算法</p>
<p><code>torch.optim.Adam</code>类的输入:被优化的参数、学习速率的初始值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line">batch_n &#x3D; 100</span><br><span class="line">hidden_layer &#x3D; 100</span><br><span class="line">input_data &#x3D; 1000</span><br><span class="line">output_data &#x3D; 10</span><br><span class="line"></span><br><span class="line">x &#x3D; torch.randn((batch_n, input_data), requires_grad &#x3D; False)</span><br><span class="line">y &#x3D; torch.randn((batch_n, output_data), requires_grad&#x3D;False)</span><br><span class="line"></span><br><span class="line">models &#x3D; torch.nn.Sequential(</span><br><span class="line">torch.nn.Linear(input_data, hidden_layer), #w1</span><br><span class="line">torch.nn.ReLU(), #激活函数</span><br><span class="line">torch.nn.Linear(hidden_layer, output_data) #w2</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">epoch_n &#x3D; 300</span><br><span class="line">learning_rate &#x3D; 1e-4</span><br><span class="line">loss_fn &#x3D; torch.nn.MSELoss() #损失函数计算</span><br><span class="line">optimzer &#x3D; torch.optim.Adam(models.parameters(), lr &#x3D; learning_rate) #定义学习速率自动调节类</span><br><span class="line"></span><br><span class="line">for epoch in range(epoch_n):</span><br><span class="line">    y_pred &#x3D; models(x)</span><br><span class="line">    loss &#x3D; loss_fn(y_pred, y)</span><br><span class="line">    print(&quot;Epoch:&#123;&#125;, Loss:&#123;:.4f&#125;&quot;.format(epoch,loss.data))</span><br><span class="line">    optimzer.zero_grad() #参数梯度归零</span><br><span class="line">    loss.backward() #自动求解梯度</span><br><span class="line">    optimzer.step() #各个参数进行梯度更新</span><br></pre></td></tr></table></figure>
<h2 id="向计算机视觉出击—MNIST"><a href="#向计算机视觉出击—MNIST" class="headerlink" title="向计算机视觉出击—MNIST"></a>向计算机视觉出击—MNIST</h2><p><code>torchvision</code>包可以实现数据的处理、导入和预览</p>
<h3 id="torchvision-datasets—数据集的准备"><a href="#torchvision-datasets—数据集的准备" class="headerlink" title="torchvision.datasets—数据集的准备"></a>torchvision.datasets—数据集的准备</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">transform&#x3D;transforms.Compose([transforms.ToTensor(),</span><br><span class="line">                              transforms.Normalize(mean&#x3D;[0.5],std&#x3D;[0.5])])</span><br><span class="line"></span><br><span class="line">data_train &#x3D; datasets.MNIST(root &#x3D; &quot;D:&#x2F;learning program&#x2F;source_data_MNIST&#x2F;&quot;,</span><br><span class="line">                            transform&#x3D;transform, #需提前定义对于数据的变换操作</span><br><span class="line">                            train &#x3D; True, #设置为true表示训练集，设置为false表示测试集</span><br><span class="line">                            download &#x3D; True)</span><br><span class="line"></span><br><span class="line">data_test &#x3D; datasets.MNIST(root&#x3D;&quot;D:&#x2F;learning program&#x2F;source_data_MNIST&#x2F;&quot;,</span><br><span class="line">                           transform&#x3D;transform,</span><br><span class="line">                           train &#x3D; False)</span><br></pre></td></tr></table></figure>
<h3 id="torchvision-transforms—数据的变换"><a href="#torchvision-transforms—数据的变换" class="headerlink" title="torchvision.transforms—数据的变换"></a>torchvision.transforms—数据的变换</h3><p>图片类型转换成tensor类型、图片数据有限时可通过变换生成训练集（缩小放大、水平垂直反转）</p>
<p><code>torch.transforms.Compose</code>类是一种容器，可将对数据的变换进行组合，传入的参数是一个列表，列表中的元素就是对载入的数据进行的各种变换操作</p>
<ol>
<li><code>torch.transforms.ToTensor</code>将数据转换为tensor类型</li>
<li><code>transforms.ToTensor</code>标准差转换，使用原始数据的均值和标准差进行标准化，即概率论中的一般正态分布的标准化x=x−meanstdx=x−meanstd</li>
<li><code>transforms.Resize</code>缩放，输入<code>(h,w)</code>序列或<code>int</code>, i.e, if height &gt; width, then image will be rescaled to (size * height / width, size) ,<code>transforms.Scale</code>与其类似</li>
<li><code>transforms.CenterCrop</code>图片以中心为参考点进行裁剪，输入同上，<code>transforms.RandomCrop</code>与其类似</li>
<li><code>transforms.RandomHorizontalFlip</code>自定义随机概率水平翻转，默认0.5，<code>.transforms.RandomVerticalFlip</code>类似</li>
<li><code>transforms. ToPILlmage</code>将tensor转换成PIL图片，便于显示</li>
</ol>
<h3 id="数据预览和装载"><a href="#数据预览和装载" class="headerlink" title="数据预览和装载"></a>数据预览和装载</h3><h4 id="装载"><a href="#装载" class="headerlink" title="装载"></a>装载</h4><p>将图片处理之后打包,使用<code>torch.utils.data.DataLoader</code>类进行数据装载，<code>dataset</code>指定载入的数据集名称 <code>batch_size</code>是每个包的大小，<code>shuffle</code>是否在装载时打乱图片的顺序</p>
<p>每个批次的装载数据是四维的？<code>(batch_size,channel,height,width)</code> labels?</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">data_loader_train &#x3D; torch.utils.data.DataLoader(dataset&#x3D;data_train,</span><br><span class="line">                                                batch_size &#x3D; 64,</span><br><span class="line">                                                shuffle &#x3D; True,</span><br><span class="line">                                               )</span><br><span class="line"></span><br><span class="line">data_loader_test &#x3D; torch.utils.data.DataLoader(dataset&#x3D;data_test,</span><br><span class="line">                                               batch_size &#x3D; 64,</span><br><span class="line">                                               shuffle &#x3D; True)</span><br></pre></td></tr></table></figure>
<h4 id="预览"><a href="#预览" class="headerlink" title="预览"></a>预览</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">images, labels &#x3D; next(iter(data_loader_train)) #迭代</span><br><span class="line"></span><br><span class="line">img &#x3D; torchvision.utils.make_grid(images) #将一个批次的图像构造成网络模式，图片维度为（channel,height,width）</span><br><span class="line">img &#x3D; img.numpy().transpose(1,2,0) #将维度变为（height,width，channel），matplotlib只支持这种格式</span><br><span class="line"># np.transpose(img,(1,2,0))</span><br><span class="line"></span><br><span class="line">std &#x3D; [0.5]</span><br><span class="line">mean &#x3D; [0.5]</span><br><span class="line">img &#x3D; img*std+mean</span><br><span class="line">print([labels[i] for i in range(64)])</span><br><span class="line">plt.imshow(img)</span><br></pre></td></tr></table></figure>
<h3 id="模型搭建和参数优化-1"><a href="#模型搭建和参数优化-1" class="headerlink" title="模型搭建和参数优化"></a>模型搭建和参数优化</h3><h4 id="卷积层的搭建"><a href="#卷积层的搭建" class="headerlink" title="卷积层的搭建"></a>卷积层的搭建</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride&#x3D;1, padding&#x3D;0, dilation&#x3D;1, groups&#x3D;1, bias&#x3D;True)</span><br></pre></td></tr></table></figure>
<p>输入：输入通道数、输出通道数、卷积核大小、卷积核移动步长、padding值。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kernel_size&#96;, &#96;stride&#96;, &#96;padding&#96;, &#96;dilation&#96;均支持&#96;int&#96;或&#96;tuple&#96;输入形式其中 &#96;tuple&#96;为&#96;(h,w)</span><br></pre></td></tr></table></figure>
<p>i.e,<code>torch.nn.Conv2d(64,128,kernel_size=3,stride=1,padding=1)</code>,即用128个3x3x64的卷积核对输入的64个通道进行卷积操作，最后输出128个通道的图像。</p>
<h4 id="池化层的搭建"><a href="#池化层的搭建" class="headerlink" title="池化层的搭建"></a>池化层的搭建</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.MaxPool2d(kernel_size, stride&#x3D;None, padding&#x3D;0, dilation&#x3D;1, return_indices&#x3D;False, ceil_mode&#x3D;False)</span><br></pre></td></tr></table></figure>
<p>输入：池化窗口大小、移动步长、padding值</p>
<h4 id="参数优化"><a href="#参数优化" class="headerlink" title="参数优化"></a>参数优化</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.Dropout(p&#x3D;0.5, inplace&#x3D;False)</span><br></pre></td></tr></table></figure>
<p>可使在每轮模型训练过程中，以一定概率将部分参数归零来减少相邻两层神经连接使最后训练出的模型对各部分权重参数不产生过度依赖，防止过拟合</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">class Model(torch.nn.Module):</span><br><span class="line">    </span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Model, self).__init__()</span><br><span class="line">        self.conv1&#x3D;torch.nn.Sequential(</span><br><span class="line">            torch.nn.Conv2d(1,64,kernel_size&#x3D;3,stride&#x3D;1,padding&#x3D;1),</span><br><span class="line">            torch.nn.ReLU(),</span><br><span class="line">            torch.nn.Conv2d(64,128,kernel_size&#x3D;3,stride&#x3D;1,padding&#x3D;1),</span><br><span class="line">            torch.nn.ReLU(),</span><br><span class="line">            torch.nn.MaxPool2d(stride&#x3D;2,kernel_size&#x3D;2))</span><br><span class="line">        self.dense&#x3D;torch.nn.Sequential(</span><br><span class="line">            torch.nn.Linear(14*14*128,1024),</span><br><span class="line">            torch.nn.ReLU(),</span><br><span class="line">            torch.nn.Dropout(p&#x3D;0.5),</span><br><span class="line">            torch.nn.Linear(1024, 10))</span><br><span class="line">        </span><br><span class="line">    def forward(self, x):</span><br><span class="line">        x &#x3D; self.conv1(x)</span><br><span class="line">        x &#x3D; x.view(-1, 14*14*128) #输入全连接层前，将数据扁平化</span><br><span class="line">        x &#x3D; self.dense(x)</span><br><span class="line">        return x</span><br><span class="line">model &#x3D; Model()</span><br><span class="line">cost &#x3D; torch.nn.CrossEntropyLoss()</span><br><span class="line">optimizer &#x3D; torch.optim.Adam(model.parameters())</span><br></pre></td></tr></table></figure>
<h4 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">n_epochs &#x3D; 1</span><br><span class="line"></span><br><span class="line">for epoch in range(n_epochs):</span><br><span class="line">    running_loss &#x3D; 0.0</span><br><span class="line">    running_correct &#x3D; 0</span><br><span class="line">    print(&quot;Epoch &#123;&#125;&#x2F;&#123;&#125;&quot;.format(epoch, n_epochs))</span><br><span class="line">    print(&quot;-&quot;*10)</span><br><span class="line">    </span><br><span class="line">    for data in data_loader_train:</span><br><span class="line">        X_train, y_train &#x3D; data</span><br><span class="line">        X_train, y_train &#x3D; Variable(X_train), Variable(y_train)</span><br><span class="line">        outputs &#x3D; model(X_train)</span><br><span class="line">        _,pred &#x3D; torch.max(outputs.data, 1)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss &#x3D; cost(outputs, y_train)</span><br><span class="line">        </span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()     </span><br><span class="line">        running_loss +&#x3D; loss.data</span><br><span class="line">        running_correct +&#x3D; torch.sum(pred &#x3D;&#x3D; y_train.data)</span><br><span class="line"></span><br><span class="line">    testing_correct &#x3D; 0    </span><br><span class="line">    for data in data_loader_test:</span><br><span class="line">        X_test, y_test &#x3D; data</span><br><span class="line">        X_test, y_test &#x3D; Variable(X_test), Variable(y_test)</span><br><span class="line">        outputs &#x3D; model(X_test)</span><br><span class="line">        _, pred &#x3D; torch.max(outputs.data, 1)</span><br><span class="line">        testing_correct +&#x3D; torch.sum(pred &#x3D;&#x3D; y_test.data)</span><br><span class="line">    print(&quot;Loss is:&#123;:.4f&#125;, Train Accuracy is:&#123;:.4f&#125;%, Test Accuracy is:&#123;:.4f&#125;&quot;.format(running_loss&#x2F;len(data_train),100*running_correct&#x2F;len(data_train),</span><br><span class="line">                 100*testing_correct&#x2F;len(data_test)))</span><br></pre></td></tr></table></figure>
<h4 id="随机选取测试集数据测试"><a href="#随机选取测试集数据测试" class="headerlink" title="随机选取测试集数据测试"></a>随机选取测试集数据测试</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">data_loader_test &#x3D; torch.utils.data.DataLoader(dataset&#x3D;data_test,</span><br><span class="line">                                               batch_size &#x3D; 4,</span><br><span class="line">                                               shuffle &#x3D; True)</span><br><span class="line"></span><br><span class="line">X_test, y_test &#x3D; next(iter(data_loader_test))</span><br><span class="line">inputs &#x3D; Variable(X_test)</span><br><span class="line">pred &#x3D; model(inputs)</span><br><span class="line">_,pred &#x3D; torch.max(pred, 1)</span><br><span class="line">print(&quot;Predict Label is:&quot;, [ i for i in pred.data])</span><br><span class="line">print(&quot;Real Label is:&quot;,[i for i in y_test])</span><br><span class="line"></span><br><span class="line">img &#x3D; torchvision.utils.make_grid(X_test)</span><br><span class="line">img &#x3D; img.numpy().transpose(1,2,0)</span><br><span class="line"></span><br><span class="line">std &#x3D; [0.5,0.5,0.5]</span><br><span class="line">mean &#x3D; [0.5,0.5,0.5]</span><br><span class="line">img &#x3D; img*std+mean</span><br><span class="line">plt.imshow(img)</span><br></pre></td></tr></table></figure>
<h2 id="动态图还是静态图"><a href="#动态图还是静态图" class="headerlink" title="动态图还是静态图"></a>动态图还是静态图</h2><p>对于使用者来说，两种形式的计算图有着非常大的区别，同时静态图和动态图都有他们各自的优点，比如动态图比较方便debug，使用者能够用任何他们喜欢的方式进行debug，同时非常直观，而静态图是通过先定义后运行的方式，之后再次运行的时候就不再需要重新构建计算图，所以速度会比动态图更快。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/24/Python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chenyang Min">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="perfectism's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/07/24/Python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="post-title-link" itemprop="url">Python学习笔记</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-24 13:10:01" itemprop="dateCreated datePublished" datetime="2020-07-24T13:10:01+08:00">2020-07-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-04-01 15:50:53" itemprop="dateModified" datetime="2020-04-01T15:50:53+08:00">2020-04-01</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Python学习笔记"><a href="#Python学习笔记" class="headerlink" title="Python学习笔记"></a>Python学习笔记</h1><h2 id="基本语法"><a href="#基本语法" class="headerlink" title="基本语法"></a>基本语法</h2><h3 id="打印输出"><a href="#打印输出" class="headerlink" title="打印输出"></a>打印输出</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">print(&quot;hello world&quot;)</span><br><span class="line">print(&quot;-&quot;*10)</span><br><span class="line">print(&quot;hello&quot;,&quot;world&quot;)</span><br><span class="line">#打印变量值</span><br><span class="line">print(&quot;width : %s, height : %s channels : %s&quot; % (width, height, channels))</span><br><span class="line">#打印矩阵</span><br><span class="line">print(image)</span><br></pre></td></tr></table></figure>
<h3 id="代码注释"><a href="#代码注释" class="headerlink" title="代码注释"></a>代码注释</h3><p>代码缩进：python对代码缩进的要求非常严格</p>
<h3 id="多行语句的分割"><a href="#多行语句的分割" class="headerlink" title="多行语句的分割"></a>多行语句的分割</h3><p>使用<code>\</code>将代码分割成多行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(&quot;Hello,World.Hello,World.\</span><br><span class="line">Hello,World.Hello,World.&quot;)</span><br></pre></td></tr></table></figure>
<h2 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h2><h3 id="赋值方式"><a href="#赋值方式" class="headerlink" title="赋值方式"></a>赋值方式</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">string1 &#x3D; string2 &#x3D; string3 &#x3D; &quot;Hello,World&quot;</span><br><span class="line">string1, string2, string3 &#x3D; &quot;Hello&quot;, &quot;World&quot;,&quot;Hello,World&quot;</span><br></pre></td></tr></table></figure>
<h3 id="数据类型及其索引"><a href="#数据类型及其索引" class="headerlink" title="数据类型及其索引"></a>数据类型及其索引</h3><h4 id="数字"><a href="#数字" class="headerlink" title="数字"></a>数字</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">float_num &#x3D; 10.000</span><br><span class="line"></span><br><span class="line">print(float_num)</span><br><span class="line">print(&quot;%f&quot; % float_num)</span><br><span class="line">print(&quot;%.2f&quot; % float_num)</span><br><span class="line">print(&quot;%.4f&quot; % float_num)</span><br><span class="line">#ouput</span><br><span class="line">10.0</span><br><span class="line">10.000000</span><br><span class="line">10.00</span><br><span class="line">10.0000</span><br></pre></td></tr></table></figure>
<h4 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">string &#x3D; &#39;Hello,World&#39; #双引号也可以</span><br><span class="line">string1 &#x3D; string[0:11]</span><br><span class="line">string2 &#x3D; string[0:5]</span><br><span class="line">string6 &#x3D; string[:5] #注意第五个字符不显示</span><br><span class="line">string3 &#x3D; string[-1]</span><br><span class="line">string4 &#x3D; string[-5:-1]</span><br><span class="line">#ouput</span><br><span class="line">Hello,World</span><br><span class="line">Hello</span><br><span class="line">Hello</span><br><span class="line">d</span><br><span class="line">worl</span><br></pre></td></tr></table></figure>
<h4 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h4><p>列表是一种容器型数据类型，可以实现多种数据类型的嵌套，元素可重新赋值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">list1 &#x3D; [ &quot;Hello,World&quot;, 100 , 10.00 ]</span><br><span class="line">list2 &#x3D; [123, &#39;Hi&#39;]</span><br><span class="line"></span><br><span class="line">print(list1) # 输出整个list1 列表元素</span><br><span class="line">print(list1[0]) # 输出列表的第1 个元素</span><br><span class="line">print(list1[1:]) # 输出从第1 个索引开始至列表末尾的所有元素</span><br><span class="line">print(list1[-1]) # 输出列表的最后一个元素</span><br><span class="line">print(list1 + list2) # 输出列表的组合</span><br><span class="line">list1[0] &#x3D; &quot;0&quot;</span><br><span class="line">print(list1)</span><br><span class="line">#output</span><br><span class="line">[&#39;Hello,World&#39;, 100, 10.0]</span><br><span class="line">Hello,World</span><br><span class="line">[100, 10.0]</span><br><span class="line">10.0</span><br><span class="line">[&#39;Hello,World&#39;, 100, 10.0, 123, &#39;Hi&#39;]</span><br><span class="line">[&#39;0&#39;, 100, 10.0]</span><br></pre></td></tr></table></figure>
<h4 id="元组"><a href="#元组" class="headerlink" title="元组"></a>元组</h4><p>另一种容器型数据类型，基本性质、索引值操作与列表相同，但其元素不能重新赋值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tuple1 &#x3D; ( &quot;Hello,World&quot;, 100 , 10.00 )</span><br><span class="line">tuple2 &#x3D; (123, &#39;Hi&#39;)</span><br><span class="line">print(list1) # 输出整个tuple1 列表元素</span><br></pre></td></tr></table></figure>
<h4 id="字典"><a href="#字典" class="headerlink" title="字典"></a>字典</h4><p>列表与元组为有序的元素组合，字典通过键值来操控元素</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">dict_info &#x3D; &#123;&quot;name&quot;: &quot;Tang&quot;, &quot;num&quot;:7272, &quot;city&quot;: &quot;GL&quot;&#125;</span><br><span class="line">dict_info[&quot;city&quot;] &#x3D; &quot;changsha&quot;</span><br><span class="line"></span><br><span class="line">print (dict_info) # 输出整个dict_info 字典</span><br><span class="line">print(dict_info[&quot;city&quot;])</span><br><span class="line">print (dict_info.keys()) # 输出dict_info 的所有键值</span><br><span class="line">print (dict_info.values()) # 输出dict_info 的所有值</span><br><span class="line"></span><br><span class="line">#output</span><br><span class="line">&#123;&#39;name&#39;: &#39;Tang&#39;, &#39;num&#39;: 7272, &#39;city&#39;: &#39;changsha&#39;&#125;</span><br><span class="line">changsha</span><br><span class="line">dict_keys([&#39;name&#39;, &#39;num&#39;, &#39;city&#39;])</span><br><span class="line">dict_values([&#39;Tang&#39;, 7272, &#39;changsha&#39;])</span><br></pre></td></tr></table></figure>
<h4 id="tuple"><a href="#tuple" class="headerlink" title="tuple"></a>tuple</h4><p>构造一个元组</p>
<h2 id="面向对象的方法-类"><a href="#面向对象的方法-类" class="headerlink" title="面向对象的方法-类"></a>面向对象的方法-类</h2><p>类是用来描述具有相同属性和方法的对象的集合，定义了该集合中每个对象的共有属性和方法，对象是类的实例</p>
<h3 id="类的创建、继承与重写"><a href="#类的创建、继承与重写" class="headerlink" title="类的创建、继承与重写"></a>类的创建、继承与重写</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">class People:</span><br><span class="line">    </span><br><span class="line">    def __init__(self, name, age):</span><br><span class="line">        self.name &#x3D; name</span><br><span class="line">        self.age &#x3D; age</span><br><span class="line">        </span><br><span class="line">    def dis_name(self):</span><br><span class="line">        print(&quot;name is:&quot;,self.name)</span><br><span class="line"></span><br><span class="line">    def set_age(self, age):</span><br><span class="line">        self.age &#x3D; age</span><br><span class="line">        </span><br><span class="line">    def dis_age(self):</span><br><span class="line">        print(&quot;age is:&quot;,self.age)</span><br><span class="line">        </span><br><span class="line">class Student(People): #继承父类</span><br><span class="line">    def __init__(self, name, age, school_name):</span><br><span class="line">        self.name &#x3D; name</span><br><span class="line">        self.age &#x3D; age</span><br><span class="line">        self.school_name &#x3D; school_name</span><br><span class="line"></span><br><span class="line">    def dis_student(self):</span><br><span class="line">        print(&quot;school name is:&quot;,self.school_name)</span><br><span class="line">    </span><br><span class="line">    def dis_name(self): #子类中对父类进行重写</span><br><span class="line">        print(&quot;名字：&quot;,self.name)</span><br><span class="line">        </span><br><span class="line">student &#x3D; Student(&quot;Wu&quot;, &quot;20&quot;, &quot;GLDZ&quot;) #创建一个Student 对象</span><br><span class="line">student.dis_student() #调用子类的方法</span><br><span class="line">student.dis_name() #调用子类的方法，已重写</span><br><span class="line">student.dis_age() #调用父类的方法</span><br><span class="line">student.set_age(22) #调用父类的方法</span><br><span class="line">student.dis_age() #调用父类的方法</span><br></pre></td></tr></table></figure>
<p><code>next()</code>返回迭代器的下一个值</p>
<p><code>iter()</code>生成迭代器</p>
<h2 id="Matplotlib"><a href="#Matplotlib" class="headerlink" title="Matplotlib"></a>Matplotlib</h2><h3 id="画函数图像"><a href="#画函数图像" class="headerlink" title="画函数图像"></a>画函数图像</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as nps</span><br><span class="line">%matplotlib inline</span><br><span class="line">x &#x3D; np.arange(-10,10,0.01)</span><br><span class="line"># y &#x3D; (np.exp(x)-np.exp(-x))&#x2F;(np.exp(x)+np.exp(-x))</span><br><span class="line">y &#x3D; np.where(x&lt;0,0,x)</span><br><span class="line"># y &#x3D; np.sin(x)</span><br><span class="line">plt.plot(x, y)</span><br><span class="line">plt.title(&quot;ReLU&quot;,fontsize &#x3D; 10)</span><br><span class="line"># plt.xlabel(&quot;horizontal axis&quot;, fontsize &#x3D; 10)</span><br><span class="line"># plt.ylabel(&quot;vertical axis&quot;,fontsize &#x3D; 10)</span><br><span class="line">plt.tick_params(axis&#x3D;&quot;both&quot;, labelsize &#x3D; 10)</span><br><span class="line">ax &#x3D; plt.gca()                                            # get current axis 获得坐标轴对象</span><br><span class="line">ax.spines[&#39;right&#39;].set_color(&#39;none&#39;) </span><br><span class="line">ax.spines[&#39;top&#39;].set_color(&#39;none&#39;)         # 将右边 上边的两条边颜色设置为空 其实就相当于抹掉这两条边</span><br><span class="line">ax.xaxis.set_ticks_position(&#39;bottom&#39;)   </span><br><span class="line">ax.yaxis.set_ticks_position(&#39;left&#39;)          # 指定下边的边作为 x 轴   指定左边的边为 y 轴</span><br><span class="line">ax.spines[&#39;bottom&#39;].set_position((&#39;data&#39;, 0))   #指定 data  设置的bottom(也就是指定的x轴)绑定到y轴的0这个点上</span><br><span class="line">ax.spines[&#39;left&#39;].set_position((&#39;data&#39;, 0))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="显示图像报错"><a href="#显示图像报错" class="headerlink" title="显示图像报错"></a>显示图像报错</h3><p>pyplot显示图像报错：Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers)</p>
<p>原因：用cv2.imread读进来的图片是uint8格式的，每个点的像素值在[0,255]之间，之前定义的图片占位符是float32，所以会直接将0-255之间的整数变成小数，但是并没有归一化！ 要显示float32格式的图片，还需要一步操作：</p>
<p>image = image/255.<br>原文链接：<a href="https://blog.csdn.net/aaon22357/article/details/82736792" target="_blank" rel="noopener">https://blog.csdn.net/aaon22357/article/details/82736792</a></p>
<p>解决：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">import cv2.cv2 as cv</span><br><span class="line">import numpy as np</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line">%matplotlib inline</span><br><span class="line">def get_image_info(image):</span><br><span class="line">    print(type(image))  # &lt;class &#39;numpy.ndarray&#39;&gt;</span><br><span class="line">    print(image.shape[1:3])  # 显示高，宽，通道数</span><br><span class="line">    # print(image.size)  # 总的像素数据大小&#x3D;高*宽*通道数</span><br><span class="line">    # print(image.dtype)  # 显示像素数据类型</span><br><span class="line">    # pixel_data &#x3D; np.array(image)  # 通过numpy获取像素值</span><br><span class="line">    # # print(pixel_data)</span><br><span class="line">    # print(image)</span><br><span class="line">print(&quot;hi,python&quot;)</span><br><span class="line">src &#x3D; cv.imread(&quot;D:&#x2F;IMG_20161227_154705.jpg&quot;)</span><br><span class="line">plt.imshow(src)</span><br><span class="line">plt.show()</span><br><span class="line">edit &#x3D; cv.resize(src, (224, 224)).astype(&quot;float32&quot;)</span><br><span class="line">edit &#x3D; cv.cvtColor(edit, cv.COLOR_BGR2RGB)</span><br><span class="line">edit &#x3D; edit&#x2F;255.</span><br><span class="line">#plt.imshow(edit.astype(&#39;uint8&#39;))，用此句不用上一句</span><br><span class="line">plt.imshow(edit)</span><br><span class="line">get_image_info(edit)</span><br></pre></td></tr></table></figure>
<h2 id="pickle块"><a href="#pickle块" class="headerlink" title="pickle块"></a>pickle块</h2><p>模块 <a href="https://docs.python.org/zh-cn/3/library/pickle.html?highlight=pickle#module-pickle" target="_blank" rel="noopener"><code>pickle</code></a> 实现了对一个 Python 对象结构的二进制序列化和反序列化。</p>
<p>json也是一种序列化格式。</p>
<h2 id="collections"><a href="#collections" class="headerlink" title="collections"></a>collections</h2><h3 id="deque双向队列"><a href="#deque双向队列" class="headerlink" title="deque双向队列"></a>deque双向队列</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; from collections import deque</span><br><span class="line">&gt;&gt;&gt; d &#x3D; deque(&#39;ghi&#39;)                 # make a new deque with three items</span><br><span class="line">&gt;&gt;&gt; for elem in d:                   # iterate over the deque&#39;s elements</span><br><span class="line">...     print(elem.upper())</span><br><span class="line">G</span><br><span class="line">H</span><br><span class="line">I</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; d.append(&#39;j&#39;)                    # add a new entry to the right side</span><br><span class="line">&gt;&gt;&gt; d.appendleft(&#39;f&#39;)                # add a new entry to the left side</span><br><span class="line">&gt;&gt;&gt; d                                # show the representation of the deque</span><br><span class="line">deque([&#39;f&#39;, &#39;g&#39;, &#39;h&#39;, &#39;i&#39;, &#39;j&#39;])</span><br></pre></td></tr></table></figure>
<h2 id="yield"><a href="#yield" class="headerlink" title="yield"></a>yield</h2><p>带yield的函数是一个生成器，而不是一个函数了，这个生成器有一个函数就是next函数，next就相当于“下一步”生成哪个数，这一次的next开始的地方是接着上一次的next停止的地方执行的，所以调用next的时候，生成器并不会从foo函数的开始执行，只是接着上一步停止的地方开始，然后遇到yield后，return出要生成的数，此步就结束</p>
<p>在深度学习中批量生成数据时经常yield（x,y)</p>
<p>其中x为数据，y代表数据标签</p>
<h2 id="找到字符串中的数字"><a href="#找到字符串中的数字" class="headerlink" title="找到字符串中的数字"></a>找到字符串中的数字</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">s=<span class="string">'zs10nj23kl'</span></span><br><span class="line">f1=re.findall(<span class="string">'(\d+)'</span>,s)</span><br><span class="line">print(f1)</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/24/Numpy%20%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chenyang Min">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="perfectism's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/07/24/Numpy%20%E7%AC%94%E8%AE%B0/" class="post-title-link" itemprop="url">Numpy 笔记</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-24 13:10:01" itemprop="dateCreated datePublished" datetime="2020-07-24T13:10:01+08:00">2020-07-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-16 21:45:30" itemprop="dateModified" datetime="2020-03-16T21:45:30+08:00">2020-03-16</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Numpy-笔记"><a href="#Numpy-笔记" class="headerlink" title="Numpy 笔记"></a>Numpy 笔记</h1><h2 id="transpose"><a href="#transpose" class="headerlink" title="transpose"></a>transpose</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">numpy.transpose(a, axes&#x3D;None)</span><br><span class="line">#修改张量的维度</span><br><span class="line">&gt;&gt;&gt; x &#x3D; np.arange(4).reshape((2,2))</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line">array([[0, 1],</span><br><span class="line">       [2, 3]])</span><br><span class="line">&gt;&gt;&gt; np.transpose(x)</span><br><span class="line">array([[0, 2],</span><br><span class="line">       [1, 3]])</span><br><span class="line">&gt;&gt;&gt; x &#x3D; np.ones((1, 2, 3))</span><br><span class="line">&gt;&gt;&gt; np.transpose(x, (1, 0, 2)).shape</span><br><span class="line">(2, 1, 3)</span><br></pre></td></tr></table></figure>
<h2 id="nonzero"><a href="#nonzero" class="headerlink" title="nonzero"></a>nonzero</h2><p>找到非零元素的下标</p>
<h2 id="where"><a href="#where" class="headerlink" title="where"></a>where</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.where(x&lt;0,0,x) #分段函数</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/24/Notes%20of%20Machine%20Learning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chenyang Min">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="perfectism's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/07/24/Notes%20of%20Machine%20Learning/" class="post-title-link" itemprop="url">Notes of Machine Learning</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-24 13:10:01" itemprop="dateCreated datePublished" datetime="2020-07-24T13:10:01+08:00">2020-07-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-16 21:50:39" itemprop="dateModified" datetime="2020-03-16T21:50:39+08:00">2020-03-16</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Notes-of-Machine-Learning"><a href="#Notes-of-Machine-Learning" class="headerlink" title="Notes of Machine Learning"></a>Notes of Machine Learning</h1><p>Min Chen Yang, Hunan University, 2019.11</p>
<h2 id="初识机器学习"><a href="#初识机器学习" class="headerlink" title="初识机器学习"></a>初识机器学习</h2><p><strong>从原始数据中提取模式的能力。</strong></p>
<p>进入21世纪，纵观机器学习发展历程，研究热点可以简单总结为2000-2006年的流形学习、2006年-2011年的稀疏学习、2012年至今的深度学习 、未来迁移学习？</p>
<p>人工智能的真正挑战在于解决对人来说很容易执行，但很难形式化描述的任务。</p>
<p>常用的10大机器学习算法有：决策树、随机森林、逻辑回归、SVM、朴素贝叶斯、K最近邻算法、K均值算法、Adaboost算法、神经网络、马尔科夫</p>
<p>大致分类：</p>
<p>监督式学习：决策树、KNN（K邻近）、朴素贝叶斯(贝叶斯分类器）、逻辑回归、支持向量机</p>
<p>非监督式学习：聚类、主成分分析PCA</p>
<p>深度学习：卷积神经网络、自编码器、循环神经网络</p>
<p><img src="https://perfectism13.github.io/2019/11/16/Notes%20of%20Machine%20Learning/21.PNG" alt="img"></p>
<p><img src="https://perfectism13.github.io/2019/11/16/Notes%20of%20Machine%20Learning/22.PNG" alt="22"></p>
<p>机器学习的三个步骤：搭建model（一系列函数），选择评价loss，选择最优的model</p>
<p><img src="https://perfectism13.github.io/2019/11/16/Notes%20of%20Machine%20Learning/23.PNG" alt="23"></p>
<p>结构化学习：超出分类的问题，如seq2seq、机器翻译、语音辨识</p>
<p>半监督学习：少量带label数据和大量没有label的数据，让model从没有label的数据中获益</p>
<p>无监督学习：全为无label数据，如让机器画画、阅读文章等</p>
<p>强化学习：从惩罚或者批评中学习，而监督学习从老师学习，需要老师手把手交，显然强化学习更加智能</p>
<h2 id="Deep-Learning"><a href="#Deep-Learning" class="headerlink" title="Deep Learning"></a>Deep Learning</h2><h3 id="初识"><a href="#初识" class="headerlink" title="初识"></a>初识</h3><p><strong>让计算机从经验中学习，根据层次化的概念体系来理解世界，每个概念通过与相对简单的概念之间的关系定义。</strong></p>
<h3 id="数学基础"><a href="#数学基础" class="headerlink" title="数学基础"></a>数学基础</h3><p>一维数组，二维矩阵，三维张量</p>
<h4 id="雅可比Jacobian矩阵"><a href="#雅可比Jacobian矩阵" class="headerlink" title="雅可比Jacobian矩阵"></a>雅可比Jacobian矩阵</h4><p><img src="https://perfectism13.github.io/2019/11/16/Notes%20of%20Machine%20Learning/jacobian-1572707333030.PNG" alt="img"></p>
<h4 id="海森Hessian矩阵"><a href="#海森Hessian矩阵" class="headerlink" title="海森Hessian矩阵"></a>海森Hessian矩阵</h4><p><img src="https://perfectism13.github.io/2019/11/16/Notes%20of%20Machine%20Learning/hessian.PNG" alt="img"></p>
<h4 id="softmax函数（归一化指数函数）"><a href="#softmax函数（归一化指数函数）" class="headerlink" title="softmax函数（归一化指数函数）"></a>softmax函数（归一化指数函数）</h4><p>σ(z)j=ezj∑Kk=1ezk for j=1,…,Kσ(z)j=ezj∑k=1Kezk for j=1,…,K</p>
<p>观察到的数据属于某个类的概率,经常将其作为神经网络的输出层</p>
<h4 id="linear-algebra"><a href="#linear-algebra" class="headerlink" title="linear algebra"></a>linear algebra</h4><p>标量、向量、矩阵、张量</p>
<p>矩阵乘积、矩阵点积</p>
<p>单位矩阵、逆矩阵</p>
<p>生成子空间（列空间、值域）、线性相关（无关）、矩阵的奇异性</p>
<p>范数、欧几里得范数、最大范数</p>
<p>对角矩阵、正交矩阵、实对称矩阵</p>
<p>特征值、特征向量、矩阵的特征分解、实对称矩阵特征分解来优化二次方程</p>
<h3 id="DNN基础"><a href="#DNN基础" class="headerlink" title="DNN基础"></a>DNN基础</h3><p>感知机是神经网络的最小单元</p>
<h4 id="线性变化与仿射变换"><a href="#线性变化与仿射变换" class="headerlink" title="线性变化与仿射变换"></a>线性变化与仿射变换</h4><p><strong>线性变换</strong>：</p>
<ul>
<li>变换前是直线的，变换后依然是直线</li>
<li>直线比例保持不变</li>
<li>变换前是原点的，变换后依然是原点</li>
</ul>
<p><strong>仿射变换</strong>：线性变换+平移</p>
<ul>
<li><p>变换前是直线的，变换后依然是直线</p>
</li>
<li><p>直线比例保持不变</p>
</li>
<li><p>变换前是原点的，变换后依然是原点</p>
</li>
</ul>
<p>  y⃗ =Ax⃗ +b⃗ y→=Ax→+b→</p>
<p><strong>通过线性变换来完成仿射变换</strong></p>
<p>通过高维度的线性变换完成低维度的仿射变换：</p>
<p>[y⃗ 1]=[A0b⃗ 1][x⃗ 1][y→1]=[Ab→01][x→1]</p>
<p>假设某二维图形上每个点为x⃗ x→，则[x⃗ 1][x→1]表示将其平移到z=1z=1的平面上</p>
<p><img src="https://perfectism13.github.io/2019/11/16/Notes%20of%20Machine%20Learning/v2-01d06795480b91a9bc1fa57ce5fd7009_hd.webp" alt="img"></p>
<p>线性不可分的样本在经过仿射变换后，仍然是不可分的</p>
<h4 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h4><p>提供一组输入数据和其对应的标签数据，然后搭建一个模型，让模型在通过训练后准确地找到输入数据和标签数据之间的最优映射关系，在输入新的数据后，模型能够通过之前学到的最优映射关系， 快速地预测出这组新数据的标签。</p>
<h5 id="回归问题"><a href="#回归问题" class="headerlink" title="回归问题"></a>回归问题</h5><p>模型通过训练后得到一个连续的线性映射关系，i.e,根据离散的（房屋面积，房屋价格）之间的关系找到房屋价格与房屋面积间的连续函数关系</p>
<h5 id="分类问题"><a href="#分类问题" class="headerlink" title="分类问题"></a>分类问题</h5><p>模型通过训练后得到一个离散的线性映射关系，输出结果为有限个</p>
<h4 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h4><p>提供一组没有任何标签的输入数据，将其在我们搭建好的模型中进行训练，对整个训练过程不做任何干涉，最后得到一个能够发现数据之间隐藏特征的映射模型，使用这个映射模型能够实现对新数据的分类，使用无监督学习实现分类的算法叫做<strong>聚类</strong>。更具有创造性，有利于提高机器学习算法对新鲜样本的适应能力（泛化能力）。</p>
<p><strong>半监督学习、弱监督学习</strong>等创新方法也在出现。</p>
<h4 id="欠拟合、过拟合"><a href="#欠拟合、过拟合" class="headerlink" title="欠拟合、过拟合"></a>欠拟合、过拟合</h4><p><img src="https://perfectism13.github.io/2019/11/16/Notes%20of%20Machine%20Learning/2.png" alt="image-20191128224211081"></p>
<p>如图：a)为欠拟合，b)为过拟合，c）为正常训练出的模型</p>
<p>欠拟合：对已有数据的匹配性很差，但对数据中的噪声不敏感，不能对新数据准确预测</p>
<p>原因及解决方法：1）没有把握数据的主要特征，加入更多和原数据有重要相关性的特征来训练，2）增加函数次项来增加泛化能力，3）减少正则化参数:正则化参数是为了防止过拟合，若出现欠拟合，可减少正则化参数</p>
<p>过拟合：对数据的匹配性太好，对数据中的噪声特别敏感</p>
<p>解决方法：1）过度捕获了数据的有限特征，可增大训练的数据量，2）正则化：对目标函数增加一个参数范数惩罚，限制其学习能力</p>
<h4 id="后向传播"><a href="#后向传播" class="headerlink" title="后向传播"></a>后向传播</h4><h4 id="损失和优化"><a href="#损失和优化" class="headerlink" title="损失和优化"></a>损失和优化</h4><p><strong>损失函数</strong>:进行损失值计算的函数，均方误差（MSE)、均方根误差(RMSE)、平均绝对误差(MAE)</p>
<p>MSE=1N∑i=1N(yitrue −yipred )2MSE=1N∑i=1N(ytrue i−ypred i)2</p>
<p>RMSE=1N∑i=1N(yitrue −yipred )2−−−−−−−−−−−−−−−−−−⎷RMSE=1N∑i=1N(ytrue i−ypred i)2</p>
<p>MAE=1N∑i=1N∣∣(yitrue −yipred )∣∣MAE=1N∑i=1N|(ytrue i−ypred i)|</p>
<p><strong>优化函数</strong>：对模型参数进行优化的函数，解决参数初始化、参数微调形式、学习速率如何选取的方案的集合</p>
<p> 梯度：多元函数的偏导以向量的形式展示。</p>
<p> 常用优化函数：</p>
<p> <strong>1）全局梯度下降GD</strong>：模型的训练依赖整个训练集，增加了计算损失值的时间成本和模型训练过程的复杂度</p>
<p> <strong>2）批量梯度下降BGD</strong>：将训练集分成若干份，每个批次（batch）使用一次来进行梯度更新，可能会导致局部最优</p>
<p> <strong>3）随机梯度下降SGD</strong>：随机从数据集中选取一部分参与模型训练，可能导致局部最优，受噪声影响严重</p>
<p> <strong>4）Adam</strong>：损失值大时采用大的ηη,反之采用小的ηη，对梯度消失、收敛过慢、高方差的参数更新等导致的损失值波动均有很好的方法。ηη过大会导致局部最优和抖动，反之会使参数优化的时间变长</p>
<p> <strong>5）扰动—动量算法</strong></p>
<h4 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h4><p>多层感知机无论多深，始终为线性，线性模型很难处理非线性问题，激活函数可带来非线性元素，抑制输出，便可近似拟合所有函数</p>
<h5 id="Logistic-sigmoid-函数"><a href="#Logistic-sigmoid-函数" class="headerlink" title="Logistic sigmoid 函数"></a>Logistic sigmoid 函数</h5><p>f(x)=11+e−xf(x)=11+e−x</p>
<p><img src="https://perfectism13.github.io/2019/11/16/Notes%20of%20Machine%20Learning/logistic-1572783311445.PNG" alt="img"></p>
<p>与生物神经网络的工作机理非常相似，</p>
<p><strong>1）</strong>因dfdx∈(0∼0.25)dfdx∈(0∼0.25),会导致梯度消失（后向传播时每逆向经过一个节点，梯度值缩小为1/41/4,t梯度值越来越小）</p>
<p><strong>2）</strong>因f(x)&gt;0f(x)&gt;0,模型优化时收敛速度变慢，会增加时间成本，因此应尽量使用零中心数据，保证计算得到的输出结果是零中心数据</p>
<h5 id="tanh函数"><a href="#tanh函数" class="headerlink" title="tanh函数"></a>tanh函数</h5><p>f(x)=ex−e−xex+e−xf(x)=ex−e−xex+e−x</p>
<p><img src="https://perfectism13.github.io/2019/11/16/Notes%20of%20Machine%20Learning/19.png" alt="img"></p>
<p>tanh输出结果是零中心数据，可解决收敛速度变慢的问题，但dfdx∈(0∼1)dfdx∈(0∼1),仍可能出现梯度消失，特别是x→−∞x→−∞或x→+∞x→+∞时，dfdx→0dfdx→0</p>
<h5 id="ReLU函数（修正线性单元）"><a href="#ReLU函数（修正线性单元）" class="headerlink" title="ReLU函数（修正线性单元）"></a>ReLU函数（修正线性单元）</h5><p>f(x)=max(0,x)f(x)=max(0,x)</p>
<p><img src="https://perfectism13.github.io/2019/11/16/Notes%20of%20Machine%20Learning/20.PNG" alt="img"></p>
<p>分段线性、收敛速度非常快、无饱和问题、明显减轻梯度消失问题，但输出不是零中心数据，可能导致某些神经元永远不被激活，对应参数永远不被更新</p>
<p>解决方法：使用Xavier方法初始化参数</p>
<p>改进版本：Leaky—ReLU、R-ReLU</p>
<h3 id="李宏毅note"><a href="#李宏毅note" class="headerlink" title="李宏毅note"></a>李宏毅note</h3><p>DNN:深度神经网络</p>
<p>CNN：卷积神经网络</p>
<p>RNN：递归（循环）神经网络</p>
<p>LSTM：长短期记忆</p>
<h5 id="单层感知机模型实现与门、或门、非门"><a href="#单层感知机模型实现与门、或门、非门" class="headerlink" title="单层感知机模型实现与门、或门、非门"></a>单层感知机模型实现与门、或门、非门</h5><p>假定三个输入：x0=1,x1,x2x0=1,x1,x2,激活函数为用小于0时输出10，大于等于0时输出1</p>
<p>与门：输入均为1输出为1，其他输出为0，设定w0=−8,w1=5,w2=5w0=−8,w1=5,w2=5可实现</p>
<p>或门：有1为1，设定w0=−5,w1=8,w2=8w0=−5,w1=8,w2=8可实现</p>
<p>非门：去掉输入x2x2,设定w0=10,w1=20w0=10,w1=20可实现</p>
<p>异或门：单层只能处理线性可分问题，不能处理非线性问题，因此多层感知机诞生了。</p>
<h5 id="完全连接前馈网络"><a href="#完全连接前馈网络" class="headerlink" title="完全连接前馈网络"></a>完全连接前馈网络</h5><p>定义一组函数：</p>
<p><img src="https://perfectism13.github.io/2019/11/16/Notes%20of%20Machine%20Learning/3-1573908546270.PNG" alt="3"></p>
<ul>
<li><p>给定参数 𝜃, 定义一个函数；给定网络结构，定义一个函数集</p>
</li>
<li><p><img src="https://perfectism13.github.io/2019/11/16/Notes%20of%20Machine%20Learning/4-1573908942871.PNG" alt="4"></p>
</li>
<li><p>f([1−1])=[0.620.83]f([1−1])=[0.620.83]</p>
</li>
</ul>
<p>深度学习的三个步骤：</p>
<p><img src="https://perfectism13.github.io/2019/11/16/Notes%20of%20Machine%20Learning/frame.PNG" alt="img"></p>
<p>模型和数据的拟合：</p>
<ul>
<li>准备训练数据—图片及其标签</li>
<li>softmax层作为输出层，正确结果应对应输出层的最大值</li>
</ul>
<p>最优函数的选择：</p>
<ul>
<li>神经网络的两个参数：权重和偏差</li>
<li>损失是神经网络输出和目标之间的距离</li>
<li>最优的函数：找到使总损失最小的参数 𝜽</li>
<li>关键计算算是关于参数的偏导</li>
</ul>
<p>选择的方法：梯度下降 Backpropagation？</p>
<ul>
<li>选取W的初始值,计算w←w−η∂L/∂ww←w−η∂L/∂w,直到∂L/∂w∂L/∂w足够小</li>
<li>不能保证全局最小值，不同的初始点到达不同的初始值</li>
<li>反向传播是一种有效的计算∂L/∂w∂L/∂w的方法—深度学习框架</li>
<li><img src="https://perfectism13.github.io/2019/11/16/Notes%20of%20Machine%20Learning/15.PNG" alt="img"></li>
<li>ηη可认为其参数值更新的快慢，即学习率</li>
</ul>
<h5 id="为什么使用深度神经网络"><a href="#为什么使用深度神经网络" class="headerlink" title="为什么使用深度神经网络"></a>为什么使用深度神经网络</h5><p>对于同样个数的神经元数量，浅胖或者深瘦？</p>
<p><strong>EX</strong>：深瘦：长短发，男孩女孩，浅胖：长发男孩、长发女孩、短法男孩、短法女孩</p>
<p>深瘦: 每个基础分类器都可以有足够的训练实例 浅胖：长发男孩样本少，没有足够的训练实例</p>
<p><img src="https://perfectism13.github.io/2019/11/16/Notes%20of%20Machine%20Learning/2.PNG" alt="img"></p>
<h5 id="神经网络变体"><a href="#神经网络变体" class="headerlink" title="神经网络变体"></a>神经网络变体</h5><h6 id="卷积神经网络（CNN"><a href="#卷积神经网络（CNN" class="headerlink" title="卷积神经网络（CNN)"></a>卷积神经网络（CNN)</h6><p><strong>为什么CNN用于图像识别</strong></p>
<ol>
<li>当处理图像时，全连接网络的第一层将会非常大</li>
<li>一些模式比整张图片小得多（如：识别鸟嘴即可识别出鸟），神经元通过较少的参数连接到小区域去发现模式</li>
<li>同样的模式可能出现在图像的不同区域，不同区域的神经元可能相同</li>
<li>对图像进行二次采样不会改变图像中的物体、使图像变小（获取图像压缩比例、加载图像缩略图、避免图片加载时的OOM异常 ）</li>
<li><img src="https://perfectism13.github.io/2019/11/16/Notes%20of%20Machine%20Learning/7.PNG" alt="7"></li>
</ol>
<p><strong>滤波器</strong></p>
<p>给定宽度和高度的滤波器，不同滤波器提取一个 patch 的不同特性。例如，一个滤波器寻找特定颜色，另一个寻找特定物体的特定形状。卷积层滤波器的数量被称为滤波器深度。</p>
<p><strong>图像的最大池化（Max Pooling）</strong></p>
<p>最大池化是基于样本的离散化过程。目的是对输入表示（图像，隐藏层输出矩阵等）进行下采样，以减小其尺寸，并允许对合并的子区域中包含的特征进行假设.</p>
<p>通过提供表示形式的抽象形式来帮助过度拟合。同样，它通过减少学习参数的数量来减少计算成本，并为内部表示提供基本的平移不变性 。下图为步长为2的最大池化：</p>
<p><img src="https://perfectism13.github.io/2019/11/16/Notes%20of%20Machine%20Learning/5.PNG" alt="5"></p>
<p><strong>CNN整体结构</strong></p>
<p><img src="https://perfectism13.github.io/2019/11/16/Notes%20of%20Machine%20Learning/6.PNG" alt="6"></p>
<h6 id="循环神经网络（RNN"><a href="#循环神经网络（RNN" class="headerlink" title="循环神经网络（RNN)"></a>循环神经网络（RNN)</h6><p><strong>插槽填充</strong></p>
<p>输入序列向量化，将每一个输入的单词用向量表示，可以使用 One-of-N Encoding 或者是 Word hashing 等编码方法，输出预测槽位的概率分布</p>
<p><strong>1.1-of-N encoding</strong></p>
<p>向量是词典大小；每个维度对应于词典中的一个单词；这个词的维数是1，其他的是0；为了表示一些不知道的词汇，加入other这个维度</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">词典 &#x3D; &#123;apple, bag, cat, dog, elephant&#125;</span><br></pre></td></tr></table></figure>
<p><strong>2.Word hashing</strong>（字串比对）</p>
<p><img src="https://perfectism13.github.io/2019/11/16/Notes%20of%20Machine%20Learning/8.PNG" alt="8"></p>
<p>不同的序列如：arrive Taipei和leave Taipei，此时Taipei应该被放入不同的slot</p>
<p>因此引入具有记忆属性的RNN</p>
<p><strong>3.RNN（Elman Network）</strong></p>
<p><img src="https://perfectism13.github.io/2019/11/16/Notes%20of%20Machine%20Learning/9.PNG" alt="9"></p>
<p>变式：深层、双向（可以考虑整个sequence的input）、Jordan Network</p>
<p><img src="https://perfectism13.github.io/2019/11/16/Notes%20of%20Machine%20Learning/10.PNG" alt="10"></p>
<p>输出是有目标的，因此Jordan Network表现更好</p>
<p><strong>4.LSTM（长短期记忆）</strong></p>
<p>一种特殊神经元机构：4 inputs，1 output，memory cell</p>
<p><img src="https://perfectism13.github.io/2019/11/16/Notes%20of%20Machine%20Learning/11.PNG" alt="11"></p>
<p><img src="https://perfectism13.github.io/2019/11/16/Notes%20of%20Machine%20Learning/12.PNG" alt="12"></p>
<p>图中c′=g(z)f(zi)+cf(zf)c′=g(z)f(zi)+cf(zf),为memory cell的记忆更新值，激活函数使用sigmoid function，输出表示门的打开和关闭。输入向量点乘相应的权重向量得到输入、输出、以及遗忘“门”的输入通过激活函数的输出来决定“门”的开闭。</p>
<p><strong>5.Multiple-layer LSTM</strong></p>
<p><img src="https://perfectism13.github.io/2019/11/16/Notes%20of%20Machine%20Learning/13.png" alt="img"></p>
<p>一般的LSTM还靖上一层LSTM的memory cell的值、output与当前时刻的input合并为一个新的向量，再点乘相应权重向量，来控制该层LSTM。</p>
<p>Keras 支持LSTM、GRU（Gated Recurrent Unit、two gates、参数量少1/3、旧的不去新的不来）、SimpleRNN（memory不断被洗掉）</p>
<p><strong>6.RNN 训练技巧</strong></p>
<p><img src="https://perfectism13.github.io/2019/11/16/Notes%20of%20Machine%20Learning/14.PNG" alt="img"></p>
<p>原因：memory cell不断与权重乘积</p>
<p>导致的问题：</p>
<ol>
<li>当∂L/∂w∂L/∂w非常大时，梯度下降的参数更新会将参数抛出很远，导致lost异常增大，因此应选择衰减速度足够慢的学习率，避免上坡运动。</li>
<li>会出现梯度消失</li>
</ol>
<p><strong>解决方法：</strong></p>
<p><strong>截断梯度</strong>：在参数更新前，逐元素地截断<strong>小批量产生的参数梯度</strong>或<strong>截断梯度gg的范数</strong></p>
<p> if ∥g∥&gt;vg←gv∥g∥ if ‖g‖&gt;vg←gv‖g‖</p>
<p><strong>LSTM</strong>:可以解决梯度消失 (不能解决梯度爆炸)</p>
<ol>
<li>当forget gate打开时梯度永远不会消失</li>
</ol>
<p>GRU可将input gate与forget gate联动，只有一个gate可打开，只有将memory cell清掉，才能输入；或者没有输入时，memory cell才能更新</p>
<p><strong>clockwise RNN、Structurally Constrained Recurrent Network (SCRN)</strong></p>
<p><strong>7.应用</strong></p>
<ol>
<li><p>many to one :setiment analysis(情感分析)</p>
</li>
<li><p>many to many（output is shorter）:语音识别，通过Connectionist Temporal Classification (CTC)来剔除重复的声音vector对应的输出（添加null来隔开相同的输出）</p>
</li>
<li><p>many to many（No limition、sequence to sequence):机器翻译，EX：根据中文声音信号转成英文文字</p>
</li>
<li><p>beyond sequence: syntactic parsing(语法分析)</p>
</li>
<li><p>auto-encoder:<strong>Text</strong>:考虑文件或语句的顺序将其变为向量 <strong>Speech</strong>：将声音信号编码为向量</p>
<p><img src="https://perfectism13.github.io/2019/11/16/Notes%20of%20Machine%20Learning/16.PNG" alt="img"></p>
<p>此时编码器和解码器同时工作，目标是使经过编码和解码后的输出与输入尽量相似。</p>
</li>
</ol>
<h6 id="注意力集中模型"><a href="#注意力集中模型" class="headerlink" title="注意力集中模型"></a>注意力集中模型</h6><p>Attention-based Model、Neural Turing machine</p>
<p><img src="https://perfectism13.github.io/2019/11/16/Notes%20of%20Machine%20Learning/17.PNG" alt="img"></p>
<p><strong>应用</strong></p>
<p>Reading Comprehension、Visual Question Answering</p>
<p>EX：Speech Question Answering</p>
<p><img src="https://perfectism13.github.io/2019/11/16/Notes%20of%20Machine%20Learning/18.png" alt="image-20191119214456154"></p>
<h4 id="RNN-vs-Structured-Learning"><a href="#RNN-vs-Structured-Learning" class="headerlink" title="RNN vs Structured Learning"></a>RNN vs Structured Learning</h4><h3 id="深度学习框架"><a href="#深度学习框架" class="headerlink" title="深度学习框架"></a>深度学习框架</h3><p>theano: 蒙特利尔大学蒙特利尔学习算法研究所开发</p>
<p>caffe: CAFFE是一个深度学习框架，最初开发于加利福尼亚大学伯克利分校。Caffe在BSD许可下开源，使用C++编写，带有Python接口</p>
<p>tensorflow: TensorFlow是一个开源软件库，用于各种感知和语言理解任务的机器学习</p>
<p>keras: Keras是一个用Python编写的开源神经网络库，能够在TensorFlow、Microsoft Cognitive Toolkit、Theano或PlaidML之上运行</p>
<p><img src="https://perfectism13.github.io/2019/11/16/Notes%20of%20Machine%20Learning/image-20191208211006443.png" alt="image-20191208211006443"></p>
<p>API风格：上方为命令式，趋于统一；下方为符号式</p>
<h3 id="深度学习与计算机视觉"><a href="#深度学习与计算机视觉" class="headerlink" title="深度学习与计算机视觉"></a>深度学习与计算机视觉</h3><p>图片分类（二分类、多分类），图像的目标识别，图像的语义分割、风格迁移</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/24/Note%20of%20ROS%20to%20Ubantu/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chenyang Min">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="perfectism's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/07/24/Note%20of%20ROS%20to%20Ubantu/" class="post-title-link" itemprop="url">Note of ROS to Ubantu</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-24 13:10:01" itemprop="dateCreated datePublished" datetime="2020-07-24T13:10:01+08:00">2020-07-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-16 21:52:11" itemprop="dateModified" datetime="2020-03-16T21:52:11+08:00">2020-03-16</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="Note-of-ROS-to-Ubantu"><a href="#Note-of-ROS-to-Ubantu" class="headerlink" title="Note of ROS to Ubantu"></a>Note of ROS to Ubantu</h3><h4 id="terminal命令"><a href="#terminal命令" class="headerlink" title="terminal命令"></a>terminal命令</h4><p>echo $PATH： echo $PATH用于列出变量PATH的值，里面包含了已添加的目录</p>
<p>env：env命令是environment的缩写，用于列出所有的环境变量</p>
<p>export：单独使用export命令也可以像env列出所有的环境变量，不过export命令还有其他额外的功能</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/24/New%20Words/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chenyang Min">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="perfectism's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/07/24/New%20Words/" class="post-title-link" itemprop="url">New Words</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-24 13:10:01" itemprop="dateCreated datePublished" datetime="2020-07-24T13:10:01+08:00">2020-07-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-16 21:46:43" itemprop="dateModified" datetime="2020-03-16T21:46:43+08:00">2020-03-16</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="New-Words"><a href="#New-Words" class="headerlink" title="New Words"></a>New Words</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">scalar 标量的</span><br><span class="line">neuron 神经元</span><br><span class="line">neural 神经的</span><br><span class="line">vector 向量</span><br><span class="line">parameter 参数</span><br><span class="line">gradient descent 梯度下降</span><br><span class="line">backpropagation 反向传播</span><br><span class="line">sentiment 感情、情绪</span><br><span class="line">embedded 嵌入的、植入的</span><br><span class="line">trimming 整理、修剪、切除</span><br><span class="line">syntactic parsing 语法分析</span><br><span class="line">semantic analysis 语义分析</span><br><span class="line">indicator 指示器，指示符</span><br><span class="line">shallow 浅的</span><br><span class="line">adversarial 对抗的</span><br><span class="line">indent 缩进</span><br><span class="line">contour 轮廓</span><br><span class="line">approx&#x3D;approxiate 大约的</span><br><span class="line">hierarchy 层级，等级制度</span><br><span class="line">Skeleton Joint 骨骼关节</span><br><span class="line">Semantic Segmentation 语义分割</span><br><span class="line">advent 来临</span><br><span class="line">gaze 注视</span><br><span class="line">row 行</span><br><span class="line">colunm 列</span><br><span class="line">extremum 极值</span><br><span class="line">gray level 灰度</span><br><span class="line">entropy 熵</span><br><span class="line">stochastic 随机的，猜测的</span><br><span class="line">crop 修剪，种植</span><br><span class="line">shuffle 随机播放，打乱顺序</span><br><span class="line">transpose 调换，转置</span><br><span class="line">precisely 恰好地</span><br><span class="line">dilation 扩张</span><br><span class="line">co-adaptation 过拟合</span><br><span class="line">syllabus 教学摘要，课程表</span><br><span class="line">spatial 空间的</span><br><span class="line">stochastic 随机的</span><br><span class="line">bottleneck 瓶颈</span><br><span class="line">geometry 几何结构</span><br><span class="line">plain 平的，简单的，朴素的</span><br><span class="line">Fine-tune 微调</span><br><span class="line">spatial 空间的</span><br><span class="line">sparse 稀疏的</span><br><span class="line">backend 后端</span><br><span class="line">attribute 属性</span><br><span class="line">deque 双端队列</span><br><span class="line">combat 反抗战斗</span><br><span class="line">temporal，temporary 暂时的</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Chenyang Min</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">25</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">分类</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chenyang Min</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  


</body>
</html>
