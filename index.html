<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":false,"nav":null,"activeClass":"gitalk"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":"trut","trigger":"auto","top_n_per_article":5,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="perfectism&#39;s blog">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="perfectism&#39;s blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Chenyang Min">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yoursite.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>perfectism's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">perfectism's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/perfectism13" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/24/%E7%94%A8Keras%E5%AE%9E%E7%8E%B0%E8%A7%86%E9%A2%91%E5%8A%A8%E4%BD%9C%E5%88%86%E7%B1%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chenyang Min">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="perfectism's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/07/24/%E7%94%A8Keras%E5%AE%9E%E7%8E%B0%E8%A7%86%E9%A2%91%E5%8A%A8%E4%BD%9C%E5%88%86%E7%B1%BB/" class="post-title-link" itemprop="url">用Keras实现视频动作分类</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-24 13:10:01" itemprop="dateCreated datePublished" datetime="2020-07-24T13:10:01+08:00">2020-07-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-16 21:36:26" itemprop="dateModified" datetime="2020-03-16T21:36:26+08:00">2020-03-16</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="用Keras实现视频动作分类"><a href="#用Keras实现视频动作分类" class="headerlink" title="用Keras实现视频动作分类"></a>用Keras实现视频动作分类</h1><p>使用LSTM或者RNN处理时序信息太费时间</p>
<p>所以我们先训练一个用于图片上运动信息分类的CNN，通过采用一种滚动平均的方法将其应用在视频分类中</p>
<h3 id="普通方法"><a href="#普通方法" class="headerlink" title="普通方法"></a>普通方法</h3><ol>
<li>Loop over all frames in the video file</li>
<li>For each frame, pass the frame through the CNN</li>
<li>Classify each frame <em>individually</em> and <em>independently</em> of each other</li>
<li>Choose the label with the largest corresponding probability</li>
<li>Label the frame and write the output frame to disk</li>
</ol>
<p>if you’ve ever tried to apply simple image classification to video classification you likely encountered a sort of <strong>“prediction flickering”</strong>（预测闪烁）</p>
<p>因此如何避免CNN模型在两个标签之间闪烁很重要</p>
<h3 id="使用滚动平均方法（rolling-prediction-average）"><a href="#使用滚动平均方法（rolling-prediction-average）" class="headerlink" title="使用滚动平均方法（rolling prediction average）"></a>使用滚动平均方法（<strong>rolling prediction average</strong>）</h3><p>假设视频里的随后几帧含有相同的语义内容</p>
<ol>
<li>Loop over all frames in the video file</li>
<li>For each frame, pass the frame through the CNN</li>
<li>Obtain the predictions from the CNN</li>
<li>Maintain a list of the last <em>K</em> predictions</li>
<li>Compute the average of the last <em>K</em> predictions and choose the label with the largest corresponding probability（假设每个视频帧有三个概率输出，则将3xK平均为单个3，然后取概率最大的标签）</li>
<li>Label the frame and write the output frame to disk</li>
</ol>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>代码链接：</p>
<p><a href="https://github.com/perfectism13/learning_colab" target="_blank" rel="noopener">https://github.com/perfectism13/learning_colab</a></p>
<h3 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">from google.colab import drive</span><br><span class="line">drive.mount(&#39;&#x2F;content&#x2F;drive&#39;)</span><br><span class="line">import os</span><br><span class="line">os.chdir(r&#39;&#x2F;content&#x2F;drive&#x2F;My Drive&#x2F;colab&#x2F;keras-video-classification&#x2F;keras-video-classification&#39;)</span><br><span class="line">print(os.getcwd())</span><br><span class="line">!ls</span><br><span class="line">!apt-get install p7zip</span><br><span class="line">!7z x sports-type-classifier-data.7z</span><br><span class="line">!ls</span><br><span class="line">!tree --dirsfirst --filelimit 50</span><br></pre></td></tr></table></figure>
<h3 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br></pre></td><td class="code"><pre><span class="line"># USAGE</span><br><span class="line"># python train.py --dataset Sports-Type-Classifier&#x2F;data --model model&#x2F;activity.model --label-bin model&#x2F;lb.pickle --epochs 50</span><br><span class="line"></span><br><span class="line"># set the matplotlib backend so figures can be saved in the background</span><br><span class="line">import matplotlib</span><br><span class="line">matplotlib.use(&quot;Agg&quot;)</span><br><span class="line"></span><br><span class="line"># import the necessary packages</span><br><span class="line">from keras.preprocessing.image import ImageDataGenerator</span><br><span class="line">from keras.layers.pooling import AveragePooling2D</span><br><span class="line">from keras.applications import ResNet50</span><br><span class="line">from keras.layers.core import Dropout</span><br><span class="line">from keras.layers.core import Flatten</span><br><span class="line">from keras.layers.core import Dense</span><br><span class="line">from keras.layers import Input</span><br><span class="line">from keras.models import Model</span><br><span class="line">from keras.optimizers import SGD</span><br><span class="line">from sklearn.preprocessing import LabelBinarizer</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.metrics import classification_report</span><br><span class="line">from imutils import paths</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line">import argparse</span><br><span class="line">import pickle</span><br><span class="line">import cv2</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line"># construct the argument parser and parse the arguments</span><br><span class="line"># 构建python文件运行时的命令行输入</span><br><span class="line">ap &#x3D; argparse.ArgumentParser()</span><br><span class="line">ap.add_argument(&quot;-d&quot;, &quot;--dataset&quot;, required&#x3D;True,</span><br><span class="line">	help&#x3D;&quot;path to input dataset&quot;)</span><br><span class="line">ap.add_argument(&quot;-m&quot;, &quot;--model&quot;, required&#x3D;True,</span><br><span class="line">	help&#x3D;&quot;path to output serialized model&quot;)</span><br><span class="line">ap.add_argument(&quot;-l&quot;, &quot;--label-bin&quot;, required&#x3D;True,</span><br><span class="line">	help&#x3D;&quot;path to output label binarizer&quot;)</span><br><span class="line">ap.add_argument(&quot;-e&quot;, &quot;--epochs&quot;, type&#x3D;int, default&#x3D;25,</span><br><span class="line">	help&#x3D;&quot;# of epochs to train our network for&quot;)</span><br><span class="line">ap.add_argument(&quot;-p&quot;, &quot;--plot&quot;, type&#x3D;str, default&#x3D;&quot;plot.png&quot;,</span><br><span class="line">	help&#x3D;&quot;path to output loss&#x2F;accuracy plot&quot;)</span><br><span class="line">args &#x3D; vars(ap.parse_args())</span><br><span class="line"></span><br><span class="line"># initialize the set of labels from the spots activity dataset we are</span><br><span class="line"># going to train our network on</span><br><span class="line">LABELS &#x3D; set([&quot;weight_lifting&quot;, &quot;tennis&quot;, &quot;football&quot;])</span><br><span class="line"></span><br><span class="line"># grab the list of images in our dataset directory, then initialize</span><br><span class="line"># the list of data (i.e., images) and class images</span><br><span class="line">print(&quot;[INFO] loading images...&quot;)</span><br><span class="line"># 通过imtuils的paths类获取dataset对应路径下所有图片的路径</span><br><span class="line">imagePaths &#x3D; list(paths.list_images(args[&quot;dataset&quot;])) </span><br><span class="line">data &#x3D; []</span><br><span class="line">labels &#x3D; []</span><br><span class="line"></span><br><span class="line"># loop over the image paths</span><br><span class="line">for imagePath in imagePaths:</span><br><span class="line">	# extract the class label from the filename</span><br><span class="line">	label &#x3D; imagePath.split(os.path.sep)[-2]</span><br><span class="line"></span><br><span class="line">	# if the label of the current image is not part of of the labels</span><br><span class="line">	# are interested in, then ignore the image</span><br><span class="line">	# 跳过不参与训练的标签对应的图片</span><br><span class="line">	if label not in LABELS:</span><br><span class="line">		continue</span><br><span class="line"></span><br><span class="line">	# load the image, convert it to RGB channel ordering, and resize</span><br><span class="line">	# it to be a fixed 224x224 pixels, ignoring aspect ratio</span><br><span class="line">	image &#x3D; cv2.imread(imagePath)</span><br><span class="line">	image &#x3D; cv2.cvtColor(image, cv2.COLOR_BGR2RGB)</span><br><span class="line">	image &#x3D; cv2.resize(image, (224, 224))</span><br><span class="line"></span><br><span class="line">	# update the data and labels lists, respectively</span><br><span class="line">	# 储存训练标签和图片</span><br><span class="line">	data.append(image)</span><br><span class="line">	labels.append(label)</span><br><span class="line"></span><br><span class="line"># convert the data and labels to NumPy arrays</span><br><span class="line"># 将数据和标签转换成numpy数组</span><br><span class="line">data &#x3D; np.array(data)</span><br><span class="line">labels &#x3D; np.array(labels)</span><br><span class="line"></span><br><span class="line"># perform one-hot encoding on the labels</span><br><span class="line"># 通过二值元素数组来对标签进行一键编码</span><br><span class="line">lb &#x3D; LabelBinarizer()</span><br><span class="line">labels &#x3D; lb.fit_transform(labels)</span><br><span class="line"></span><br><span class="line"># partition the data into training and testing splits using 75% of</span><br><span class="line"># the data for training and the remaining 25% for testing</span><br><span class="line"># 将整个数据的%75用来训练剩下的用来检验</span><br><span class="line">(trainX, testX, trainY, testY) &#x3D; train_test_split(data, labels,</span><br><span class="line">	test_size&#x3D;0.25, stratify&#x3D;labels, random_state&#x3D;42)</span><br><span class="line"></span><br><span class="line"># initialize the training data augmentation object</span><br><span class="line"># 声明训练时的数据增强操作</span><br><span class="line">trainAug &#x3D; ImageDataGenerator(</span><br><span class="line">	rotation_range&#x3D;30,</span><br><span class="line">	zoom_range&#x3D;0.15,</span><br><span class="line">	width_shift_range&#x3D;0.2,</span><br><span class="line">	height_shift_range&#x3D;0.2,</span><br><span class="line">	shear_range&#x3D;0.15,</span><br><span class="line">	horizontal_flip&#x3D;True,</span><br><span class="line">	fill_mode&#x3D;&quot;nearest&quot;)</span><br><span class="line"></span><br><span class="line"># initialize the validation&#x2F;testing data augmentation object (which</span><br><span class="line"># we&#39;ll be adding mean subtraction to)</span><br><span class="line"># 测验时无数据增强操作</span><br><span class="line">valAug &#x3D; ImageDataGenerator()</span><br><span class="line"></span><br><span class="line"># define the ImageNet mean subtraction (in RGB order) and set the</span><br><span class="line"># the mean subtraction value for each of the data augmentation</span><br><span class="line"># objects</span><br><span class="line"># 设置训练和测试时用来归一化的图片每个通道的均值</span><br><span class="line">mean &#x3D; np.array([123.68, 116.779, 103.939], dtype&#x3D;&quot;float32&quot;)</span><br><span class="line">trainAug.mean &#x3D; mean</span><br><span class="line">valAug.mean &#x3D; mean</span><br><span class="line"></span><br><span class="line"># load the ResNet-50 network, ensuring the head FC layer sets are left</span><br><span class="line"># off</span><br><span class="line"># 通过keras.applications来获取预训练的resnet50模型</span><br><span class="line">baseModel &#x3D; ResNet50(weights&#x3D;&quot;imagenet&quot;, include_top&#x3D;False,</span><br><span class="line">	input_tensor&#x3D;Input(shape&#x3D;(224, 224, 3)))</span><br><span class="line"></span><br><span class="line"># construct the head of the model that will be placed on top of the</span><br><span class="line"># the base model</span><br><span class="line"># 定义basemodel前的全连接层</span><br><span class="line">headModel &#x3D; baseModel.output</span><br><span class="line">headModel &#x3D; AveragePooling2D(pool_size&#x3D;(7, 7))(headModel)</span><br><span class="line">headModel &#x3D; Flatten(name&#x3D;&quot;flatten&quot;)(headModel)</span><br><span class="line">headModel &#x3D; Dense(512, activation&#x3D;&quot;relu&quot;)(headModel)</span><br><span class="line">headModel &#x3D; Dropout(0.5)(headModel)</span><br><span class="line">headModel &#x3D; Dense(len(lb.classes_), activation&#x3D;&quot;softmax&quot;)(headModel)</span><br><span class="line"></span><br><span class="line"># place the head FC model on top of the base model (this will become</span><br><span class="line"># the actual model we will train)</span><br><span class="line"># 在basemodel前加上一个全连接层来微调</span><br><span class="line">model &#x3D; Model(inputs&#x3D;baseModel.input, outputs&#x3D;headModel)</span><br><span class="line"></span><br><span class="line"># loop over all layers in the base model and freeze them so they will</span><br><span class="line"># *not* be updated during the training process</span><br><span class="line"># 训练时将basemodel里的全部参数冻结</span><br><span class="line">for layer in baseModel.layers:</span><br><span class="line">	layer.trainable &#x3D; False</span><br><span class="line"></span><br><span class="line"># compile our model (this needs to be done after our setting our</span><br><span class="line"># layers to being non-trainable)</span><br><span class="line"># 定义初始学习率和优化方法来编译模型</span><br><span class="line">print(&quot;[INFO] compiling model...&quot;)</span><br><span class="line">opt &#x3D; SGD(lr&#x3D;1e-4, momentum&#x3D;0.9, decay&#x3D;1e-4 &#x2F; args[&quot;epochs&quot;])</span><br><span class="line">model.compile(loss&#x3D;&quot;categorical_crossentropy&quot;, optimizer&#x3D;opt,</span><br><span class="line">	metrics&#x3D;[&quot;accuracy&quot;])</span><br><span class="line"></span><br><span class="line"># train the head of the network for a few epochs (all other layers</span><br><span class="line"># are frozen) -- this will allow the new FC layers to start to become</span><br><span class="line"># initialized with actual &quot;learned&quot; values versus pure random</span><br><span class="line"># 使用fit_generator类来对逐批生成的数据进行训练</span><br><span class="line">print(&quot;[INFO] training head...&quot;)</span><br><span class="line">H &#x3D; model.fit_generator(</span><br><span class="line">	trainAug.flow(trainX, trainY, batch_size&#x3D;32),</span><br><span class="line">	steps_per_epoch&#x3D;len(trainX) &#x2F;&#x2F; 32,</span><br><span class="line">	validation_data&#x3D;valAug.flow(testX, testY),</span><br><span class="line">	validation_steps&#x3D;len(testX) &#x2F;&#x2F; 32,</span><br><span class="line">	epochs&#x3D;args[&quot;epochs&quot;])</span><br><span class="line"></span><br><span class="line"># evaluate the network</span><br><span class="line"># 使用sklearn的classification_report类查看预测效果</span><br><span class="line">print(&quot;[INFO] evaluating network...&quot;)</span><br><span class="line">predictions &#x3D; model.predict(testX, batch_size&#x3D;32)</span><br><span class="line">print(classification_report(testY.argmax(axis&#x3D;1), </span><br><span class="line">	predictions.argmax(axis&#x3D;1), target_names&#x3D;lb.classes_))</span><br><span class="line"></span><br><span class="line"># plot the training loss and accuracy</span><br><span class="line"># 打印训练loss和准确性等</span><br><span class="line">N &#x3D; args[&quot;epochs&quot;]</span><br><span class="line">plt.style.use(&quot;ggplot&quot;)</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(np.arange(0, N), H.history[&quot;loss&quot;], label&#x3D;&quot;train_loss&quot;)</span><br><span class="line">plt.plot(np.arange(0, N), H.history[&quot;val_loss&quot;], label&#x3D;&quot;val_loss&quot;)</span><br><span class="line">plt.plot(np.arange(0, N), H.history[&quot;acc&quot;], label&#x3D;&quot;train_acc&quot;)</span><br><span class="line">plt.plot(np.arange(0, N), H.history[&quot;val_acc&quot;], label&#x3D;&quot;val_acc&quot;)</span><br><span class="line">plt.title(&quot;Training Loss and Accuracy on Dataset&quot;)</span><br><span class="line">plt.xlabel(&quot;Epoch #&quot;)</span><br><span class="line">plt.ylabel(&quot;Loss&#x2F;Accuracy&quot;)</span><br><span class="line">plt.legend(loc&#x3D;&quot;lower left&quot;) # 标签说明放在左下角</span><br><span class="line">plt.savefig(args[&quot;plot&quot;])</span><br><span class="line"></span><br><span class="line"># serialize the model to disk</span><br><span class="line"># 讲训练好的模型保存</span><br><span class="line">print(&quot;[INFO] serializing network...&quot;)</span><br><span class="line">model.save(args[&quot;model&quot;])</span><br><span class="line"></span><br><span class="line"># serialize the label binarizer to disk</span><br><span class="line"># 保存标签二值化器</span><br><span class="line">f &#x3D; open(args[&quot;label_bin&quot;], &quot;wb&quot;)</span><br><span class="line">f.write(pickle.dumps(lb))</span><br><span class="line">f.close()</span><br><span class="line">!python train.py --dataset data --model output&#x2F;activity.model \</span><br><span class="line">	--label-bin output&#x2F;lb.pickle --epochs 50</span><br><span class="line">Using TensorFlow backend.</span><br><span class="line">[INFO] loading images...</span><br><span class="line">libpng warning: iCCP: known incorrect sRGB profile</span><br><span class="line">libpng warning: iCCP: known incorrect sRGB profile</span><br><span class="line">libpng warning: iCCP: known incorrect sRGB profile</span><br><span class="line">libpng warning: iCCP: known incorrect sRGB profile</span><br><span class="line">libpng warning: iCCP: known incorrect sRGB profile</span><br><span class="line">WARNING:tensorflow:From &#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.6&#x2F;dist-packages&#x2F;keras&#x2F;backend&#x2F;tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.</span><br><span class="line"></span><br><span class="line">WARNING:tensorflow:From &#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.6&#x2F;dist-packages&#x2F;keras&#x2F;backend&#x2F;tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.</span><br><span class="line"></span><br><span class="line">WARNING:tensorflow:From &#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.6&#x2F;dist-packages&#x2F;keras&#x2F;backend&#x2F;tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.</span><br><span class="line"></span><br><span class="line">WARNING:tensorflow:From &#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.6&#x2F;dist-packages&#x2F;keras&#x2F;backend&#x2F;tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.</span><br><span class="line"></span><br><span class="line">WARNING:tensorflow:From &#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.6&#x2F;dist-packages&#x2F;keras&#x2F;backend&#x2F;tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.</span><br><span class="line"></span><br><span class="line">WARNING:tensorflow:From &#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.6&#x2F;dist-packages&#x2F;keras&#x2F;backend&#x2F;tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.</span><br><span class="line"></span><br><span class="line">2019-12-14 08:24:02.011318: I tensorflow&#x2F;core&#x2F;platform&#x2F;profile_utils&#x2F;cpu_utils.cc:94] CPU Frequency: 2300000000 Hz</span><br><span class="line">2019-12-14 08:24:02.013846: I tensorflow&#x2F;compiler&#x2F;xla&#x2F;service&#x2F;service.cc:168] XLA service 0x2306840 initialized for platform Host (this does not guarantee that XLA will be used). Devices:</span><br><span class="line">2019-12-14 08:24:02.013885: I tensorflow&#x2F;compiler&#x2F;xla&#x2F;service&#x2F;service.cc:176]   StreamExecutor device (0): Host, Default Version</span><br><span class="line">2019-12-14 08:24:02.018815: I tensorflow&#x2F;stream_executor&#x2F;platform&#x2F;default&#x2F;dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1</span><br><span class="line">2019-12-14 08:24:02.152830: I tensorflow&#x2F;stream_executor&#x2F;cuda&#x2F;cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero</span><br><span class="line">2019-12-14 08:24:02.153830: I tensorflow&#x2F;compiler&#x2F;xla&#x2F;service&#x2F;service.cc:168] XLA service 0x2306bc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:</span><br><span class="line">2019-12-14 08:24:02.153865: I tensorflow&#x2F;compiler&#x2F;xla&#x2F;service&#x2F;service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7</span><br><span class="line">2019-12-14 08:24:02.155504: I tensorflow&#x2F;stream_executor&#x2F;cuda&#x2F;cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero</span><br><span class="line">2019-12-14 08:24:02.156205: I tensorflow&#x2F;core&#x2F;common_runtime&#x2F;gpu&#x2F;gpu_device.cc:1618] Found device 0 with properties: </span><br><span class="line">name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235</span><br><span class="line">pciBusID: 0000:00:04.0</span><br><span class="line">2019-12-14 08:24:02.176292: I tensorflow&#x2F;stream_executor&#x2F;platform&#x2F;default&#x2F;dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1</span><br><span class="line">2019-12-14 08:24:02.394209: I tensorflow&#x2F;stream_executor&#x2F;platform&#x2F;default&#x2F;dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10</span><br><span class="line">2019-12-14 08:24:02.508460: I tensorflow&#x2F;stream_executor&#x2F;platform&#x2F;default&#x2F;dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10</span><br><span class="line">2019-12-14 08:24:02.530840: I tensorflow&#x2F;stream_executor&#x2F;platform&#x2F;default&#x2F;dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10</span><br><span class="line">2019-12-14 08:24:02.748284: I tensorflow&#x2F;stream_executor&#x2F;platform&#x2F;default&#x2F;dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10</span><br><span class="line">2019-12-14 08:24:02.770949: I tensorflow&#x2F;stream_executor&#x2F;platform&#x2F;default&#x2F;dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10</span><br><span class="line">2019-12-14 08:24:03.213586: I tensorflow&#x2F;stream_executor&#x2F;platform&#x2F;default&#x2F;dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7</span><br><span class="line">2019-12-14 08:24:03.213829: I tensorflow&#x2F;stream_executor&#x2F;cuda&#x2F;cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero</span><br><span class="line">2019-12-14 08:24:03.214779: I tensorflow&#x2F;stream_executor&#x2F;cuda&#x2F;cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero</span><br><span class="line">2019-12-14 08:24:03.215576: I tensorflow&#x2F;core&#x2F;common_runtime&#x2F;gpu&#x2F;gpu_device.cc:1746] Adding visible gpu devices: 0</span><br><span class="line">2019-12-14 08:24:03.220635: I tensorflow&#x2F;stream_executor&#x2F;platform&#x2F;default&#x2F;dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1</span><br><span class="line">2019-12-14 08:24:03.222331: I tensorflow&#x2F;core&#x2F;common_runtime&#x2F;gpu&#x2F;gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:</span><br><span class="line">2019-12-14 08:24:03.222385: I tensorflow&#x2F;core&#x2F;common_runtime&#x2F;gpu&#x2F;gpu_device.cc:1165]      0 </span><br><span class="line">2019-12-14 08:24:03.222418: I tensorflow&#x2F;core&#x2F;common_runtime&#x2F;gpu&#x2F;gpu_device.cc:1178] 0:   N </span><br><span class="line">2019-12-14 08:24:03.223491: I tensorflow&#x2F;stream_executor&#x2F;cuda&#x2F;cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero</span><br><span class="line">2019-12-14 08:24:03.224341: I tensorflow&#x2F;stream_executor&#x2F;cuda&#x2F;cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero</span><br><span class="line">2019-12-14 08:24:03.225215: W tensorflow&#x2F;core&#x2F;common_runtime&#x2F;gpu&#x2F;gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.</span><br><span class="line">2019-12-14 08:24:03.225289: I tensorflow&#x2F;core&#x2F;common_runtime&#x2F;gpu&#x2F;gpu_device.cc:1304] Created TensorFlow device (&#x2F;job:localhost&#x2F;replica:0&#x2F;task:0&#x2F;device:GPU:0 with 10805 MB memory) -&gt; physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)</span><br><span class="line">WARNING:tensorflow:From &#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.6&#x2F;dist-packages&#x2F;keras&#x2F;backend&#x2F;tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.</span><br><span class="line"></span><br><span class="line">WARNING:tensorflow:From &#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.6&#x2F;dist-packages&#x2F;keras&#x2F;backend&#x2F;tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.</span><br><span class="line"></span><br><span class="line">WARNING:tensorflow:From &#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.6&#x2F;dist-packages&#x2F;keras&#x2F;backend&#x2F;tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.</span><br><span class="line"></span><br><span class="line">WARNING:tensorflow:From &#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.6&#x2F;dist-packages&#x2F;keras&#x2F;backend&#x2F;tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.</span><br><span class="line"></span><br><span class="line">WARNING:tensorflow:From &#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.6&#x2F;dist-packages&#x2F;keras&#x2F;backend&#x2F;tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.</span><br><span class="line"></span><br><span class="line">WARNING:tensorflow:From &#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.6&#x2F;dist-packages&#x2F;keras&#x2F;backend&#x2F;tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.</span><br><span class="line"></span><br><span class="line">&#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.6&#x2F;dist-packages&#x2F;keras_applications&#x2F;resnet50.py:265: UserWarning: The output shape of &#96;ResNet50(include_top&#x3D;False)&#96; has been changed since Keras 2.2.0.</span><br><span class="line">  warnings.warn(&#39;The output shape of &#96;ResNet50(include_top&#x3D;False)&#96; &#39;</span><br><span class="line">Downloading data from https:&#x2F;&#x2F;github.com&#x2F;fchollet&#x2F;deep-learning-models&#x2F;releases&#x2F;download&#x2F;v0.2&#x2F;resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5</span><br><span class="line">94658560&#x2F;94653016 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 7s 0us&#x2F;step</span><br><span class="line">WARNING:tensorflow:From &#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.6&#x2F;dist-packages&#x2F;keras&#x2F;backend&#x2F;tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.</span><br><span class="line"></span><br><span class="line">WARNING:tensorflow:From &#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.6&#x2F;dist-packages&#x2F;keras&#x2F;backend&#x2F;tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.</span><br><span class="line"></span><br><span class="line">WARNING:tensorflow:From &#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.6&#x2F;dist-packages&#x2F;keras&#x2F;backend&#x2F;tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.</span><br><span class="line">Instructions for updating:</span><br><span class="line">Please use &#96;rate&#96; instead of &#96;keep_prob&#96;. Rate should be set to &#96;rate &#x3D; 1 - keep_prob&#96;.</span><br><span class="line">[INFO] compiling model...</span><br><span class="line">WARNING:tensorflow:From &#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.6&#x2F;dist-packages&#x2F;keras&#x2F;optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.</span><br><span class="line"></span><br><span class="line">WARNING:tensorflow:From &#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.6&#x2F;dist-packages&#x2F;keras&#x2F;backend&#x2F;tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.</span><br><span class="line"></span><br><span class="line">[INFO] training head...</span><br><span class="line">WARNING:tensorflow:From &#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.6&#x2F;dist-packages&#x2F;tensorflow_core&#x2F;python&#x2F;ops&#x2F;math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.</span><br><span class="line">Instructions for updating:</span><br><span class="line">Use tf.where in 2.0, which has the same broadcast rule as np.where</span><br><span class="line">WARNING:tensorflow:From &#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.6&#x2F;dist-packages&#x2F;keras&#x2F;backend&#x2F;tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.</span><br><span class="line"></span><br><span class="line">WARNING:tensorflow:From &#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.6&#x2F;dist-packages&#x2F;keras&#x2F;backend&#x2F;tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.</span><br><span class="line"></span><br><span class="line">Epoch 1&#x2F;50</span><br><span class="line">2019-12-14 08:24:25.840365: I tensorflow&#x2F;stream_executor&#x2F;platform&#x2F;default&#x2F;dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10</span><br><span class="line">2019-12-14 08:24:26.891772: I tensorflow&#x2F;stream_executor&#x2F;platform&#x2F;default&#x2F;dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 29s 597ms&#x2F;step - loss: 1.2660 - acc: 0.3822 - val_loss: 0.9862 - val_acc: 0.5332</span><br><span class="line">Epoch 2&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 24s 504ms&#x2F;step - loss: 1.0399 - acc: 0.4962 - val_loss: 0.8028 - val_acc: 0.6337</span><br><span class="line">Epoch 3&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 24s 496ms&#x2F;step - loss: 0.8882 - acc: 0.5950 - val_loss: 0.6543 - val_acc: 0.7119</span><br><span class="line">Epoch 4&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 23s 478ms&#x2F;step - loss: 0.8053 - acc: 0.6517 - val_loss: 0.5938 - val_acc: 0.7510</span><br><span class="line">Epoch 5&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 23s 479ms&#x2F;step - loss: 0.7165 - acc: 0.6940 - val_loss: 0.4964 - val_acc: 0.8045</span><br><span class="line">Epoch 6&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 24s 490ms&#x2F;step - loss: 0.6342 - acc: 0.7500 - val_loss: 0.4970 - val_acc: 0.8148</span><br><span class="line">Epoch 7&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 23s 471ms&#x2F;step - loss: 0.6217 - acc: 0.7526 - val_loss: 0.4313 - val_acc: 0.8313</span><br><span class="line">Epoch 8&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 22s 464ms&#x2F;step - loss: 0.5881 - acc: 0.7832 - val_loss: 0.3984 - val_acc: 0.8683</span><br><span class="line">Epoch 9&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 23s 475ms&#x2F;step - loss: 0.5611 - acc: 0.7741 - val_loss: 0.4083 - val_acc: 0.8498</span><br><span class="line">Epoch 10&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 23s 471ms&#x2F;step - loss: 0.5241 - acc: 0.8073 - val_loss: 0.3564 - val_acc: 0.8807</span><br><span class="line">Epoch 11&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 22s 459ms&#x2F;step - loss: 0.4947 - acc: 0.8171 - val_loss: 0.3755 - val_acc: 0.8642</span><br><span class="line">Epoch 12&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 22s 467ms&#x2F;step - loss: 0.4841 - acc: 0.8190 - val_loss: 0.3499 - val_acc: 0.8704</span><br><span class="line">Epoch 13&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 22s 463ms&#x2F;step - loss: 0.4801 - acc: 0.8196 - val_loss: 0.3397 - val_acc: 0.8704</span><br><span class="line">Epoch 14&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 22s 455ms&#x2F;step - loss: 0.4430 - acc: 0.8242 - val_loss: 0.3491 - val_acc: 0.8786</span><br><span class="line">Epoch 15&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 22s 456ms&#x2F;step - loss: 0.4179 - acc: 0.8477 - val_loss: 0.2985 - val_acc: 0.8909</span><br><span class="line">Epoch 16&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 22s 448ms&#x2F;step - loss: 0.4189 - acc: 0.8379 - val_loss: 0.3302 - val_acc: 0.8807</span><br><span class="line">Epoch 17&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 22s 454ms&#x2F;step - loss: 0.4167 - acc: 0.8425 - val_loss: 0.3139 - val_acc: 0.8868</span><br><span class="line">Epoch 18&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 22s 464ms&#x2F;step - loss: 0.3985 - acc: 0.8444 - val_loss: 0.3067 - val_acc: 0.8926</span><br><span class="line">Epoch 19&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 21s 447ms&#x2F;step - loss: 0.3881 - acc: 0.8587 - val_loss: 0.3024 - val_acc: 0.8951</span><br><span class="line">Epoch 20&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 22s 459ms&#x2F;step - loss: 0.3944 - acc: 0.8548 - val_loss: 0.2902 - val_acc: 0.8992</span><br><span class="line">Epoch 21&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 21s 446ms&#x2F;step - loss: 0.3782 - acc: 0.8620 - val_loss: 0.2824 - val_acc: 0.9115</span><br><span class="line">Epoch 22&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 21s 440ms&#x2F;step - loss: 0.4034 - acc: 0.8412 - val_loss: 0.3105 - val_acc: 0.9012</span><br><span class="line">Epoch 23&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 22s 461ms&#x2F;step - loss: 0.3600 - acc: 0.8691 - val_loss: 0.2667 - val_acc: 0.9012</span><br><span class="line">Epoch 24&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 22s 456ms&#x2F;step - loss: 0.3357 - acc: 0.8750 - val_loss: 0.2630 - val_acc: 0.9177</span><br><span class="line">Epoch 25&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 21s 440ms&#x2F;step - loss: 0.3411 - acc: 0.8737 - val_loss: 0.3130 - val_acc: 0.8951</span><br><span class="line">Epoch 26&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 22s 460ms&#x2F;step - loss: 0.3312 - acc: 0.8848 - val_loss: 0.2747 - val_acc: 0.9198</span><br><span class="line">Epoch 27&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 22s 448ms&#x2F;step - loss: 0.3401 - acc: 0.8691 - val_loss: 0.2811 - val_acc: 0.9033</span><br><span class="line">Epoch 28&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 21s 445ms&#x2F;step - loss: 0.3326 - acc: 0.8776 - val_loss: 0.2546 - val_acc: 0.9280</span><br><span class="line">Epoch 29&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 21s 442ms&#x2F;step - loss: 0.3445 - acc: 0.8692 - val_loss: 0.2683 - val_acc: 0.9156</span><br><span class="line">Epoch 30&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 22s 454ms&#x2F;step - loss: 0.3072 - acc: 0.8854 - val_loss: 0.2658 - val_acc: 0.9095</span><br><span class="line">Epoch 31&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 22s 449ms&#x2F;step - loss: 0.3029 - acc: 0.8978 - val_loss: 0.2819 - val_acc: 0.9033</span><br><span class="line">Epoch 32&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 22s 457ms&#x2F;step - loss: 0.3123 - acc: 0.8900 - val_loss: 0.2680 - val_acc: 0.9198</span><br><span class="line">Epoch 33&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 22s 450ms&#x2F;step - loss: 0.3020 - acc: 0.8867 - val_loss: 0.2422 - val_acc: 0.9198</span><br><span class="line">Epoch 34&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 22s 463ms&#x2F;step - loss: 0.3244 - acc: 0.8802 - val_loss: 0.2712 - val_acc: 0.9115</span><br><span class="line">Epoch 35&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 22s 462ms&#x2F;step - loss: 0.2898 - acc: 0.8952 - val_loss: 0.2588 - val_acc: 0.9160</span><br><span class="line">Epoch 36&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 22s 454ms&#x2F;step - loss: 0.3157 - acc: 0.8854 - val_loss: 0.2807 - val_acc: 0.9095</span><br><span class="line">Epoch 37&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 22s 465ms&#x2F;step - loss: 0.3021 - acc: 0.8848 - val_loss: 0.2514 - val_acc: 0.9218</span><br><span class="line">Epoch 38&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 22s 453ms&#x2F;step - loss: 0.3053 - acc: 0.8731 - val_loss: 0.2646 - val_acc: 0.9053</span><br><span class="line">Epoch 39&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 22s 454ms&#x2F;step - loss: 0.2845 - acc: 0.8874 - val_loss: 0.2502 - val_acc: 0.9177</span><br><span class="line">Epoch 40&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 21s 443ms&#x2F;step - loss: 0.2850 - acc: 0.8972 - val_loss: 0.2571 - val_acc: 0.9136</span><br><span class="line">Epoch 41&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 22s 461ms&#x2F;step - loss: 0.2892 - acc: 0.8997 - val_loss: 0.2667 - val_acc: 0.9156</span><br><span class="line">Epoch 42&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 22s 450ms&#x2F;step - loss: 0.2804 - acc: 0.8971 - val_loss: 0.2466 - val_acc: 0.9115</span><br><span class="line">Epoch 43&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 21s 436ms&#x2F;step - loss: 0.2756 - acc: 0.8978 - val_loss: 0.2548 - val_acc: 0.9177</span><br><span class="line">Epoch 44&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 21s 445ms&#x2F;step - loss: 0.2730 - acc: 0.9010 - val_loss: 0.2562 - val_acc: 0.9239</span><br><span class="line">Epoch 45&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 21s 443ms&#x2F;step - loss: 0.2724 - acc: 0.9017 - val_loss: 0.2561 - val_acc: 0.9259</span><br><span class="line">Epoch 46&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 22s 455ms&#x2F;step - loss: 0.2871 - acc: 0.8906 - val_loss: 0.2700 - val_acc: 0.9239</span><br><span class="line">Epoch 47&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 22s 456ms&#x2F;step - loss: 0.2734 - acc: 0.9017 - val_loss: 0.2244 - val_acc: 0.9259</span><br><span class="line">Epoch 48&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 22s 453ms&#x2F;step - loss: 0.2570 - acc: 0.9062 - val_loss: 0.2566 - val_acc: 0.9156</span><br><span class="line">Epoch 49&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 22s 450ms&#x2F;step - loss: 0.2457 - acc: 0.9069 - val_loss: 0.2649 - val_acc: 0.9177</span><br><span class="line">Epoch 50&#x2F;50</span><br><span class="line">48&#x2F;48 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 21s 446ms&#x2F;step - loss: 0.2753 - acc: 0.8997 - val_loss: 0.2346 - val_acc: 0.9300</span><br><span class="line">[INFO] evaluating network...</span><br><span class="line">                precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">      football       0.92      0.95      0.93       196</span><br><span class="line">        tennis       0.92      0.91      0.92       179</span><br><span class="line">weight_lifting       0.94      0.91      0.92       143</span><br><span class="line"></span><br><span class="line">      accuracy                           0.92       518</span><br><span class="line">     macro avg       0.93      0.92      0.92       518</span><br><span class="line">  weighted avg       0.92      0.92      0.92       518</span><br><span class="line"></span><br><span class="line">[INFO] serializing network...</span><br></pre></td></tr></table></figure>
<h3 id="用滚动预测平均的方式应用模型到视频分类中"><a href="#用滚动预测平均的方式应用模型到视频分类中" class="headerlink" title="用滚动预测平均的方式应用模型到视频分类中"></a>用滚动预测平均的方式应用模型到视频分类中</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br></pre></td><td class="code"><pre><span class="line"># USAGE</span><br><span class="line"># python predict_video.py --model model&#x2F;activity.model --label-bin model&#x2F;lb.pickle --input example_clips&#x2F;lifting.mp4 --output output&#x2F;lifting_128avg.avi --size 128</span><br><span class="line"></span><br><span class="line"># import the necessary packages</span><br><span class="line">from keras.models import load_model</span><br><span class="line">from collections import deque #用来实现滑动平均</span><br><span class="line">import numpy as np</span><br><span class="line">import argparse</span><br><span class="line">import pickle</span><br><span class="line">import cv2</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line"></span><br><span class="line"># construct the argument parser and parse the arguments</span><br><span class="line">ap &#x3D; argparse.ArgumentParser()</span><br><span class="line">ap.add_argument(&quot;-m&quot;, &quot;--model&quot;, required&#x3D;True,</span><br><span class="line">	help&#x3D;&quot;path to trained serialized model&quot;)</span><br><span class="line">ap.add_argument(&quot;-l&quot;, &quot;--label-bin&quot;, required&#x3D;True,</span><br><span class="line">	help&#x3D;&quot;path to  label binarizer&quot;)</span><br><span class="line">ap.add_argument(&quot;-i&quot;, &quot;--input&quot;, required&#x3D;True,</span><br><span class="line">	help&#x3D;&quot;path to our input video&quot;)</span><br><span class="line">ap.add_argument(&quot;-o&quot;, &quot;--output&quot;, required&#x3D;True,</span><br><span class="line">	help&#x3D;&quot;path to our output video&quot;)</span><br><span class="line">ap.add_argument(&quot;-s&quot;, &quot;--size&quot;, type&#x3D;int, default&#x3D;128,</span><br><span class="line">	help&#x3D;&quot;size of queue for averaging&quot;)</span><br><span class="line">args &#x3D; vars(ap.parse_args())</span><br><span class="line"></span><br><span class="line"># load the trained model and label binarizer from disk</span><br><span class="line"># 从命令行的声明载入训练好的模型以及二值化</span><br><span class="line">print(&quot;[INFO] loading model and label binarizer...&quot;)</span><br><span class="line">model &#x3D; load_model(args[&quot;model&quot;])</span><br><span class="line">lb &#x3D; pickle.loads(open(args[&quot;label_bin&quot;], &quot;rb&quot;).read())</span><br><span class="line"></span><br><span class="line"># initialize the image mean for mean subtraction along with the</span><br><span class="line"># predictions queue</span><br><span class="line">mean &#x3D; np.array([123.68, 116.779, 103.939][::1], dtype&#x3D;&quot;float32&quot;)</span><br><span class="line"># 初始化Q为一个双向序列，deque的尺寸由size决定</span><br><span class="line">Q &#x3D; deque(maxlen&#x3D;args[&quot;size&quot;])</span><br><span class="line"></span><br><span class="line"># initialize the video stream, pointer to output video file, and</span><br><span class="line"># frame dimensions</span><br><span class="line"># 使用opencv的VideoCapture类读取视频流，并初始化视频写入类</span><br><span class="line">vs &#x3D; cv2.VideoCapture(args[&quot;input&quot;])</span><br><span class="line">writer &#x3D; None</span><br><span class="line">(W, H) &#x3D; (None, None)</span><br><span class="line"></span><br><span class="line"># loop over frames from the video file stream</span><br><span class="line"># 循环抓取被测试视频的帧</span><br><span class="line">while True:</span><br><span class="line">	# read the next frame from the file</span><br><span class="line">	(grabbed, frame) &#x3D; vs.read()</span><br><span class="line"></span><br><span class="line">	# if the frame was not grabbed, then we have reached the end</span><br><span class="line">	# of the stream</span><br><span class="line">	# 如果没有抓取到视频帧，则退出</span><br><span class="line">	if not grabbed:</span><br><span class="line">		break</span><br><span class="line"></span><br><span class="line">	# if the frame dimensions are empty, grab them</span><br><span class="line">	if W is None or H is None:</span><br><span class="line">		(H, W) &#x3D; frame.shape[:2]</span><br><span class="line"></span><br><span class="line">	# clone the output frame, then convert it from BGR to RGB</span><br><span class="line">	# ordering, resize the frame to a fixed 224x224, and then</span><br><span class="line">	# perform mean subtraction 归一化操作</span><br><span class="line">	output &#x3D; frame.copy()</span><br><span class="line">	frame &#x3D; cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)</span><br><span class="line">	frame &#x3D; cv2.resize(frame, (224, 224)).astype(&quot;float32&quot;) #改变图像宽和高，像素转移到特定数据类型</span><br><span class="line">	frame -&#x3D; mean</span><br><span class="line"></span><br><span class="line">	# make predictions on the frame and then update the predictions</span><br><span class="line">	# queue</span><br><span class="line">	# 新建一维用来储存每一帧对应的分类结果</span><br><span class="line">	preds &#x3D; model.predict(np.expand_dims(frame, axis&#x3D;0))[0]</span><br><span class="line">	# 将预测值加载Q后面</span><br><span class="line">	Q.append(preds)</span><br><span class="line"></span><br><span class="line">	# perform prediction averaging over the current history of</span><br><span class="line">	# previous predictions</span><br><span class="line">	# 先平均到K个概率输出值，在取最大</span><br><span class="line">	results &#x3D; np.array(Q).mean(axis&#x3D;0)</span><br><span class="line">	i &#x3D; np.argmax(results)</span><br><span class="line">	label &#x3D; lb.classes_[i]</span><br><span class="line"></span><br><span class="line">	# draw the activity on the output frame</span><br><span class="line">	text &#x3D; &quot;activity: &#123;&#125;&quot;.format(label)</span><br><span class="line">	cv2.putText(output, text, (35, 50), cv2.FONT_HERSHEY_SIMPLEX,</span><br><span class="line">		1.25, (0, 255, 0), 5)</span><br><span class="line"></span><br><span class="line">	# check if the video writer is None</span><br><span class="line">	if writer is None:</span><br><span class="line">		# initialize our video writer</span><br><span class="line">		fourcc &#x3D; cv2.VideoWriter_fourcc(*&quot;MJPG&quot;)</span><br><span class="line">		writer &#x3D; cv2.VideoWriter(args[&quot;output&quot;], fourcc, 30,</span><br><span class="line">			(W, H), True)</span><br><span class="line"></span><br><span class="line">	# write the output frame to disk</span><br><span class="line">	writer.write(output)</span><br><span class="line"></span><br><span class="line">	# show the output image</span><br><span class="line">	# 避免cannot connect to X server，此处使用matplotlib</span><br><span class="line">	# cv2.imshow(&quot;Output&quot;, output)</span><br><span class="line">  plt.imshow(output)</span><br><span class="line">	key &#x3D; cv2.waitKey(1) &amp; 0xFF</span><br><span class="line"></span><br><span class="line">	# if the &#96;q&#96; key was pressed, break from the loop</span><br><span class="line">	if key &#x3D;&#x3D; ord(&quot;q&quot;):</span><br><span class="line">		break</span><br><span class="line"></span><br><span class="line"># release the file pointers</span><br><span class="line">print(&quot;[INFO] cleaning up...&quot;)</span><br><span class="line">writer.release()</span><br><span class="line">vs.release()</span><br><span class="line">!sudo apt-get install tree</span><br><span class="line">!tree --dirsfirst --filelimit 50</span><br><span class="line">.</span><br><span class="line">├── data</span><br><span class="line">│   ├── badminton [938 entries exceeds filelimit, not opening dir]</span><br><span class="line">│   ├── baseball [746 entries exceeds filelimit, not opening dir]</span><br><span class="line">│   ├── basketball [495 entries exceeds filelimit, not opening dir]</span><br><span class="line">│   ├── boxing [705 entries exceeds filelimit, not opening dir]</span><br><span class="line">│   ├── chess [481 entries exceeds filelimit, not opening dir]</span><br><span class="line">│   ├── cricket [715 entries exceeds filelimit, not opening dir]</span><br><span class="line">│   ├── fencing [635 entries exceeds filelimit, not opening dir]</span><br><span class="line">│   ├── football [799 entries exceeds filelimit, not opening dir]</span><br><span class="line">│   ├── formula1 [687 entries exceeds filelimit, not opening dir]</span><br><span class="line">│   ├── gymnastics [719 entries exceeds filelimit, not opening dir]</span><br><span class="line">│   ├── hockey [572 entries exceeds filelimit, not opening dir]</span><br><span class="line">│   ├── ice_hockey [715 entries exceeds filelimit, not opening dir]</span><br><span class="line">│   ├── kabaddi [454 entries exceeds filelimit, not opening dir]</span><br><span class="line">│   ├── models</span><br><span class="line">│   │   ├── res50-stage-1.pth</span><br><span class="line">│   │   ├── res50-stage-2.pth</span><br><span class="line">│   │   ├── res50-stage-3.pth</span><br><span class="line">│   │   ├── stage-1.pth</span><br><span class="line">│   │   ├── tmp.pth</span><br><span class="line">│   │   └── unfreeze-stage-1.pth</span><br><span class="line">│   ├── motogp [679 entries exceeds filelimit, not opening dir]</span><br><span class="line">│   ├── shooting [536 entries exceeds filelimit, not opening dir]</span><br><span class="line">│   ├── swimming [689 entries exceeds filelimit, not opening dir]</span><br><span class="line">│   ├── table_tennis [713 entries exceeds filelimit, not opening dir]</span><br><span class="line">│   ├── tennis [718 entries exceeds filelimit, not opening dir]</span><br><span class="line">│   ├── volleyball [713 entries exceeds filelimit, not opening dir]</span><br><span class="line">│   ├── weight_lifting [577 entries exceeds filelimit, not opening dir]</span><br><span class="line">│   ├── wrestling [611 entries exceeds filelimit, not opening dir]</span><br><span class="line">│   ├── wwe [671 entries exceeds filelimit, not opening dir]</span><br><span class="line">│   ├── badminton_urls.txt</span><br><span class="line">│   ├── baseball_urls.txt</span><br><span class="line">│   ├── basketball_urls.txt</span><br><span class="line">│   ├── boxing_urls.txt</span><br><span class="line">│   ├── chess_urls.txt</span><br><span class="line">│   ├── cleaned.csv</span><br><span class="line">│   ├── cricket_urls.txt</span><br><span class="line">│   ├── export.pkl</span><br><span class="line">│   ├── fencing_urls.txt</span><br><span class="line">│   ├── football_urls.txt</span><br><span class="line">│   ├── formula1_urls.txt</span><br><span class="line">│   ├── gymnastics_urls.txt</span><br><span class="line">│   ├── hockey_urls.txt</span><br><span class="line">│   ├── ice_hockey_urls.txt</span><br><span class="line">│   ├── kabaddi_urls.txt</span><br><span class="line">│   ├── motogp_urls.txt</span><br><span class="line">│   ├── shooting_urls.txt</span><br><span class="line">│   ├── swimming_urls.txt</span><br><span class="line">│   ├── table_tennis_urls.txt</span><br><span class="line">│   ├── tennis_urls.txt</span><br><span class="line">│   ├── volleyball_urls.txt</span><br><span class="line">│   ├── weight_lifting_urls.txt</span><br><span class="line">│   ├── wrestling_urls.txt</span><br><span class="line">│   └── wwe_urls.txt</span><br><span class="line">├── example_clips</span><br><span class="line">│   ├── lifting.mp4</span><br><span class="line">│   ├── soccer.mp4</span><br><span class="line">│   └── tennis.mp4</span><br><span class="line">├── model</span><br><span class="line">├── output</span><br><span class="line">│   ├── activity.model</span><br><span class="line">│   ├── lb.pickle</span><br><span class="line">│   ├── tennis_128frames_smoothened.avi</span><br><span class="line">│   ├── tennis_128frames_smoothened (convert-video-online.com).mp4</span><br><span class="line">│   └── tennis_1frame.avi</span><br><span class="line">├── Sports-Type-Classifier</span><br><span class="line">│   ├── readme_images</span><br><span class="line">│   │   ├── acc_sports.png</span><br><span class="line">│   │   ├── cric.png</span><br><span class="line">│   │   ├── heat_cric.png</span><br><span class="line">│   │   ├── si_sports.png</span><br><span class="line">│   │   ├── sports_confusion_matrix.png</span><br><span class="line">│   │   ├── sports_data_aug.png</span><br><span class="line">│   │   └── sports.png</span><br><span class="line">│   ├── README.md</span><br><span class="line">│   └── sports_classifier.ipynb</span><br><span class="line">├── plot.png</span><br><span class="line">├── predict_video.py</span><br><span class="line">├── sports_classifier.ipynb</span><br><span class="line">├── sports-type-classifier-data.7z</span><br><span class="line">├── sports-type-classifier-data.zip</span><br><span class="line">└── train.py</span><br><span class="line"></span><br><span class="line">29 directories, 53 files</span><br><span class="line">!python predict_video.py --model output&#x2F;activity.model \</span><br><span class="line">	--label-bin output&#x2F;lb.pickle \</span><br><span class="line">	--input example_clips&#x2F;lifting.mp4 \</span><br><span class="line">	--output output&#x2F;lifting_128frame.avi \</span><br><span class="line">	--size 128</span><br><span class="line">!python predict_video.py --model output&#x2F;activity.model \</span><br><span class="line">	--label-bin output&#x2F;lb.pickle \</span><br><span class="line">	--input example_clips&#x2F;tennis.mp4 \</span><br><span class="line">	--output output&#x2F;tennis_128frames_smoothened.avi \</span><br><span class="line">	--size 128</span><br></pre></td></tr></table></figure>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol>
<li><a href="https://www.pyimagesearch.com/2019/07/15/video-classification-with-keras-and-deep-learning/" target="_blank" rel="noopener">https://www.pyimagesearch.com/2019/07/15/video-classification-with-keras-and-deep-learning/</a></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/24/%E6%88%91%E7%9A%84CV&DL%E4%B9%8B%E8%B7%AF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chenyang Min">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="perfectism's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/07/24/%E6%88%91%E7%9A%84CV&DL%E4%B9%8B%E8%B7%AF/" class="post-title-link" itemprop="url">我的CV&DL之路</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-24 13:10:01" itemprop="dateCreated datePublished" datetime="2020-07-24T13:10:01+08:00">2020-07-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-07-08 15:55:29" itemprop="dateModified" datetime="2020-07-08T15:55:29+08:00">2020-07-08</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="OpenCV"><a href="#OpenCV" class="headerlink" title="OpenCV"></a>OpenCV</h1><ul>
<li>[ ] OpenCV to python</li>
<li>[ ] OpenCV to c++</li>
</ul>
<h2 id="Foundation"><a href="#Foundation" class="headerlink" title="Foundation"></a>Foundation</h2><ul>
<li>[ ] data structure</li>
<li>[ ] ROS to Ubantu</li>
<li>[ ] python</li>
<li>[ ] c++</li>
<li>[ ] leetcode</li>
</ul>
<h2 id="Deep-Learning"><a href="#Deep-Learning" class="headerlink" title="Deep Learning"></a>Deep Learning</h2><ul>
<li>[x] DNN</li>
<li>[x] CNN</li>
<li>[x] RNN,LSTM</li>
<li>[x] use google colab to train my model</li>
<li>[ ] transfer learning</li>
<li>[ ] deploy</li>
<li>[ ] distributed system</li>
</ul>
<h2 id="Action-Recognition"><a href="#Action-Recognition" class="headerlink" title="Action Recognition"></a>Action Recognition</h2><ul>
<li>[ ] Survey of action recognition</li>
<li>[ ] static action recognition</li>
<li>[ ] action recognition in video</li>
<li>[ ] LSTM to action recognition</li>
<li>[ ] Skeleton-Based Action Recognition</li>
<li>[ ] Use OpenVINO to deploy model</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/24/%E9%97%AE%E9%A2%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chenyang Min">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="perfectism's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/07/24/%E9%97%AE%E9%A2%98/" class="post-title-link" itemprop="url">问题</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-24 13:10:01" itemprop="dateCreated datePublished" datetime="2020-07-24T13:10:01+08:00">2020-07-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-16 21:35:25" itemprop="dateModified" datetime="2020-03-16T21:35:25+08:00">2020-03-16</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>问题：</p>
<ol>
<li><pre><code>frame = cv2.resize(frame, (224, 224)).astype(&quot;float32&quot;)
</code></pre></li>
<li><p>数据预处理是用sklearn比较好还是自带的</p>
</li>
<li><p>动作识别和人体姿态估计（只是识别出骨骼关键点）有关系吗</p>
</li>
<li><p>光流法能用在动作识别上吗</p>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/24/%E9%9A%8F%E7%AC%94/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chenyang Min">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="perfectism's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/07/24/%E9%9A%8F%E7%AC%94/" class="post-title-link" itemprop="url">随笔</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-24 13:10:01" itemprop="dateCreated datePublished" datetime="2020-07-24T13:10:01+08:00">2020-07-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-16 21:51:50" itemprop="dateModified" datetime="2020-03-16T21:51:50+08:00">2020-03-16</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="随笔"><a href="#随笔" class="headerlink" title="随笔"></a>随笔</h1><h4 id="2019-2-16"><a href="#2019-2-16" class="headerlink" title="2019.2.16"></a>2019.2.16</h4><p>有的时候其实要及时行乐，不去想那些没有发生的事情，豁达一点，其实事情并没有想象的那么重要，那么糟糕，但是当人们真正面对的时候，往往头脑冲动，自甘堕落，一直活在对过去的内疚和对未来的恐惧中，这其实是很可悲的。</p>
<h4 id="2019-2-19"><a href="#2019-2-19" class="headerlink" title="2019.2.19"></a>2019.2.19</h4><p>有的时候多希望梦境是真的，因为在梦里人可以无所畏惧，有的时候如果入梦太深，尽管处于半睡半醒的状态，但还是不愿醒来，不情愿的醒来之后，会感到很失落，就像看一部电影，看到落幕，却发现主角并不是自己一样。</p>
<h4 id="2019-2-23"><a href="#2019-2-23" class="headerlink" title="2019.2.23"></a>2019.2.23</h4><p>记得哪里曾经说过，当一个人开始回忆过去时便开始衰老了，我想大多数人都想象不到自己会变成什么样的人或许丑陋，或许高尚，回忆过去的原因可能是因为那种心灵的疲惫让自己羡慕心底对未来的向往吧</p>
<h4 id="2019-2-24"><a href="#2019-2-24" class="headerlink" title="2019.2.24"></a>2019.2.24</h4><p>家庭环境是对一个人的性格影响最大的，就拿家境不是很好的我来说，总是不够自信，太过自卑，把有些事情看的太重，或者说太敏感，其实有时候自信一点，放开一点，结果会更好，加油吧，少年！</p>
<h4 id="2019-11-04于天马公寓"><a href="#2019-11-04于天马公寓" class="headerlink" title="2019.11.04于天马公寓"></a>2019.11.04于天马公寓</h4><p>这短短的一生我们最终都会失去，不妨大胆一点，爱一个人，攀一座山，追一个梦。说的多好呀，但是有多少人能够大胆起来</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/24/%E4%BD%BF%E7%94%A8Google%20Colab%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chenyang Min">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="perfectism's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/07/24/%E4%BD%BF%E7%94%A8Google%20Colab%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/" class="post-title-link" itemprop="url">使用Google Colab训练模型</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-24 13:10:01" itemprop="dateCreated datePublished" datetime="2020-07-24T13:10:01+08:00">2020-07-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-16 21:39:33" itemprop="dateModified" datetime="2020-03-16T21:39:33+08:00">2020-03-16</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="使用Google-Colab训练模型"><a href="#使用Google-Colab训练模型" class="headerlink" title="使用Google Colab训练模型"></a>使用Google Colab训练模型</h1><h2 id="挂载Google-Drive并修改运行路径"><a href="#挂载Google-Drive并修改运行路径" class="headerlink" title="挂载Google Drive并修改运行路径"></a>挂载Google Drive并修改运行路径</h2><h3 id="方法一"><a href="#方法一" class="headerlink" title="方法一"></a>方法一</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">!apt-get install -y -qq software-properties-common python-software-properties module-init-tools</span><br><span class="line">!add-apt-repository -y ppa:alessandro-strada&#x2F;ppa 2&gt;&amp;1 &gt; &#x2F;dev&#x2F;null</span><br><span class="line">!apt-get update -qq 2&gt;&amp;1 &gt; &#x2F;dev&#x2F;null</span><br><span class="line">!apt-get -y install -qq google-drive-ocamlfuse fuse</span><br><span class="line">from google.colab import auth</span><br><span class="line">auth.authenticate_user()</span><br><span class="line">from oauth2client.client import GoogleCredentials</span><br><span class="line">creds &#x3D; GoogleCredentials.get_application_default()</span><br><span class="line">import getpass</span><br><span class="line">!google-drive-ocamlfuse -headless -id&#x3D;&#123;creds.client_id&#125; -secret&#x3D;&#123;creds.client_secret&#125; &lt; &#x2F;dev&#x2F;null 2&gt;&amp;1 | grep URL</span><br><span class="line">vcode &#x3D; getpass.getpass()</span><br><span class="line">!echo &#123;vcode&#125; | google-drive-ocamlfuse -headless -id&#x3D;&#123;creds.client_id&#125; -secret&#x3D;&#123;creds.client_secret&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">!mkdir -p drive</span><br><span class="line">!google-drive-ocamlfuse -o nonempty drive</span><br><span class="line">import os</span><br><span class="line">os.chdir(&quot;drive&#x2F;colab&#x2F;resnet_20191204&quot;) #修改此处来修改colab在google drive中的运行路径</span><br></pre></td></tr></table></figure>
<h3 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from google.colab import drive</span><br><span class="line">drive.mount(&#39;&#x2F;content&#x2F;drive&#39;)</span><br><span class="line"></span><br><span class="line">import os</span><br><span class="line">os.chdir(r&#39;&#x2F;content&#x2F;drive&#x2F;My Drive&#x2F;colab&#x2F;resnet_20191204&#39;)</span><br><span class="line">print(os.getcwd())</span><br></pre></td></tr></table></figure>
<h2 id="使用linux命令安装PyTorch"><a href="#使用linux命令安装PyTorch" class="headerlink" title="使用linux命令安装PyTorch"></a>使用linux命令安装PyTorch</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">! pip3 install torch torchvision</span><br></pre></td></tr></table></figure>
<h2 id="用FashionMNIST训练ResNet"><a href="#用FashionMNIST训练ResNet" class="headerlink" title="用FashionMNIST训练ResNet"></a>用FashionMNIST训练ResNet</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br></pre></td><td class="code"><pre><span class="line">import time</span><br><span class="line">import torch</span><br><span class="line">import torchvision</span><br><span class="line">from torch import nn,optim</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line">import sys</span><br><span class="line">sys.path.append(&quot;..&quot;)  #添加当前文件夹为python解释器的模块搜索目录，写成sys.path.append(&quot;d2lzh_pytorch&quot;)也行 </span><br><span class="line">device &#x3D; torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)</span><br><span class="line">print(torch.__version__)</span><br><span class="line">print(device)</span><br><span class="line"></span><br><span class="line">class Residual(nn.Module):  # 本类已保存在d2lzh_pytorch包中方便以后使用</span><br><span class="line">    def __init__(self, in_channels, out_channels, use_1x1conv&#x3D;False, stride&#x3D;1):</span><br><span class="line">        super(Residual, self).__init__()</span><br><span class="line">        self.conv1 &#x3D; nn.Conv2d(in_channels, out_channels, kernel_size&#x3D;3, padding&#x3D;1, stride&#x3D;stride)</span><br><span class="line">        self.conv2 &#x3D; nn.Conv2d(out_channels, out_channels, kernel_size&#x3D;3, padding&#x3D;1)</span><br><span class="line">        if use_1x1conv:</span><br><span class="line">            self.conv3 &#x3D; nn.Conv2d(in_channels, out_channels, kernel_size&#x3D;1, stride&#x3D;stride)</span><br><span class="line">        else:</span><br><span class="line">            self.conv3 &#x3D; None</span><br><span class="line">        self.bn1 &#x3D; nn.BatchNorm2d(out_channels)</span><br><span class="line">        self.bn2 &#x3D; nn.BatchNorm2d(out_channels)</span><br><span class="line"></span><br><span class="line">    def forward(self, X):</span><br><span class="line">        Y &#x3D; F.relu(self.bn1(self.conv1(X)))</span><br><span class="line">        Y &#x3D; self.bn2(self.conv2(Y))</span><br><span class="line">        if self.conv3:</span><br><span class="line">            X &#x3D; self.conv3(X)</span><br><span class="line">        return F.relu(Y + X)</span><br><span class="line"></span><br><span class="line">net &#x3D; nn.Sequential(</span><br><span class="line">        nn.Conv2d(1, 64, kernel_size&#x3D;7, stride&#x3D;2, padding&#x3D;3),</span><br><span class="line">        nn.BatchNorm2d(64), </span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.MaxPool2d(kernel_size&#x3D;3, stride&#x3D;2, padding&#x3D;1))</span><br><span class="line"></span><br><span class="line">def resnet_block(in_channels, out_channels, num_residuals, first_block&#x3D;False):</span><br><span class="line">    if first_block:</span><br><span class="line">        assert in_channels &#x3D;&#x3D; out_channels # 第一个模块的通道数同输入通道数一致</span><br><span class="line">    blk &#x3D; []</span><br><span class="line">    for i in range(num_residuals):</span><br><span class="line">        if i &#x3D;&#x3D; 0 and not first_block:</span><br><span class="line">            blk.append(Residual(in_channels, out_channels, use_1x1conv&#x3D;True, stride&#x3D;2))</span><br><span class="line">        else:</span><br><span class="line">            blk.append(Residual(out_channels, out_channels))</span><br><span class="line">    return nn.Sequential(*blk)</span><br><span class="line"></span><br><span class="line">class GlobalAvgPool2d(nn.Module):</span><br><span class="line">    # 全局平均池化层可通过将池化窗口形状设置成输入的高和宽实现</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(GlobalAvgPool2d, self).__init__()</span><br><span class="line">    def forward(self, x):</span><br><span class="line">        return F.avg_pool2d(x, kernel_size&#x3D;x.size()[2:])</span><br><span class="line"></span><br><span class="line">class FlattenLayer(torch.nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(FlattenLayer, self).__init__()</span><br><span class="line">    def forward(self, x): # x shape: (batch, *, *, ...)</span><br><span class="line">        return x.view(x.shape[0], -1)</span><br><span class="line"></span><br><span class="line">net.add_module(&quot;resnet_block1&quot;, resnet_block(64, 64, 2, first_block&#x3D;True))</span><br><span class="line">net.add_module(&quot;resnet_block2&quot;, resnet_block(64, 128, 2))</span><br><span class="line">net.add_module(&quot;resnet_block3&quot;, resnet_block(128, 256, 2))</span><br><span class="line">net.add_module(&quot;resnet_block4&quot;, resnet_block(256, 512, 2))</span><br><span class="line">net.add_module(&quot;global_avg_pool&quot;, GlobalAvgPool2d()) # GlobalAvgPool2d的输出: (Batch, 512, 1, 1)</span><br><span class="line">net.add_module(&quot;fc&quot;, nn.Sequential(FlattenLayer(), nn.Linear(512, 10))) </span><br><span class="line"></span><br><span class="line">X &#x3D; torch.rand((1, 1, 224, 224))</span><br><span class="line">for name, layer in net.named_children():</span><br><span class="line">    X &#x3D; layer(X)</span><br><span class="line">    print(name, &#39; output shape:\t&#39;, X.shape) #第二个通道数，最后两个为高和宽</span><br><span class="line"></span><br><span class="line">def load_data_fashion_mnist(batch_size, resize&#x3D;None, root&#x3D;&#39;~&#x2F;Datasets&#x2F;FashionMNIST&#39;):</span><br><span class="line">    &quot;&quot;&quot;Download the fashion mnist dataset and then load into memory.&quot;&quot;&quot;</span><br><span class="line">    trans &#x3D; []</span><br><span class="line">    if resize:</span><br><span class="line">        trans.append(torchvision.transforms.Resize(size&#x3D;resize))</span><br><span class="line">    trans.append(torchvision.transforms.ToTensor())</span><br><span class="line">    </span><br><span class="line">    transform &#x3D; torchvision.transforms.Compose(trans)</span><br><span class="line">    mnist_train &#x3D; torchvision.datasets.FashionMNIST(root&#x3D;root, train&#x3D;True, download&#x3D;True, transform&#x3D;transform)</span><br><span class="line">    mnist_test &#x3D; torchvision.datasets.FashionMNIST(root&#x3D;root, train&#x3D;False, download&#x3D;True, transform&#x3D;transform)</span><br><span class="line">    if sys.platform.startswith(&#39;win&#39;):</span><br><span class="line">        num_workers &#x3D; 0  # 0表示不用额外的进程来加速读取数据</span><br><span class="line">    else:</span><br><span class="line">        num_workers &#x3D; 4</span><br><span class="line">    train_iter &#x3D; torch.utils.data.DataLoader(mnist_train, batch_size&#x3D;batch_size, shuffle&#x3D;True, num_workers&#x3D;num_workers)</span><br><span class="line">    test_iter &#x3D; torch.utils.data.DataLoader(mnist_test, batch_size&#x3D;batch_size, shuffle&#x3D;False, num_workers&#x3D;num_workers)</span><br><span class="line"></span><br><span class="line">    return train_iter, test_iter</span><br><span class="line"></span><br><span class="line">def evaluate_accuracy(data_iter, net, device&#x3D;None):</span><br><span class="line">    if device is None and isinstance(net, torch.nn.Module):</span><br><span class="line">        # 如果没指定device就使用net的device</span><br><span class="line">        device &#x3D; list(net.parameters())[0].device </span><br><span class="line">    acc_sum, n &#x3D; 0.0, 0</span><br><span class="line">    with torch.no_grad():</span><br><span class="line">        for X, y in data_iter:</span><br><span class="line">            if isinstance(net, torch.nn.Module):</span><br><span class="line">                net.eval() # 评估模式, 这会关闭dropout</span><br><span class="line">                acc_sum +&#x3D; (net(X.to(device)).argmax(dim&#x3D;1) &#x3D;&#x3D; y.to(device)).float().sum().cpu().item()</span><br><span class="line">                net.train() # 改回训练模式</span><br><span class="line">            else: # 自定义的模型, 3.13节之后不会用到, 不考虑GPU</span><br><span class="line">                if(&#39;is_training&#39; in net.__code__.co_varnames): # 如果有is_training这个参数</span><br><span class="line">                    # 将is_training设置成False</span><br><span class="line">                    acc_sum +&#x3D; (net(X, is_training&#x3D;False).argmax(dim&#x3D;1) &#x3D;&#x3D; y).float().sum().item() </span><br><span class="line">                else:</span><br><span class="line">                    acc_sum +&#x3D; (net(X).argmax(dim&#x3D;1) &#x3D;&#x3D; y).float().sum().item() </span><br><span class="line">            n +&#x3D; y.shape[0]</span><br><span class="line">    return acc_sum &#x2F; n</span><br><span class="line"></span><br><span class="line">def train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs):</span><br><span class="line">    net &#x3D; net.to(device)</span><br><span class="line">    print(&quot;training on &quot;, device)</span><br><span class="line">    loss &#x3D; torch.nn.CrossEntropyLoss()</span><br><span class="line">    batch_count &#x3D; 0</span><br><span class="line">    for epoch in range(num_epochs):</span><br><span class="line">        train_l_sum, train_acc_sum, n, start &#x3D; 0.0, 0.0, 0, time.time()</span><br><span class="line">        for X, y in train_iter:</span><br><span class="line">            X &#x3D; X.to(device)</span><br><span class="line">            y &#x3D; y.to(device)</span><br><span class="line">            y_hat &#x3D; net(X)</span><br><span class="line">            l &#x3D; loss(y_hat, y)</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            l.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            train_l_sum +&#x3D; l.cpu().item()</span><br><span class="line">            train_acc_sum +&#x3D; (y_hat.argmax(dim&#x3D;1) &#x3D;&#x3D; y).sum().cpu().item()</span><br><span class="line">            n +&#x3D; y.shape[0]</span><br><span class="line">            batch_count +&#x3D; 1</span><br><span class="line">        test_acc &#x3D; evaluate_accuracy(test_iter, net)</span><br><span class="line">        print(&#39;epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec&#39;</span><br><span class="line">              % (epoch + 1, train_l_sum &#x2F; batch_count, train_acc_sum &#x2F; n, test_acc, time.time() - start))</span><br><span class="line"></span><br><span class="line">batch_size &#x3D; 256</span><br><span class="line"># 如出现“out of memory”的报错信息，可减小batch_size或resize</span><br><span class="line">train_iter, test_iter &#x3D; load_data_fashion_mnist(batch_size, resize&#x3D;96)</span><br><span class="line"></span><br><span class="line">lr, num_epochs &#x3D; 0.001, 5</span><br><span class="line">optimizer &#x3D; torch.optim.Adam(net.parameters(), lr&#x3D;lr)</span><br><span class="line">train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)</span><br><span class="line">1.3.1</span><br><span class="line">cuda</span><br><span class="line">0  output shape:     torch.Size([1, 64, 112, 112])</span><br><span class="line">1  output shape:     torch.Size([1, 64, 112, 112])</span><br><span class="line">2  output shape:     torch.Size([1, 64, 112, 112])</span><br><span class="line">3  output shape:     torch.Size([1, 64, 56, 56])</span><br><span class="line">resnet_block1  output shape:     torch.Size([1, 64, 56, 56])</span><br><span class="line">resnet_block2  output shape:     torch.Size([1, 128, 28, 28])</span><br><span class="line">resnet_block3  output shape:     torch.Size([1, 256, 14, 14])</span><br><span class="line">resnet_block4  output shape:     torch.Size([1, 512, 7, 7])</span><br><span class="line">global_avg_pool  output shape:     torch.Size([1, 512, 1, 1])</span><br><span class="line">fc  output shape:     torch.Size([1, 10])</span><br><span class="line">training on  cuda</span><br><span class="line">epoch 1, loss 0.4035, train acc 0.852, test acc 0.892, time 28.7 sec</span><br><span class="line">epoch 2, loss 0.1233, train acc 0.908, test acc 0.904, time 28.5 sec</span><br><span class="line">epoch 3, loss 0.0698, train acc 0.922, test acc 0.909, time 28.5 sec</span><br><span class="line">epoch 4, loss 0.0446, train acc 0.934, test acc 0.916, time 28.5 sec</span><br><span class="line">epoch 5, loss 0.0306, train acc 0.943, test acc 0.905, time 28.5 sec</span><br></pre></td></tr></table></figure>
<p>下面是在自己电脑（GTX-960M）上跑一个batch的数据，整整快了11倍多</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">training on  cuda</span><br><span class="line">epoch 1, loss 0.3956, train acc 0.854, test acc 0.888, time 325.2 sec</span><br></pre></td></tr></table></figure>
<h2 id="免费的GPU算力"><a href="#免费的GPU算力" class="headerlink" title="免费的GPU算力"></a>免费的GPU算力</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">!nvidia-smi</span><br><span class="line">Wed Dec  4 12:29:39 2019       </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 440.33.01    Driver Version: 418.67       CUDA Version: 10.1     |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage&#x2F;Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;+&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;+&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;|</span><br><span class="line">|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |</span><br><span class="line">| N&#x2F;A   38C    P0    34W &#x2F; 250W |   2697MiB &#x2F; 16280MiB |      0%      Default |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line"></span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                       GPU Memory |</span><br><span class="line">|  GPU       PID   Type   Process name                             Usage      |</span><br><span class="line">|&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;|</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure>
<p>经过两次测验分别分配的是 Tesla K80 和 Tesla P100</p>
<h2 id="随机查看一个Batch的数据"><a href="#随机查看一个Batch的数据" class="headerlink" title="随机查看一个Batch的数据"></a>随机查看一个Batch的数据</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line">import torchvision</span><br><span class="line"></span><br><span class="line"># functions to show an image</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def imshow(img):</span><br><span class="line">    img &#x3D; img &#x2F; 2 + 0.5     # unnormalize</span><br><span class="line">    npimg &#x3D; img.cpu().numpy()</span><br><span class="line">    plt.imshow(np.transpose(npimg, (1, 2, 0)))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">classes &#x3D; (&#39;T-shirt&#x2F;top&#39;, &#39;Trouser&#39;, &#39;Pullover&#39;, &#39;Dress&#39;,</span><br><span class="line">           &#39;Coat&#39;, &#39;Sandal&#39;, &#39;Shirt&#39;, &#39;Sneaker&#39;, &#39;Bag&#39;, &#39;Ankle boot&#39;)</span><br><span class="line"># get some random training images</span><br><span class="line">dataiter &#x3D; iter(train_iter)</span><br><span class="line">images, labels &#x3D; dataiter.next()</span><br><span class="line"></span><br><span class="line"># show images</span><br><span class="line">imshow(torchvision.utils.make_grid(images))</span><br><span class="line"># print labels</span><br><span class="line">print(&#39; &#39;.join(&#39;%5s&#39; % classes[labels[j]] for j in range(4)))</span><br></pre></td></tr></table></figure>
<h2 id="随机选取一个Batch的数据测试"><a href="#随机选取一个Batch的数据测试" class="headerlink" title="随机选取一个Batch的数据测试"></a>随机选取一个Batch的数据测试</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">PATH &#x3D; &#39;.&#x2F;resnet_20191204.pth&#39;</span><br><span class="line">torch.save(net.state_dict(), PATH)</span><br><span class="line"></span><br><span class="line">dataiter &#x3D; iter(test_iter)</span><br><span class="line">images, labels &#x3D; dataiter.next() #通过next和iter迭代来获取一个批次的装载数据</span><br><span class="line">images, labels &#x3D; images.to(device), labels.to(device)</span><br><span class="line"></span><br><span class="line"># print images</span><br><span class="line">imshow(torchvision.utils.make_grid(images))</span><br><span class="line">print(&#39;GroundTruth: &#39;, &#39; &#39;.join(&#39;%5s&#39; % classes[labels[j]] for j in range(4)))</span><br><span class="line">#net &#x3D; Net()</span><br><span class="line">net.load_state_dict(torch.load(PATH))</span><br><span class="line">outputs &#x3D; net(images)</span><br><span class="line">_, predicted &#x3D; torch.max(outputs, 1)</span><br><span class="line"></span><br><span class="line">print(&#39;Predicted: &#39;, &#39; &#39;.join(&#39;%5s&#39; % classes[predicted[j]]</span><br><span class="line">                              for j in range(4)))</span><br><span class="line">GroundTruth:  Ankle boot Pullover Trouser Trouser</span><br><span class="line">Predicted:  Ankle boot Pullover Trouser Trouser</span><br></pre></td></tr></table></figure>
<h2 id="在kaggle中使用tensorboardcolab"><a href="#在kaggle中使用tensorboardcolab" class="headerlink" title="在kaggle中使用tensorboardcolab"></a>在kaggle中使用tensorboardcolab</h2><h3 id="Tensorboardcolab使用笔记"><a href="#Tensorboardcolab使用笔记" class="headerlink" title="Tensorboardcolab使用笔记"></a>Tensorboardcolab使用笔记</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">!pip install tensorboardcolab</span><br><span class="line">from tensorboardcolab import TensorBoardColab</span><br><span class="line"></span><br><span class="line">tb &#x3D; TensorBoardColab() #初始化类</span><br><span class="line"></span><br><span class="line">#训练循环里写明</span><br><span class="line">writer.save_value(&#39;Train Loss&#39;, &#39;train_loss&#39;, epoch, epoch_loss)</span><br><span class="line">writer.save_value(&#39;Train Accuracy&#39;, &#39;train_loss&#39;, epoch, epoch_acc)</span><br><span class="line">tb.flush_line(&#39;train_loss&#39;)</span><br></pre></td></tr></table></figure>
<h3 id="core-of-Tensorboardcolab"><a href="#core-of-Tensorboardcolab" class="headerlink" title="core of Tensorboardcolab"></a>core of Tensorboardcolab</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">from keras.callbacks import TensorBoard</span><br><span class="line">import time</span><br><span class="line">import os</span><br><span class="line">import io</span><br><span class="line"></span><br><span class="line">class TensorBoardColab:</span><br><span class="line">    def __init__(self, port&#x3D;6006, graph_path&#x3D;&#39;.&#x2F;Graph&#39;, startup_waiting_time&#x3D;8):</span><br><span class="line">        self.port &#x3D; port</span><br><span class="line">        self.graph_path &#x3D; graph_path</span><br><span class="line">        self.writer &#x3D; None</span><br><span class="line">        self.deep_writers &#x3D; &#123;&#125;</span><br><span class="line">        self.eager_execution &#x3D; None</span><br><span class="line">        get_ipython().system_raw(&#39;npm i -s -q --unsafe-perm -g ngrok&#39;)  # sudo npm i -s -q --unsafe-perm -g ngrok</span><br><span class="line"></span><br><span class="line">        setup_passed &#x3D; False</span><br><span class="line">        retry_count &#x3D; 0</span><br><span class="line">        sleep_time &#x3D; startup_waiting_time &#x2F; 3.0</span><br><span class="line">        while not setup_passed:</span><br><span class="line">            get_ipython().system_raw(&#39;kill -9 $(sudo lsof -t -i:%d)&#39; % port)</span><br><span class="line">            get_ipython().system_raw(&#39;rm -Rf &#39; + graph_path)</span><br><span class="line">            print(&#39;Wait for %d seconds...&#39; % startup_waiting_time)</span><br><span class="line">            time.sleep(sleep_time)</span><br><span class="line">            get_ipython().system_raw(&#39;tensorboard --logdir %s --host 0.0.0.0 --port %d &amp;&#39; % (graph_path, port))</span><br><span class="line">            time.sleep(sleep_time)</span><br><span class="line">            get_ipython().system_raw(&#39;ngrok http %d &amp;&#39; % port)</span><br><span class="line">            time.sleep(sleep_time)</span><br><span class="line">            try:</span><br><span class="line">                tensorboard_link &#x3D; get_ipython().getoutput(</span><br><span class="line">                    &#39;curl -s http:&#x2F;&#x2F;localhost:4040&#x2F;api&#x2F;tunnels | python3 -c &quot;import sys, json; print(json.load(sys.stdin))&quot;&#39;)[</span><br><span class="line">                    0]</span><br><span class="line">                tensorboard_link &#x3D; eval(tensorboard_link)[&#39;tunnels&#39;][0][&#39;public_url&#39;]</span><br><span class="line">                setup_passed &#x3D; True</span><br><span class="line">            except:</span><br><span class="line">                setup_passed &#x3D; False</span><br><span class="line">                retry_count +&#x3D; 1</span><br><span class="line">                print(&#39;Initialization failed, retry again (%d)&#39; % retry_count)</span><br><span class="line">                print(&#39;\n&#39;)</span><br><span class="line"></span><br><span class="line">        print(&quot;TensorBoard link:&quot;)</span><br><span class="line">        print(tensorboard_link)</span><br><span class="line"></span><br><span class="line">    def get_graph_path(self):</span><br><span class="line">        return self.graph_path</span><br><span class="line"></span><br><span class="line">    def is_eager_execution(self):</span><br><span class="line">        if self.eager_execution is None:</span><br><span class="line">            try:</span><br><span class="line">                tf.summary.FileWriter(self.graph_path)</span><br><span class="line">                self.eager_execution &#x3D; False</span><br><span class="line">            except Exception as err:</span><br><span class="line">                self.eager_execution &#x3D; str(</span><br><span class="line">                    err) &#x3D;&#x3D; &#39;tf.summary.FileWriter is not compatible with eager execution. Use tf.contrib.summary instead.&#39;</span><br><span class="line">        return self.eager_execution</span><br><span class="line"></span><br><span class="line">    def get_writer(self):</span><br><span class="line">        if self.writer is None:</span><br><span class="line">            if self.is_eager_execution():</span><br><span class="line">                self.writer &#x3D; tf.contrib.summary.create_file_writer(self.graph_path)</span><br><span class="line">            else:</span><br><span class="line">                self.writer &#x3D; tf.summary.FileWriter(self.graph_path)</span><br><span class="line"></span><br><span class="line">        return self.writer</span><br><span class="line"></span><br><span class="line">    def get_deep_writers(self, name):</span><br><span class="line">        if not (name in self.deep_writers):</span><br><span class="line">            log_path &#x3D; os.path.join(self.graph_path, name)</span><br><span class="line">            if self.is_eager_execution():</span><br><span class="line">                self.deep_writers[name] &#x3D; tf.contrib.summary.create_file_writer(log_path)</span><br><span class="line">            else:</span><br><span class="line">                self.deep_writers[name] &#x3D; tf.summary.FileWriter(log_path)</span><br><span class="line">        return self.deep_writers[name]</span><br><span class="line"></span><br><span class="line">    def save_image(self, title, image):</span><br><span class="line">        image_path &#x3D; os.path.join(self.graph_path, &#39;images&#39;)</span><br><span class="line">        if self.is_eager_execution():</span><br><span class="line">            print(&#39;Warning: save_image() is not supported in eager execution mode&#39;)</span><br><span class="line">        #           writer &#x3D; tf.contrib.summary.create_file_writer(image_path)</span><br><span class="line">        #           writer.set_as_default()</span><br><span class="line">        #           with tf.contrib.summary.always_record_summaries():</span><br><span class="line">        #               tf.contrib.summary.image(</span><br><span class="line">        #                   title,</span><br><span class="line">        #                   image_tensor</span><br><span class="line">        #               )</span><br><span class="line">        else:</span><br><span class="line">            summary_op &#x3D; tf.summary.image(title, image)</span><br><span class="line">            with tf.Session() as sess:</span><br><span class="line">                summary &#x3D; sess.run(summary_op)</span><br><span class="line">                writer &#x3D; tf.summary.FileWriter(image_path)</span><br><span class="line">                writer.add_summary(summary)</span><br><span class="line">                writer.close()</span><br><span class="line"></span><br><span class="line">    def save_value(self, graph_name, line_name, epoch, value):</span><br><span class="line">        if self.is_eager_execution():</span><br><span class="line">            self.get_deep_writers(line_name).set_as_default()</span><br><span class="line">            global_step &#x3D; tf.train.get_or_create_global_step()</span><br><span class="line">            global_step.assign(epoch)</span><br><span class="line">            with tf.contrib.summary.always_record_summaries():</span><br><span class="line">                tf.contrib.summary.scalar(graph_name, value)</span><br><span class="line">        else:</span><br><span class="line">            summary &#x3D; tf.Summary()</span><br><span class="line">            summary_value &#x3D; summary.value.add()</span><br><span class="line">            summary_value.simple_value &#x3D; value</span><br><span class="line">            summary_value.tag &#x3D; graph_name</span><br><span class="line">            self.get_deep_writers(line_name).add_summary(summary, epoch)</span><br><span class="line"></span><br><span class="line">    def flush_line(self, line_name):</span><br><span class="line">        self.get_deep_writers(line_name).flush()</span><br><span class="line"></span><br><span class="line">    def close(self):</span><br><span class="line">        if self.writer is not None:</span><br><span class="line">            self.writer.close()</span><br><span class="line">            self.writer &#x3D; None</span><br><span class="line">        for key in self.deep_writers:</span><br><span class="line">            self.deep_writers[key].close()</span><br><span class="line">        self.deep_writers &#x3D; &#123;&#125;</span><br></pre></td></tr></table></figure>
<h2 id="cv2-imshow碰到cannot-connect-to-X-server"><a href="#cv2-imshow碰到cannot-connect-to-X-server" class="headerlink" title="cv2.imshow碰到cannot connect to X server"></a>cv2.imshow碰到cannot connect to X server</h2><p>X server是Linux系统上提供图形用户界面的服务程序。当客户端主机Client访问服务器Server上的图形程序时，需要Server对该Client赋能访问图形程序的权限</p>
<p>OpenCV采用highgui，而命令行下无法产生图形界面</p>
<p>改用matplotlib</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">original_image &#x3D; &#39;a.jpg&#39;</span><br><span class="line">image &#x3D; cv2.imread(original_image)</span><br><span class="line">show_img &#x3D; cv2.cvtColor(image, cv2.COLOR_BGR2RGB)</span><br><span class="line">plt.imshow(show_img)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h2 id="在线编辑py文件"><a href="#在线编辑py文件" class="headerlink" title="在线编辑py文件"></a>在线编辑py文件</h2><p>anyfile-notepad</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/24/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chenyang Min">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="perfectism's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/07/24/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/" class="post-title-link" itemprop="url">迁移学习</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-24 13:10:01" itemprop="dateCreated datePublished" datetime="2020-07-24T13:10:01+08:00">2020-07-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-16 21:40:07" itemprop="dateModified" datetime="2020-03-16T21:40:07+08:00">2020-03-16</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="迁移学习"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习</h1><p><strong>大量资源训练的模型</strong>经过细微调整后解决同一类问题，解决原始数据较少的问题，可节省大量时间和算力，因为分类对象变化，需要重新训练</p>
<p>若出现负迁移:模型的泛化能力恶化，解决两个毫不相关的问题</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/24/%E5%B9%B3%E5%8F%B0%E6%A1%86%E6%9E%B6%E9%83%A8%E5%88%86%E8%A1%A5%E5%85%85/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chenyang Min">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="perfectism's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/07/24/%E5%B9%B3%E5%8F%B0%E6%A1%86%E6%9E%B6%E9%83%A8%E5%88%86%E8%A1%A5%E5%85%85/" class="post-title-link" itemprop="url">平台框架部分补充</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-24 13:10:01" itemprop="dateCreated datePublished" datetime="2020-07-24T13:10:01+08:00">2020-07-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-16 21:48:52" itemprop="dateModified" datetime="2020-03-16T21:48:52+08:00">2020-03-16</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="平台框架部分补充"><a href="#平台框架部分补充" class="headerlink" title="平台框架部分补充"></a>平台框架部分补充</h1><p>闵晨阳 车辆1601 2019.11.14</p>
<h2 id="ROS常见开源库"><a href="#ROS常见开源库" class="headerlink" title="ROS常见开源库"></a>ROS常见开源库</h2><p>pcl： Point Cloud Library是用于点云处理任务和3D几何处理的算法的开源库</p>
<p>openrave： 开放式机器人自动化虚拟环境为在现实世界的机器人应用中测试，开发和部署运动规划算法提供了一个环境</p>
<p>openni： 验证和提高互操作性自然用户界面和有机用户接口对于自然交互（NI）设备，使用这些设备的应用程序和中间件这便于此类设备的访问和使用</p>
<p>BSD 许可协议：Berkeley Software Distribution license，是自由软件中使用最广泛的许可协议之一。BSD 就是遵照这个许可证来发布，也因此而得名 BSD 许可协议。</p>
<h2 id="Apollo-Ros有何不同"><a href="#Apollo-Ros有何不同" class="headerlink" title="Apollo Ros有何不同"></a>Apollo Ros有何不同</h2><p>详见： <a href="http://blog.exbot.net/archives/3437" target="_blank" rel="noopener">http://blog.exbot.net/archives/3437</a></p>
<p><strong>一、 自动驾驶对ROS框架的三点需求</strong></p>
<p>自动驾驶系统非常复杂，包含感知、障碍物检测、决策、车辆控制等模块，把这么多功能各异的模块集成在一起，组成一个完整的系统并完成自动驾驶的任务，这是一个非常大挑战。</p>
<p><strong>1、高效的开发支持</strong>，快速的算法迭代要求ROS框架要能提供良好的开发模式，算法工程师更多聚焦在算法本身的开发和功能验证上。通过一个框架统一完成诸如配置管理、环境配置、整体运行以及调试等功能，快速构建系统原型，验证算法和功能。</p>
<p><strong>2、模块灵活配置</strong>，感知、定位、决策模块，本身功能相对独立，通过接口定义数据。工程师在整体开发中希望各个模块独立开发、调试，应用时能通过框架快速集合成完整的系统并运行。</p>
<p><strong>3、丰富的调试工具</strong>，自动驾驶系统涉及大量图像、点云处理算法，对于各种可视化工具有非常高需求，障碍物检测是否精准， 规划路径是否合理、定位是否正确，这些环节在调试过程中都需要可视化工具的支持。</p>
<p><strong>二、 为什么选用ROS框架？</strong></p>
<p><strong>1、行业认可</strong>，ROS框架很早就被机器人行业所使用，目前有3000多个基础库，能够支持应用的快速开发。</p>
<p><strong>2、消息机制</strong>，ROS在开发过程中，基于功能把整个自动驾驶系统分成多个模块，每个模块负责自己消息的接收、处理、发布。当模块需要联调时，通过框架可以把各个模块快速的集成到一起。</p>
<p><strong>3、使用广泛</strong>，ROS是学术界使用最广泛的框架，对于验证最新的算法非常便利。</p>
<p>正是基于以上特性，在Apollo1.0版本中选择ROS作为开发和集成的框架。</p>
<p><img src="https://perfectism13.github.io/2019/11/17/%E5%AE%9E%E8%B7%B5%E5%9F%BA%E7%A1%80_%E5%B9%B3%E5%8F%B0%E6%A1%86%E6%9E%B6%E8%A1%A5%E5%85%85/fc7aaf5673174f76901670c37839642a_th-2.png" alt="img"></p>
<p><strong>三、Apollo中ROS的改进</strong></p>
<p><img src="https://perfectism13.github.io/2019/11/17/%E5%AE%9E%E8%B7%B5%E5%9F%BA%E7%A1%80_%E5%B9%B3%E5%8F%B0%E6%A1%86%E6%9E%B6%E8%A1%A5%E5%85%85/da1bd41d96dd43a5850ff0573d8a285a_th-1.png" alt="img"></p>
<p><strong>1、通信性能优化</strong></p>
<p><strong>｜问题：自动驾驶大量使用传感器引发很大的传输带宽需求</strong></p>
<p>自动驾驶系统为了能够感知复杂的道路情况，需要多种传感器协同工作才能覆盖不同的场景、不同路况需求。多传感器共同使用会对车载系统造成很大压力。</p>
<p><strong>｜解决优化：共享内存能减少传输中的数据拷贝，显著提升传输效率</strong></p>
<p><img src="https://perfectism13.github.io/2019/11/17/%E5%AE%9E%E8%B7%B5%E5%9F%BA%E7%A1%80_%E5%B9%B3%E5%8F%B0%E6%A1%86%E6%9E%B6%E8%A1%A5%E5%85%85/eab7a7c0401e4d11b8ea75e55ef6357b_th-1.png" alt="img"></p>
<p><strong>｜问题：单路传感器消息有多个消费者时负载成倍增长</strong></p>
<p><strong>｜解决优化：共享内存可以有效满足一对多的传输场景</strong></p>
<p>共享内存本身的特性能够支持一次写入、多次读取功能。对于一对多传输场景，不同的使用者就可以同时读取，实现一次写入，多次读取的功能，成倍提升传输效率。</p>
<p><img src="https://perfectism13.github.io/2019/11/17/%E5%AE%9E%E8%B7%B5%E5%9F%BA%E7%A1%80_%E5%B9%B3%E5%8F%B0%E6%A1%86%E6%9E%B6%E8%A1%A5%E5%85%85/9fad66a1c29d43babda165b200d7db47_th-1.png" alt="img"></p>
<p><strong>｜通信性能优化效果</strong></p>
<p>A、一对一传输过程中，共享内存吞吐量达到socket两倍，一对多传输过程中，共享内存传输对带宽的优势进一步扩大。</p>
<p>B、共享内存传输延迟比Shared节省一半，对强实时性系统的自动驾驶汽车帮助很大。</p>
<p>C、共享内存CPU资源占用要比socket减少很多，一定程度上提升计算算法和能力。</p>
<p><strong>2、去中心化的网络拓扑</strong></p>
<p><strong>｜ROS特点：ROS以Master为中心构建hybridp2p拓扑网络</strong></p>
<p>ROS是以Master为中心构建Hybrid p2p拓扑网络，带来了比较强的容错性，不同语言模块隔离，模块开发低耦合，当某个算法出现异常导致崩溃的时候，不会引起整个的异常，为局部异常处理提供便利。</p>
<p><strong>｜问题：Master作为拓扑网络的中心，一旦异常将影响整个网络</strong></p>
<p>整个系统非常依赖Master这个单点，一旦Master异常，所有节点都不能发现其他节点，这样整个系统就不能正常工作，缺乏异常恢复机制。</p>
<p><strong>｜解决优化：使用RTPS服务发现协议实现完全的P2P网络拓扑</strong></p>
<p>在ROS中添加基于RTPS服务协议功能，网络构建不会以Master作为中心，而是通过域概念作为划分，所有节点加入域中，会通过RTPS协议相互广播通知其他节点，然后节点间会建立点对点连接，来发布订阅消息，以替代Master作为中央信息交换的功能。</p>
<p><img src="https://perfectism13.github.io/2019/11/17/%E5%AE%9E%E8%B7%B5%E5%9F%BA%E7%A1%80_%E5%B9%B3%E5%8F%B0%E6%A1%86%E6%9E%B6%E8%A1%A5%E5%85%85/c85fbfa5578d4480a882a3f1743f5d9c_th-1.png" alt="img"></p>
<p><strong>｜使用RTPS服务发现过程</strong></p>
<p>A. Sub节点启动，通过组播向网络注册</p>
<p>B、通过节点发现，两两建立unicast</p>
<p>C、向新加入的节点发送历史拓扑消息</p>
<p>D、收发双发建立连接，开始通信</p>
<p><strong>3、数据兼容性扩展</strong></p>
<p><strong>｜Message是ROS中描述软件组件接口的语言</strong></p>
<p>Message是ROS中描述接口的一种语言，当两个节点之间需要建立连接的时候，通常需要满足两个条件。一是接收和发送的Topic属于同一个话题，二是两个模块定义的模式要完全一致。</p>
<p><strong>｜ROS使用msg描述文件定义模块间的消息接口</strong></p>
<p>ROS怎么定义message？ROS使用msg文件对数据接口进行抽象化的描述，并可以生成不同语言的接口实现，以满足不同语言的通信交流需求。</p>
<p><strong>｜问题：接口升级后，不同版本的模块难以兼容</strong></p>
<p>兼容性的问题，当项目规模比较小时，影响不大；但是对于无人自动驾驶比较庞大的项目时，影响就很大。当某一个模块接口升级了，需要把所有相关模块升级到最新版本之后，才能在一起进行基础功能的连调。同时对于线下仿真调试的时候，有时需要把某一个模块回到历史版本验证或定位某一个问题，这时候若接口之间出现升级，就会出现不兼容问题，导致系统运行障碍。</p>
<p><strong>｜问题:接口升级后，历史数据也面临无法使用的问题</strong></p>
<p>接口兼容性问题会对历史数据使用造成更大影响，自动驾驶汽车系统中历史数据是非常宝贵和重要资源，对于这种问题有一些解决方式，一是通过离线数据批量转换和在线方式，二是转换成新数据。</p>
<p><strong>｜解决优化：protobuf能够很好支持向后兼容</strong></p>
<p>使用protobuf来替代ROSmessage，最大好处是可以完全覆盖message中本身包含的类型，有利于把既有的ROSmessage迁移到protobuf格式下。此外protobuf有非常好的版本兼容性。</p>
<p><img src="https://perfectism13.github.io/2019/11/17/%E5%AE%9E%E8%B7%B5%E5%9F%BA%E7%A1%80_%E5%B9%B3%E5%8F%B0%E6%A1%86%E6%9E%B6%E8%A1%A5%E5%85%85/f92c6292ed9d439a9ed597399709230a_th.png" alt="img"></p>
<p><strong>｜解决优化：protobuf消息格式与ROS深度集成</strong></p>
<p>在Apollo ROS中，做了一整套对protobuf的支持， 在工程中可以不需要做protobuf和ROS message的转换，直接publish protobuf格式的消息，调试工具也能够非常正确的解析出来正确的protobuf消息。这样既能够很好解决兼容性问题，也不会产生额外的学习成本和使用成本。</p>
<p><img src="https://perfectism13.github.io/2019/11/17/%E5%AE%9E%E8%B7%B5%E5%9F%BA%E7%A1%80_%E5%B9%B3%E5%8F%B0%E6%A1%86%E6%9E%B6%E8%A1%A5%E5%85%85/9dd4c11ea1a34ab198c9efde7966082d_th.png" alt="img"></p>
<h2 id="平台框架"><a href="#平台框架" class="headerlink" title="平台框架"></a>平台框架</h2><p><strong>OTA</strong>: 空中下载（OTA）是通过移动通信的空中接口实现对移动终端设备及SIM卡数据进行远程管理的技术。</p>
<p><strong>DuerOS</strong>:是百度<a href="https://baike.baidu.com/item/度秘" target="_blank" rel="noopener">度秘</a>事业部研发的对话式人工智能系统。</p>
<p><strong>HMI</strong>:Human Machine Interface , 人机界面（又称用户界面或使用者界面）是系统和用户之间进行交互和信息交换的媒介， 它实现信息的内部形式与人类可以接受形式之间的转换。凡参与人机信息交流的领域都存在 着人机界面。</p>
<p><strong>黑盒子存在的原因</strong>：</p>
<h3 id="端到端："><a href="#端到端：" class="headerlink" title="端到端："></a><strong>端到端</strong>：</h3><p>端到端就意味着完整性、完备性 ，一种工作态度</p>
<p> 单个模块即便能正常工作，但当各个模块组合成为一个系统时，整个系统可能不能正常工作，因此必须在整个系统的输出与输出之间建立一种端到端的连接，使整个系统能够正常工作</p>
<p><img src="https://perfectism13.github.io/2019/11/17/%E5%AE%9E%E8%B7%B5%E5%9F%BA%E7%A1%80_%E5%B9%B3%E5%8F%B0%E6%A1%86%E6%9E%B6%E8%A1%A5%E5%85%85/71278e9847764506ac39200bdc3a3b76_th-1573746277221.png" alt="img"></p>
<p><img src="https://perfectism13.github.io/2019/11/17/%E5%AE%9E%E8%B7%B5%E5%9F%BA%E7%A1%80_%E5%B9%B3%E5%8F%B0%E6%A1%86%E6%9E%B6%E8%A1%A5%E5%85%85/c96d3715ac4d4717b7bebe7fe4089946_th-1573746464451.png" alt="img"></p>
<p><strong>｜Rule base的特点：</strong></p>
<p>1.系统复杂性，需要人工设计上千个模块。</p>
<p>2.高精地图的成本，更新必须及时。</p>
<p>3.车载硬件计算能力，每个模块都要深度学习，车辆最多可能需要运行十几个深度学习网络，对计算能力和消耗需求很大。</p>
<p><strong>｜功能、系统工程复杂度、算法要求</strong></p>
<p>人们开车的时候有两类行为：一类可以边打电话边开车，我们称之为Reactive control（无脑操作）。需要集中注意力做出判断的，是Proactive planning。End-to-End系统到目前为止，主要实现了Reactive control，Proactive planning尚处于探索阶段。每一个message背后其实都是一个复杂的系统，End-to-End大部分系统自己完成，算法要求都很高。</p>
<p><strong>｜可解释性</strong></p>
<p>自动驾驶对安全性要求极高，必须做可解释性的东西。很多公司不做End-to-End系统，主要原因是其不可解释，而Rule based是可解释的。但限制Rule based往前发展的恰恰就是面临的不确定性因素，尤其是复杂环境。可解释性不应该成为这两个系统选择或者是评比优劣的点，最终的评比应该是客观的指标性的东西，比如能安全运行多少公里。</p>
<p><strong>｜广铺成本</strong></p>
<p>Rule based广铺成本面临的大问题是高精地图，End-to-End目前还不需要高精地图，普通导航系统即可。</p>
<p><strong>｜传感器成本</strong></p>
<p>Rule based相对高一些，End-to-End相对低一些。并不是End-to-End系统需要的传感器少，而在于它对传感器的利用率高。以摄像头为例，宝马的自动驾驶方案中，前档有3个摄像头，周围一圈又有不少，每个摄像头都对应了Rule based系统中特定的功能。而End-to-End系统是用神经网络拟合，如不同的摄像头中所需要的像素级别的融合，可以自己用机器识别出，或者机器自己判断和加工中所需要的过程，更高效的利用传感器。</p>
<p><strong>｜车载计算资源、核心问题、关系</strong></p>
<p>车载计算资源的实践差距非常大，Rule based的研发和广铺成本极高，而End-to-End系统核心问题主要在于数据，它的所有行为需要数据，而目前开源闭源都很难有优质的数据需要训练。Rule based和End-to-End更像互补关系。对于普通的，需要在边打电话边开车的场合，End-to-End更适合；对于入口和街区，Rule based更靠谱。</p>
<h3 id="RTOS"><a href="#RTOS" class="headerlink" title="RTOS"></a>RTOS</h3><p>是指当外界事件或数据产生时，能够接受并以足够快的速度予以处理，其处理的结果又能在规定的时间之内来控制生产过程或对处理系统做出快速响应，调度一切可利用的资源完成实时任务，并控制所有实时任务协调一致运行的操作系统。提供及时响应和高可靠性是其主要特点</p>
<h3 id="硬件连接"><a href="#硬件连接" class="headerlink" title="硬件连接"></a>硬件连接</h3><p><img src="https://perfectism13.github.io/2019/11/17/%E5%AE%9E%E8%B7%B5%E5%9F%BA%E7%A1%80_%E5%B9%B3%E5%8F%B0%E6%A1%86%E6%9E%B6%E8%A1%A5%E5%85%85/Hardware_connection_3_5_1.png" alt="image alt text"></p>
<h3 id="软件连接"><a href="#软件连接" class="headerlink" title="软件连接"></a>软件连接</h3><p><img src="https://perfectism13.github.io/2019/11/17/%E5%AE%9E%E8%B7%B5%E5%9F%BA%E7%A1%80_%E5%B9%B3%E5%8F%B0%E6%A1%86%E6%9E%B6%E8%A1%A5%E5%85%85/Apollo_3_5_software_architecture.png" alt="image alt text"></p>
<h2 id="计算平台体系结构设计"><a href="#计算平台体系结构设计" class="headerlink" title="计算平台体系结构设计"></a>计算平台体系结构设计</h2><p>详见： <a href="https://cloud.tencent.com/developer/article/1004746?from=10680" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1004746?from=10680</a></p>
<h3 id="异构计算"><a href="#异构计算" class="headerlink" title="异构计算"></a>异构计算</h3><p>主要是指使用不同类型指令集和体系架构的计算单元组成系统的计算方式。</p>
<p>异构计算近年来得到更多关注，主要是因为通过提升CPU时钟频率和内核数量而提高计算能力的传统方式遇到了散热和能耗瓶颈。而与此同时，GPU等专用计算单元虽然工作频率较低，具有更多的内核数和并行计算能力，总体性能-芯片面积比和性能-功耗比都很高，却远远没有得到充分利用。广义上，不同计算平台的各个层次上都存在异构现象，除硬件层的指令集、互联方式、内存层次之外，软件层中<a href="https://zh.wikipedia.org/wiki/应用二进制接口" target="_blank" rel="noopener">应用二进制接口</a>、API、语言特性底层实现等的不同，对于上层应用和服务而言，都是异构的。</p>
<h3 id="GPU"><a href="#GPU" class="headerlink" title="GPU"></a>GPU</h3><p><strong>G</strong>raphics <strong>P</strong>rocessing <strong>U</strong>nit ，EX： <strong>NVIDIA DRIVE PX 2</strong></p>
<p>GPU专为图像处理设计，主频一般在500mhz左右，但是核多啊，比如titan,有380多个流处理单元，500*400就是200g这个量级，远大与于前面2者了。</p>
<p>GPU的设计出发点在于GPU更适用于计算强度高、多并行的计算。因此，GPU把晶体管更多用于计算单元，而不像CPU用于数据Cache和流程控制器。这样的设计是因为并行计算时每个数据单元执行相同程序，不需要繁琐的流程控制而更需要高计算能力，因此也不需要大的cache容量。</p>
<p>GPU同CPU一样也是指令执行过程：取指令 -&gt;指令译码 -&gt;指令执行，只有在指令执行的时候，计算单元才发挥作用。GPU的逻辑控制单元相比CPU简单，所以要想做到指令流水处理，提高指令执行效率，必然要求处理的算法本身复杂度低，处理的数据之间相互独立，所以算法本身的串行处理会导致GPU浮点计算能力的显著降低。</p>
<p><img src="https://perfectism13.github.io/2019/11/17/%E5%AE%9E%E8%B7%B5%E5%9F%BA%E7%A1%80_%E5%B9%B3%E5%8F%B0%E6%A1%86%E6%9E%B6%E8%A1%A5%E5%85%85/20190613175451735.png" alt="在这里插入图片描述"></p>
<p>与CPU相比，CPU芯片空间的不到20%是ALU，而GPU芯片空间的80%以上是ALU。即GPU拥有更多的ALU用于数据并行处理</p>
<ul>
<li>NVIDIA的PX平台是目前领先的基于GPU的无人驾驶解决方案。每个PX2由两个Tegra SoC和两个Pascal GPU图形处理器组成，其中每个图像处理器都有自己的专用内存并配备有专用的指令以完成深度神经网络加速。为了提供高吞吐量，每个Tegra SOC使用PCI-E Gen 2 x4总线与Pascal GPU直接相连，其总带宽为4 GB/s。此外，两个CPU-GPU集群通过千兆以太网项链，数据传输速度可达70 Gigabit/s。借助于优化的I/O架构与深度神经网络的硬件加速，每个PX2能够每秒执行24兆次深度学习计算。这意味着当运行AlexNet深度学习典型应用时，PX2的处理能力可达2800帧/秒。</li>
</ul>
<p>1 、多线程，提供了多核并行计算的基础结构，且核心数非常多，可以支撑大量数据的并行计算。</p>
<p>2、拥有更高的访存速度。</p>
<p>3、更高的浮点运算能力。</p>
<p>因此，GPU比CPU更适合深度学习中的大量训练数据、大量矩阵、卷积运算。</p>
<h3 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h3><p><strong>C</strong>entral <strong>P</strong>rocessing <strong>U</strong>nit ，</p>
<p>一般来说CPU运算能力最弱，CPU虽然主频最高，但是单颗也就8核、16核的样子，一个核3.5g，16核也就56g，再考虑指令周期，每秒最多也就30g次乘法。还是定点的。</p>
<p>CPU作为通用处理器，兼顾计算和控制，70%晶体管用来构建Cache 还有一部分控制单元，用来处理复杂逻辑和提高指令的执行效率，如图6所示，所以导致计算通用性强，可以处理计算复杂度高，但计算性能一般。适合逻辑控制运算</p>
<ul>
<li><p>CPU的指令执行过程是：取指令 -&gt;指令译码 -&gt;指令执行，只有在指令执行的时候，计算单元才发挥作用，这样取指令和指令译码的两段时间，计算单元是不在工作的，</p>
</li>
<li><p><img src="https://perfectism13.github.io/2019/11/17/%E5%AE%9E%E8%B7%B5%E5%9F%BA%E7%A1%80_%E5%B9%B3%E5%8F%B0%E6%A1%86%E6%9E%B6%E8%A1%A5%E5%85%85/20190613175436184.png" alt="在这里插入图片描述"></p>
<p>CPU遵循的是冯诺依曼架构，其核心是存储程序、顺序执行。CPU的架构中需要大量的空间去放置存储单元（Cache）和控制单元（Control），相比之下计算单元（ALU）只占据了很小的一部分，所以它在大规模并行计算能力上极受限制，而更擅长于逻辑控制。 CPU无法做到大量矩阵数据并行计算的能力，但GPU可以。</p>
</li>
</ul>
<h3 id="FPGA"><a href="#FPGA" class="headerlink" title="FPGA"></a>FPGA</h3><p>Field Programmable Gate Array ,现场可编程逻辑门阵列，EX: <strong>Altera</strong> 的 <strong>CycloneV SoC</strong></p>
<p>FPGA的运算能力的，拿高端的来说。3000多个固定乘法器，拿数字逻辑还能搭3000个，最快能到接近300mhz, 也就是1800g这个量级。</p>
<p>FPGA作为一种高性能、低功耗的可编程芯片，可以根据客户定制来做针对性的算法设计。所以在处理海量数据的时候，FPGA 相比于CPU 和GPU，无指令，无需共享内存，优势在于：FPGA计算效率更高，FPGA更接近IO。</p>
<p>FPGA不采用指令和软件，是软硬件合一的器件。对FPGA进行编程要使用硬件描述语言，硬件描述语言描述的逻辑可以直接被编译为晶体管电路的组合。所以FPGA实际上直接用晶体管电路实现用户的算法，没有通过指令系统的翻译。 它就是一堆逻辑门电路的组合，可以编程，还可以重复编程。 用户可以通过烧入FPGA 配置文件来定义这些门电路以及存储器之间的连线。这种烧入不是一次性的，可重复编写定义，重复配置。</p>
<p><img src="https://perfectism13.github.io/2019/11/17/%E5%AE%9E%E8%B7%B5%E5%9F%BA%E7%A1%80_%E5%B9%B3%E5%8F%B0%E6%A1%86%E6%9E%B6%E8%A1%A5%E5%85%85/20190613175912795.png" alt="在这里插入图片描述"></p>
<ul>
<li><p>FPGA的编程逻辑块（Programable Logic Blocks）中包含很多功能单元，由LUT（Look-up Table）、触发器组成。FPGA是直接通过这些门电路来实现用户的算法，没有通过指令系统的翻译，执行效率更高 ，大规模并行运算</p>
</li>
<li><p>FPGA由于算法是定制的，所以没有CPU和GPU的取指令和指令译码过程，数据流直接根据定制的算法进行固定操作，计算单元在每个时钟周期上都可以执行，所以可以充分发挥浮点计算能力，计算效率高于CPU和GPU。性能高、功耗低、可硬件编程的特点， 开发使用硬件描述语言，开发门槛相对GPU、NPU高。</p>
<p>Altera公司的Cyclone V SoC是一个基于FPGA的无人驾驶解决方案，现已应用在奥迪无人车产品中。Altera公司的FPGA专为传感器融合提供优化，可结合分析来自多个传感器的数据以完成高度可靠的物体检测。类似的产品有Zynq专为无人驾驶设计的Ultra ScaleMPSoC。当运行卷积神经网络计算任务时，Ultra ScaleMPSoC运算效能为14帧/秒/瓦，优于NVIDIA Tesla K40 GPU可达的4帧/秒/瓦。同时，在目标跟踪计算方面，Ultra ScaleMPSoC在1080p视频流上的处理能力可达60fps。</p>
</li>
</ul>
<h3 id="ASIC"><a href="#ASIC" class="headerlink" title="ASIC"></a>ASIC</h3><p><strong>A</strong>pplication <strong>S</strong>pecific <strong>I</strong>ntegrated <strong>C</strong>ircuit 专用集成电路, EX: <strong>Mobileye</strong> 的 <strong>Eyeq5</strong></p>
<p>优越性：体积小、功耗低、计算性能高、计算效率高、芯片出货量越大成本越低。但是缺点也很明显：算法是固定的，一旦算法变化就可能无法使用。FPGA成本高面向企业军工，ASIC成本面向消费电子。</p>
<p>Mobileye是一家基于ASIC的无人驾驶解决方案提供商。其Eyeq5 SOC装备有四种异构的全编程加速器，分别对专有的算法进行了优化，包括有：计算机视觉、信号处理和机器学习等。Eyeq5 SOC同时实现了两个PCI-E端口以支持多处理器间通信。这种加速器架构尝试为每一个计算任务适配最合适的计算单元，硬件资源的多样性使应用程序能够节省计算时间并提高计算效能。</p>
<h3 id="DSP"><a href="#DSP" class="headerlink" title="DSP"></a>DSP</h3><p><strong>digital signal processor</strong> 数字信号处理器，EX:德州仪器的 <strong>TDA2x</strong></p>
<p>DSP虽然主频不如CPU,但是胜在乘法器多，随随便便带16个乘法器，还是浮点的。再来个4核，8核，还有特定的算法硬件加速，所以虽然主频只有1,2g但是运算能力还是比CPU强。当然现在出现了带专用乘法器的CPU，DSP也集了ARM核，这两个的界限开始模糊了。<br>DSP所有计算均使用浮点算法，而且目前还没有位或整数运算指令</p>
<p>德州仪器提供了一种基于DSP的无人驾驶的解决方案。其TDA2x SoC拥有两个浮点DSP内核C66x和四个专为视觉处理设计的完全可编程的视觉加速器。相比ARM Cortex-15处理器，视觉加速器可提供八倍的视觉处理加速且功耗更低。类似设计有CEVA XM4。这是另一款基于DSP的无人驾驶计算解决方案，专门面向计算视觉任务中的视频流分析计算。使用CEVA XM4每秒处理30帧1080p的视频仅消耗功率30MW，是一种相对节能的解决方案。</p>
<p>总结：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">① 这几个应用场合不同，CPU虽然运算不行，但是擅长管理和调度，比如读取数据，管理文件，人机交互等，例程多，辅助工具也很多。</span><br><span class="line">② DSP相比而言管理弱了，运算加强了。这两者都是靠高主频来解决运算量的问题，适合有&lt;u&gt;大量递归操作以及不便拆分&lt;&#x2F;u&gt;的算法。</span><br><span class="line">③ GPU管理更弱，运算更强，但由于是多进程并发，更适合整块数据进行流处理的算法</span><br><span class="line">④ FPGA能管理能运算，但是开发周期长，复杂算法开发难度大。适合流处理算法，不管是整块数据进还是一个一个进。还有实时性来说，FPGA是最高的。前3种处理器为了避免将运算能力浪费在数据搬运上，一般要求累计一定量数据后才开始计算，产生群延时，而FPGA所有操作都并行，因此群延时可以很小</span><br></pre></td></tr></table></figure>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>能耗比方面：ASIC &gt; FPGA &gt; GPU &gt; CPU</p>
<p>以人脸识别为例， 其处理基本流程及对应功能模块所需的算力分布如下：</p>
<p><img src="https://perfectism13.github.io/2019/11/17/%E5%AE%9E%E8%B7%B5%E5%9F%BA%E7%A1%80_%E5%B9%B3%E5%8F%B0%E6%A1%86%E6%9E%B6%E8%A1%A5%E5%85%85/20190613175426636.png" alt="在这里插入图片描述"></p>
<p><img src="https://perfectism13.github.io/2019/11/17/%E5%AE%9E%E8%B7%B5%E5%9F%BA%E7%A1%80_%E5%B9%B3%E5%8F%B0%E6%A1%86%E6%9E%B6%E8%A1%A5%E5%85%85/20190613175919378.png" alt="在这里插入图片描述"></p>
<h2 id="摩尔定律"><a href="#摩尔定律" class="headerlink" title="摩尔定律"></a>摩尔定律</h2><p>摩尔定律（英语：Moore’s law）是由英特尔（Intel）创始人之一戈登·摩尔提出的。其内容为：集成电路上可容纳的晶体管数目，约每隔两年便会增加一倍；经常被引用的“18个月”，是由英特尔首席执行官大卫·豪斯（David House）提出：预计18个月会将芯片的性能提高一倍（即更多的晶体管使其更快），是一种以倍数增长的观测。</p>
<h2 id="车辆实时操作系统"><a href="#车辆实时操作系统" class="headerlink" title="车辆实时操作系统"></a>车辆实时操作系统</h2><p>详见： <a href="https://zhuanlan.zhihu.com/p/45294616" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/45294616</a></p>
<h3 id="QNX"><a href="#QNX" class="headerlink" title="QNX"></a>QNX</h3><p>QNX，英文名Quick Unix，是由加拿大QSSL公司（2010年被加拿大黑莓公司收购）开发的分布式实时操作系统，采用独特的微内核实时平台，相比Windos、Linux等大型操作系统，QNX内核极小且运行速度极快。 除了快，QNX的实时性、稳定性也极高，据说MTTF（平均失效时间）可以达到99.999%（5个9），也就是说，一年365天当中，它可能出错的时间只有31秒。</p>
<p><strong>EX</strong>：Apollo2.0整合了QNX操作系统，大众、宝马、丰田、菲亚特、福特等</p>
<h3 id="WinCE"><a href="#WinCE" class="headerlink" title="WinCE"></a>WinCE</h3><p>Windos Embedbed Compact, 微软Windows操作系统中的一员 ,相对于Android系统的丰富体验，Windos CE就显得捉襟见肘。由于车机系统大部分应用场景是导航和音乐，移动互联时代，任何一部智能手机都能取代车机，而获得更佳的用户体验。</p>
<p><strong>EX</strong>： 早期如凯立德、四维图新等车载导航系统供应商，都是基于Windos CE开发的</p>
<h3 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h3><p>免费开源、可个性化定制、 稳定性及处理效率较好、 基于Linux开发的难度也极大，而且开发周期比较长， 限制了车机系统进入门槛，除了规模较大的主机厂，以及有实力的车机供应商，能够花重金雇佣一支专业操作系统研发团队，其余的也只能望尘莫及 。</p>
<p><strong>EX:</strong> 凯迪拉克CUE系统</p>
<h3 id="VxWorks"><a href="#VxWorks" class="headerlink" title="VxWorks"></a>VxWorks</h3><p>美国 Wind River System 公司（ 简称风河公司 ，即 WRS 公司）推出的一个实时操作系统。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/24/%E7%A7%91%E7%9B%AE%E4%BA%8C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chenyang Min">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="perfectism's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/07/24/%E7%A7%91%E7%9B%AE%E4%BA%8C/" class="post-title-link" itemprop="url">科目二</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-24 13:10:01" itemprop="dateCreated datePublished" datetime="2020-07-24T13:10:01+08:00">2020-07-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-07-05 21:19:55" itemprop="dateModified" datetime="2020-07-05T21:19:55+08:00">2020-07-05</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>起步与停车</p>
<p>￼<img src="科目二\下载.png" alt=""></p>
<p>1.直角弯与s弯</p>
<ul>
<li>喷水嘴对准砖头，当边线挡住左车头角（儿童锁对住内直角），往左打死，过弯后迅速回正</li>
</ul>
<p>喷水嘴对住箭头中线，当右边线过车盖中点，向左打一圈，转过弯之后，到路中央回正，等到左边线过车盖中点，向右打一圈，快出s弯时，回正，结束</p>
<p>Ps:</p>
<ul>
<li>左大灯贴到右边线，往左打一圈，左转看左镜腿（大灯）</li>
<li>左大灯盖住外侧黄线时回正，车头一半盖到黄线时，往右打一圈</li>
<li>右转看右镜腿</li>
<li>车正后回正</li>
<li>若左镜腿超出则往左打，左轮压线是因为打的过早或者开始时没有稍微往右</li>
</ul>
<p>2.倒车入库</p>
<p>(1)右倒库:</p>
<ul>
<li>先将车停在右方人对住黄线（通过左镜看黄线（7米线）位于左后视镜下沿中间偏左)，人坐在控制线上时停车</li>
<li>后倒当后轮压住线（左后视镜下沿和控制线重合），迅速向右打死</li>
<li>通过右后视镜观察右后轮与库角距离稍小于三十公分时回正</li>
<li>继续观察当后轮快到库口或右后轮快压住库口连接线时（右后车把手进入库角而不压角，<strong>确保右后轮入库不压角</strong>），再右打死</li>
<li>观察左后视镜，车身正时（左后视镜观察到库角，后线露出15公分时，快要平行时）迅速回正，(当左后视镜后面窄时，向右打轮回正)</li>
<li>后轮压线(一定要压线)或者左后视镜下沿和实线重合时，过一秒后停车</li>
<li>ps：注意一把进的情况：第一把打死，后轮已经能入库且不压角，则看左后视镜</li>
</ul>
<p>(2):左飞</p>
<ul>
<li><p>左后视镜左轮(一定是车轮不要是车屁股)对住库角或左后视镜看到库前角，向左打死</p>
</li>
<li><p>喷水嘴对住线后回正</p>
</li>
</ul>
<p>(3):左倒库</p>
<ul>
<li>左后视镜看到左轮压线，向左打死</li>
<li>与库口略小于30公分时回正</li>
<li>后轮快入库时左打死</li>
<li>车身正时回正（或右后视镜观察到库角15公分）</li>
<li>后轮压线过一秒停车</li>
</ul>
<p>(4):右飞</p>
<ul>
<li>左轮(一定是车轮)到库角右打死</li>
<li>喷水嘴对住线回正</li>
</ul>
<p>备注：</p>
<ul>
<li><p>入库后一边宽，一边窄，不用管，一定保持车身平齐</p>
</li>
<li><p>出库时后视镜里左后宽，往右微打轮</p>
</li>
<li><p>入库时左后视镜后边宽，往左微打轮</p>
</li>
<li><p>入库后，车屁股左斜稍早停车，车屁股右斜稍迟停车</p>
</li>
</ul>
<p>3.侧方停车</p>
<ul>
<li>人对住树后停车（或库角在右后视镜中央时停车）(右侧与黄线保持30到40公分或左侧雨刮器制高点贴右侧边线走，车头右侧三分之一贴边线)</li>
<li>通过右后视镜看右后轮快到库角时（或右后视镜库角刚消失时）右打死</li>
<li>观察左镜，当露出四分之三时回正</li>
<li>当左后轮<strong>快快</strong>压住库口连接线时左打死，车身正时，停车(注意方向不要回正，踩离合，踩刹车),打左转向灯</li>
<li>看车头被二分时，迅速回正，并缓慢向右打一圈</li>
<li>xxx左后镜看后轮，当压住连接线时（或挡风玻璃右下角和右实线对齐时），回正并向右打一圈，当前盖被二分时向右半圈，然后打死，车身正后回正</li>
</ul>
<p>ps：领边线右边距离宽了时，方向盘提前打</p>
<p>最后停车，左边宽时稍早停车，左边窄时，稍迟停车</p>
<p>4.半坡起步</p>
<ul>
<li><p>上坡前缓抬离合，上坡后离合抬完，边线要取好（左侧雨刮器制高点贴右侧边线走，车头右侧三分之一贴边线）</p>
</li>
<li><p>对住点（左后视镜下沿稍过黄色实线）后，先踩离合再踩刹车，然后将手刹按住按钮往上提死</p>
</li>
<li><p>缓抬离合（车嘎嘎的响，或者车抖动，仪表盘转速表指针掉一格，车抬头），右脚踩油门2000到3000转后，当车头抬起后，两脚稳住，缓慢松手刹，感觉上去比较费劲再松一些离合</p>
</li>
<li>翻过坡后松油门，离合松完，缓踩刹车，喷水嘴对住砖头后，进入直角弯</li>
<li>(油门一定不能松,一定不能松，一定不能松)</li>
</ul>
<p>ps：松刹车时后溜，立马再踩刹车，熄火时，回空挡，再打火，再挂一档，可在上坡之前打开空调</p>
<p>窝窝对住箭头</p>
<p>侧方对住花牌停车，南边的侧方会下滑，离合要控制好</p>
<p>倒库记得都是第一道线</p>
<p>半坡记得左边的上去要往右打一点</p>
<p>出s弯时记得注意黄线</p>
<p>4号车离合稳好，6号要油门踩多</p>
<p>考试时可以先试一下车</p>
<p>倒库时先把线看好，再挂倒档</p>
<p>上车后座位一定要调好，要让脚前掌在离合器上，而不是脚后跟</p>
<p>压住线再打，不要提前打，小于三十公分回正，继续倒，当轮子到裤口大于十公分时，向左打死，当车屁股向左稍斜时，回正</p>
<p>第一个库压第一道线，第二个库压第二道线</p>
<p>半坡起步，左脚抬离合到车抖或者差不多，右脚踩油门，松手刹，方向盘稍向左</p>
<p>考试千万不敢紧张</p>
<p>2020.7.4丹凤练车总结</p>
<p>半坡：</p>
<ul>
<li>熄火时，回到空挡再打火，打完火记得挂前进挡</li>
<li>先踩离合，再踩刹车</li>
<li>拿窝窝对水泥缝子稍左，宁愿扣十分也不能压右边线</li>
</ul>
<p>S弯：</p>
<ul>
<li>出S弯时等车斜的开一会再开回原位</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/24/%E4%BA%A4%E6%B5%81%E6%80%9D%E8%80%83/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chenyang Min">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="perfectism's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/07/24/%E4%BA%A4%E6%B5%81%E6%80%9D%E8%80%83/" class="post-title-link" itemprop="url">交流思考</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-24 13:10:01" itemprop="dateCreated datePublished" datetime="2020-07-24T13:10:01+08:00">2020-07-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-16 21:34:55" itemprop="dateModified" datetime="2020-03-16T21:34:55+08:00">2020-03-16</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="交流思考"><a href="#交流思考" class="headerlink" title="交流思考"></a>交流思考</h1><h2 id="2019-12-19下午三点于中楼"><a href="#2019-12-19下午三点于中楼" class="headerlink" title="2019.12.19下午三点于中楼"></a>2019.12.19下午三点于中楼</h2><p>1.如何产生新的idea：</p>
<p>复现论文和阅读论文是一个循环的过程</p>
<p>可以将其他领域的方法移植到自己的问题上来，也就是要找到问题的本质，也要求自己的知识面要足够广，i.e:将NLP中的方法移植到CV中来？</p>
<p>2.要看好的大学的英文论文，要沉下心来，看看别人的想法是什么，最后一定要有自己的想法，找到论文之间的差异性，新颖点，不同点在哪里</p>
<p>3.图像领域重要的就是准确度的提升、工程应用的难易程度？</p>
<p>4.写小论文，申请专利，反复修改，论文框架？</p>
<h2 id="2019-12-19晚11点与天马公寓"><a href="#2019-12-19晚11点与天马公寓" class="headerlink" title="2019.12.19晚11点与天马公寓"></a>2019.12.19晚11点与天马公寓</h2><p>1.善于利用网络问别人问题<br>2.和师兄搞好关系<br>3.寻找每篇论文存在的问题，新颖点<br>4.每周报告认真写报告，越详细越好<br>5.大胆的假设结果，然后向目标求证<br>6.不同角度解读问题<br>7.必要时修改对结果的预判，甚至修改问题<br>8.不打迷糊仗，避免使用大概等词：有方法，有数据，有实验，有证明<br>10.现在每天工作14小时，以后8小时？<br>11.如何阅读论文<br>中国科学，机械工程学报<br>不要找含复杂数学知识的论文<br>重现论文<br>12.创新思维</p>
<p>来源-崔老师《如何做科研》</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/24/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chenyang Min">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="perfectism's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/07/24/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/" class="post-title-link" itemprop="url">驾驶员动作检测综述</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-24 13:10:01" itemprop="dateCreated datePublished" datetime="2020-07-24T13:10:01+08:00">2020-07-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-16 21:34:09" itemprop="dateModified" datetime="2020-03-16T21:34:09+08:00">2020-03-16</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="驾驶员动作检测综述"><a href="#驾驶员动作检测综述" class="headerlink" title="驾驶员动作检测综述"></a>驾驶员动作检测综述</h1><p>闵晨阳 2020.02.01</p>
<h2 id="图片分类"><a href="#图片分类" class="headerlink" title="图片分类"></a>图片分类</h2><h3 id="多流融合的CNN"><a href="#多流融合的CNN" class="headerlink" title="多流融合的CNN"></a>多流融合的CNN</h3><p>原文见参考文献【1】</p>
<p><strong>datasets</strong></p>
<p>SEU-DRIVING dataset，state-farm distracted driving dataset</p>
<p><strong>Network architecture</strong></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/1.PNG" alt="img"></p>
<p><strong>Fusion strategy</strong></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/2.PNG" alt="img"></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/3.PNG" alt="img"></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/4.PNG" alt="img"></p>
<p><strong>Experiment results</strong></p>
<p><strong>state farm</strong></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/5.PNG" alt="img"></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/6.PNG" alt="img"></p>
<p>SEU</p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/7.PNG" alt="img"></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/8.PNG" alt="img"></p>
<h3 id="多尺度注意机制CNN"><a href="#多尺度注意机制CNN" class="headerlink" title="多尺度注意机制CNN"></a>多尺度注意机制CNN</h3><p>原文见参考文献【2】</p>
<p><strong>datasets</strong></p>
<p>State-Farm,S-DA,R-DA</p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/32.PNG" alt="img"></p>
<p><strong>Network architecture</strong></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/10.PNG" alt="img"></p>
<p><strong>Experiment results</strong></p>
<p><strong>state farm</strong></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/14.PNG" alt="img"></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/13.PNG" alt="img"></p>
<p><strong>R-DA</strong></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/11.PNG" alt="img"></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/12.PNG" alt="img"></p>
<p><strong>S-DA</strong></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/16.PNG" alt="img"></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/15.PNG" alt="img"></p>
<h3 id="融合手脸特征的CNN"><a href="#融合手脸特征的CNN" class="headerlink" title="融合手脸特征的CNN"></a>融合手脸特征的CNN</h3><p>原文见参考文献【5】</p>
<p><strong>datasets</strong></p>
<p>AUC([5]首创)</p>
<p><strong>Network architecture</strong></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/23.PNG" alt="img"></p>
<p><strong>Experiment results</strong></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/24.PNG" alt="img"></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/25.PNG" alt="img"></p>
<h2 id="视频分类"><a href="#视频分类" class="headerlink" title="视频分类"></a>视频分类</h2><h3 id="Two-Stream-Inflated-3D-ConvNet-I3D"><a href="#Two-Stream-Inflated-3D-ConvNet-I3D" class="headerlink" title="Two-Stream Inflated 3D ConvNet(I3D)"></a>Two-Stream Inflated 3D ConvNet(I3D)</h3><p>原文见参考文献【3】【4】</p>
<p><strong>datasets</strong></p>
<p>AUC,State Farm</p>
<p>经过对以上两个数据集的每一帧图片的组合得到20,094 10-frame clips for State<br>Farm and 14,536 10-frame clips for AUC dataset</p>
<p><strong>Network architecture</strong></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/17.PNG" alt="img"></p>
<p><strong>Experiment results</strong></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/18.PNG" alt="img"></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/20.PNG" alt="img"></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/19.PNG" alt="img"></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/21.PNG" alt="img"></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/22.PNG" alt="img"></p>
<h3 id="基于空间-时间特征的CNN"><a href="#基于空间-时间特征的CNN" class="headerlink" title="基于空间-时间特征的CNN"></a>基于空间-时间特征的CNN</h3><p>原文见参考文献【6】</p>
<p><strong>datasets</strong></p>
<p>AUC ,Brain4Cars</p>
<p><strong>Network architecture</strong></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/26.PNG" alt="img"></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/27.PNG" alt="img"></p>
<p><strong>数据融合</strong>：通过每一帧图片后增加几帧光流来联系“连续几帧图片”</p>
<p>融合后的四帧数据输入带有Softmax层(批量归一化层）的inception网络，每一帧结果融合后经过softmax层输出预测结果</p>
<p><strong>Experiment results</strong></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/28.PNG" alt="img"></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/29.PNG" alt="img"></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/30.PNG" alt="img"></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/31.PNG" alt="img"></p>
<h3 id="多类型细粒度Drive-amp-Act数据集"><a href="#多类型细粒度Drive-amp-Act数据集" class="headerlink" title="多类型细粒度Drive&amp;Act数据集"></a>多类型细粒度Drive&amp;Act数据集</h3><p>原文见参考文献【7】</p>
<p><strong>datasets</strong></p>
<p><a href="https://www.driveandact.com/" target="_blank" rel="noopener">https://www.driveandact.com/</a></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/33.PNG" alt="img"></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/34.PNG" alt="img"></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/35.PNG" alt="35"></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/36.PNG" alt="36"></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/37.PNG" alt="37"></p>
<p><strong>Experiment results</strong></p>
<p><strong>Mid-Level</strong></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/38.PNG" alt="img"></p>
<p><strong>Action-Object-Location</strong></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/39.PNG" alt="39"></p>
<p><strong>Long-running Task</strong></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/40.PNG" alt="40"></p>
<p><strong>多类型数据融合的结果</strong></p>
<p><img src="https://perfectism13.github.io/2020/02/01/%E9%A9%BE%E9%A9%B6%E5%91%98%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/41.PNG" alt="41"></p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>【1】Hu Y, Lu M, Lu X, et al. Driving behaviour recognition from still images by using multi-stream fusion CNN[J]. machine vision applications, 2019, 30(5): 851-865.</p>
<p>【2】Hu Y, Lu M, Lu X, et al. Feature refinement for image-based driver action recognition via multi-scale attention convolutional neural network[J]. Signal Processing-image Communication, 2020.</p>
<p>【3】Moslemi N, Azmi R, Soryani M, et al. Driver Distraction Recognition using 3D Convolutional Neural Networks[C]. international conference on pattern recognition, 2019.</p>
<p>【4】 J. Carreira and A. Zisserman, “Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset,” in IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.</p>
<p>【5】Abouelnaga Y, Eraqi H M, Moustafa M, et al. Real-time Distracted Driver Posture Classification.[J]. arXiv: Computer Vision and Pattern Recognition, 2017.</p>
<p>【6】Kose N, Kopuklu O, Unnervik A, et al. Real-Time Driver State Monitoring Using a CNN Based Spatio-Temporal Approach*[C]. international conference on intelligent transportation systems, 2019.</p>
<p>【7】Martin M, Roitberg A, Haurilet M, et al. Drive&amp;Act: A Multi-Modal Dataset for Fine-Grained Driver Behavior Recognition in Autonomous Vehicles[C]. international conference on computer vision, 2019: 2801-2810.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Chenyang Min</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">26</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">分类</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chenyang Min</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  


</body>
</html>
